{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363000</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126905</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118497</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308858</th>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107934</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "363000  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0415  0.0928   \n",
       "126905  0.0024  0.0024  0.0513  0.0269  0.0024  0.0024  0.0684  0.0977   \n",
       "118497  0.0049  0.2026  0.0464  0.0024  0.0024  0.0024  0.0635  0.0659   \n",
       "308858  0.0928  0.0610  0.1465  0.1074  0.0073  0.0073  0.2271  0.2124   \n",
       "107934  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "363000  0.1440  0.0244           0             0         0           0  \n",
       "126905  0.0024  0.0342           1             1         4           4  \n",
       "118497  0.1929  0.1587           1             1         3           3  \n",
       "308858  0.0586  0.0586           6             6         7           7  \n",
       "107934  0.0024  0.0024           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential    \n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(48, input_dim=input_dim, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(192, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(384, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(768, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "\n",
    "model.add(Dense(768, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(384, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(192, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_188 (Dense)           (None, 48)                528       \n",
      "                                                                 \n",
      " batch_normalization_144 (Ba  (None, 48)               192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 96)                4704      \n",
      "                                                                 \n",
      " batch_normalization_145 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 192)               18624     \n",
      "                                                                 \n",
      " batch_normalization_146 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 384)               74112     \n",
      "                                                                 \n",
      " batch_normalization_147 (Ba  (None, 384)              1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 768)               295680    \n",
      "                                                                 \n",
      " batch_normalization_148 (Ba  (None, 768)              3072      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 24)                18456     \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 768)               19200     \n",
      "                                                                 \n",
      " batch_normalization_149 (Ba  (None, 768)              3072      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 384)               295296    \n",
      "                                                                 \n",
      " batch_normalization_150 (Ba  (None, 384)              1536      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 192)               73920     \n",
      "                                                                 \n",
      " batch_normalization_151 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 96)                18528     \n",
      "                                                                 \n",
      " batch_normalization_152 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 48)                4656      \n",
      "                                                                 \n",
      " batch_normalization_153 (Ba  (None, 48)               192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 24)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 836,784\n",
      "Trainable params: 830,832\n",
      "Non-trainable params: 5,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 3s 22ms/step - loss: 1.5396 - accuracy: 0.6187 - val_loss: 2.8676 - val_accuracy: 0.5284\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 1.0007 - accuracy: 0.7367 - val_loss: 2.6290 - val_accuracy: 0.5284\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.8058 - accuracy: 0.7830 - val_loss: 2.4518 - val_accuracy: 0.5284\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.7039 - accuracy: 0.8073 - val_loss: 2.3534 - val_accuracy: 0.5284\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.6333 - accuracy: 0.8243 - val_loss: 2.2433 - val_accuracy: 0.5284\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.5835 - accuracy: 0.8364 - val_loss: 2.1961 - val_accuracy: 0.5284\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.8460 - val_loss: 2.1615 - val_accuracy: 0.5284\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.5108 - accuracy: 0.8549 - val_loss: 2.0757 - val_accuracy: 0.5292\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.4862 - accuracy: 0.8609 - val_loss: 1.7825 - val_accuracy: 0.5836\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.4672 - accuracy: 0.8659 - val_loss: 1.2152 - val_accuracy: 0.7059\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.4483 - accuracy: 0.8710 - val_loss: 0.7789 - val_accuracy: 0.8235\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.4236 - accuracy: 0.8780 - val_loss: 0.5038 - val_accuracy: 0.8593\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 0.4085 - accuracy: 0.8815 - val_loss: 0.4856 - val_accuracy: 0.8701\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3946 - accuracy: 0.8854 - val_loss: 0.4213 - val_accuracy: 0.8789\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3836 - accuracy: 0.8881 - val_loss: 0.4426 - val_accuracy: 0.8759\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3732 - accuracy: 0.8914 - val_loss: 0.4222 - val_accuracy: 0.8814\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3598 - accuracy: 0.8951 - val_loss: 0.4131 - val_accuracy: 0.8833\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3513 - accuracy: 0.8980 - val_loss: 0.4163 - val_accuracy: 0.8847\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3437 - accuracy: 0.8999 - val_loss: 0.4211 - val_accuracy: 0.8854\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3381 - accuracy: 0.9009 - val_loss: 0.4670 - val_accuracy: 0.8694\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3294 - accuracy: 0.9038 - val_loss: 0.4055 - val_accuracy: 0.8852\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3203 - accuracy: 0.9067 - val_loss: 0.4065 - val_accuracy: 0.8888\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3150 - accuracy: 0.9084 - val_loss: 0.4031 - val_accuracy: 0.8870\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3100 - accuracy: 0.9097 - val_loss: 0.3793 - val_accuracy: 0.8932\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.3039 - accuracy: 0.9113 - val_loss: 0.3808 - val_accuracy: 0.8939\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2995 - accuracy: 0.9122 - val_loss: 0.3961 - val_accuracy: 0.8871\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2954 - accuracy: 0.9139 - val_loss: 0.3686 - val_accuracy: 0.8972\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2854 - accuracy: 0.9169 - val_loss: 0.3604 - val_accuracy: 0.9015\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2794 - accuracy: 0.9185 - val_loss: 0.3777 - val_accuracy: 0.8991\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2726 - accuracy: 0.9207 - val_loss: 0.3609 - val_accuracy: 0.8982\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2739 - accuracy: 0.9202 - val_loss: 0.3672 - val_accuracy: 0.8962\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2644 - accuracy: 0.9233 - val_loss: 0.3517 - val_accuracy: 0.9022\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2657 - accuracy: 0.9227 - val_loss: 0.4578 - val_accuracy: 0.8550\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2634 - accuracy: 0.9231 - val_loss: 0.3717 - val_accuracy: 0.9010\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2589 - accuracy: 0.9246 - val_loss: 0.3321 - val_accuracy: 0.9060\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2543 - accuracy: 0.9263 - val_loss: 0.3433 - val_accuracy: 0.9040\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 0.2489 - accuracy: 0.9281 - val_loss: 0.3376 - val_accuracy: 0.9086\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2491 - accuracy: 0.9272 - val_loss: 0.3309 - val_accuracy: 0.9059\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2441 - accuracy: 0.9292 - val_loss: 0.3384 - val_accuracy: 0.9093\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2399 - accuracy: 0.9303 - val_loss: 0.3503 - val_accuracy: 0.9090\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2367 - accuracy: 0.9312 - val_loss: 0.3513 - val_accuracy: 0.9013\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2332 - accuracy: 0.9325 - val_loss: 0.3270 - val_accuracy: 0.9106\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2329 - accuracy: 0.9324 - val_loss: 0.3327 - val_accuracy: 0.9102\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2305 - accuracy: 0.9333 - val_loss: 0.3360 - val_accuracy: 0.9092\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2312 - accuracy: 0.9331 - val_loss: 0.4158 - val_accuracy: 0.8745\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2265 - accuracy: 0.9342 - val_loss: 0.3496 - val_accuracy: 0.9054\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2258 - accuracy: 0.9348 - val_loss: 0.3390 - val_accuracy: 0.9098\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2188 - accuracy: 0.9366 - val_loss: 0.3284 - val_accuracy: 0.9124\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 0.2221 - accuracy: 0.9354 - val_loss: 0.3294 - val_accuracy: 0.9118\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2184 - accuracy: 0.9369 - val_loss: 0.3284 - val_accuracy: 0.9121\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2229 - accuracy: 0.9353 - val_loss: 0.3216 - val_accuracy: 0.9115\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2151 - accuracy: 0.9381 - val_loss: 0.3327 - val_accuracy: 0.9118\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2133 - accuracy: 0.9384 - val_loss: 0.3351 - val_accuracy: 0.9085\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2132 - accuracy: 0.9386 - val_loss: 0.3204 - val_accuracy: 0.9141\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2139 - accuracy: 0.9379 - val_loss: 0.3086 - val_accuracy: 0.9181\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2069 - accuracy: 0.9403 - val_loss: 0.3033 - val_accuracy: 0.9191\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2029 - accuracy: 0.9418 - val_loss: 0.3132 - val_accuracy: 0.9164\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2067 - accuracy: 0.9403 - val_loss: 0.3183 - val_accuracy: 0.9152\n",
      "Epoch 59/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2030 - accuracy: 0.9416 - val_loss: 0.3125 - val_accuracy: 0.9151\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.2083 - accuracy: 0.9397 - val_loss: 0.3054 - val_accuracy: 0.9174\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1972 - accuracy: 0.9433 - val_loss: 0.3127 - val_accuracy: 0.9168\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1990 - accuracy: 0.9426 - val_loss: 0.3101 - val_accuracy: 0.9184\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.2011 - accuracy: 0.9421 - val_loss: 0.3022 - val_accuracy: 0.9191\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1951 - accuracy: 0.9436 - val_loss: 0.3284 - val_accuracy: 0.9176\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1917 - accuracy: 0.9448 - val_loss: 0.2930 - val_accuracy: 0.9220\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1920 - accuracy: 0.9447 - val_loss: 0.3107 - val_accuracy: 0.9213\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1907 - accuracy: 0.9452 - val_loss: 0.3100 - val_accuracy: 0.9206\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 0.1927 - accuracy: 0.9443 - val_loss: 0.3020 - val_accuracy: 0.9211\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1901 - accuracy: 0.9454 - val_loss: 0.2955 - val_accuracy: 0.9228\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1842 - accuracy: 0.9472 - val_loss: 0.2955 - val_accuracy: 0.9240\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1842 - accuracy: 0.9471 - val_loss: 0.3563 - val_accuracy: 0.9030\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1821 - accuracy: 0.9477 - val_loss: 0.3060 - val_accuracy: 0.9216\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1879 - accuracy: 0.9457 - val_loss: 0.3204 - val_accuracy: 0.9175\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1820 - accuracy: 0.9474 - val_loss: 0.2981 - val_accuracy: 0.9228\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1861 - accuracy: 0.9463 - val_loss: 0.2993 - val_accuracy: 0.9213\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1855 - accuracy: 0.9465 - val_loss: 0.3465 - val_accuracy: 0.9068\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1844 - accuracy: 0.9467 - val_loss: 0.2959 - val_accuracy: 0.9229\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1826 - accuracy: 0.9475 - val_loss: 0.2866 - val_accuracy: 0.9246\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1733 - accuracy: 0.9500 - val_loss: 0.3171 - val_accuracy: 0.9163\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1722 - accuracy: 0.9505 - val_loss: 0.3042 - val_accuracy: 0.9215\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1721 - accuracy: 0.9505 - val_loss: 0.2913 - val_accuracy: 0.9253\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1717 - accuracy: 0.9506 - val_loss: 0.2943 - val_accuracy: 0.9231\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1748 - accuracy: 0.9499 - val_loss: 0.3429 - val_accuracy: 0.9179\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1797 - accuracy: 0.9481 - val_loss: 0.3072 - val_accuracy: 0.9207\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1746 - accuracy: 0.9497 - val_loss: 0.3005 - val_accuracy: 0.9206\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1694 - accuracy: 0.9512 - val_loss: 0.2900 - val_accuracy: 0.9255\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1697 - accuracy: 0.9512 - val_loss: 0.2978 - val_accuracy: 0.9230\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1697 - accuracy: 0.9514 - val_loss: 0.2976 - val_accuracy: 0.9252\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1648 - accuracy: 0.9530 - val_loss: 0.3092 - val_accuracy: 0.9213\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1639 - accuracy: 0.9530 - val_loss: 0.2956 - val_accuracy: 0.9267\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1679 - accuracy: 0.9518 - val_loss: 0.3035 - val_accuracy: 0.9242\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9525 - val_loss: 0.3012 - val_accuracy: 0.9255\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1632 - accuracy: 0.9533 - val_loss: 0.3011 - val_accuracy: 0.9252\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1636 - accuracy: 0.9531 - val_loss: 0.2918 - val_accuracy: 0.9258\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9527 - val_loss: 0.2982 - val_accuracy: 0.9261\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1644 - accuracy: 0.9527 - val_loss: 0.3111 - val_accuracy: 0.9208\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1671 - accuracy: 0.9521 - val_loss: 0.2897 - val_accuracy: 0.9265\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1602 - accuracy: 0.9542 - val_loss: 0.2962 - val_accuracy: 0.9249\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1625 - accuracy: 0.9528 - val_loss: 0.2897 - val_accuracy: 0.9260\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1643 - accuracy: 0.9529 - val_loss: 0.3017 - val_accuracy: 0.9255\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1569 - accuracy: 0.9552 - val_loss: 0.2746 - val_accuracy: 0.9283\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1563 - accuracy: 0.9555 - val_loss: 0.2786 - val_accuracy: 0.9295\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1574 - accuracy: 0.9551 - val_loss: 0.2946 - val_accuracy: 0.9255\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1582 - accuracy: 0.9548 - val_loss: 0.2994 - val_accuracy: 0.9239\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1560 - accuracy: 0.9552 - val_loss: 0.2780 - val_accuracy: 0.9295\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 0.1544 - accuracy: 0.9559 - val_loss: 0.3081 - val_accuracy: 0.9273\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1549 - accuracy: 0.9555 - val_loss: 0.2963 - val_accuracy: 0.9276\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1570 - accuracy: 0.9552 - val_loss: 0.2969 - val_accuracy: 0.9256\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1537 - accuracy: 0.9557 - val_loss: 0.2986 - val_accuracy: 0.9248\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 0.1498 - accuracy: 0.9572 - val_loss: 0.2915 - val_accuracy: 0.9280\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1509 - accuracy: 0.9569 - val_loss: 0.2888 - val_accuracy: 0.9268\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 0.1537 - accuracy: 0.9558 - val_loss: 0.2849 - val_accuracy: 0.9285\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1532 - accuracy: 0.9559 - val_loss: 0.2967 - val_accuracy: 0.9280\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1488 - accuracy: 0.9574 - val_loss: 0.2851 - val_accuracy: 0.9290\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1489 - accuracy: 0.9571 - val_loss: 0.3601 - val_accuracy: 0.8974\n",
      "Epoch 116/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1527 - accuracy: 0.9559 - val_loss: 0.2938 - val_accuracy: 0.9279\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1465 - accuracy: 0.9582 - val_loss: 0.2901 - val_accuracy: 0.9291\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1476 - accuracy: 0.9574 - val_loss: 0.2891 - val_accuracy: 0.9291\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1485 - accuracy: 0.9578 - val_loss: 0.2949 - val_accuracy: 0.9285\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1501 - accuracy: 0.9571 - val_loss: 0.2875 - val_accuracy: 0.9299\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1498 - accuracy: 0.9570 - val_loss: 0.2908 - val_accuracy: 0.9291\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1477 - accuracy: 0.9575 - val_loss: 0.2990 - val_accuracy: 0.9263\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1445 - accuracy: 0.9589 - val_loss: 0.2966 - val_accuracy: 0.9296\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1451 - accuracy: 0.9583 - val_loss: 0.2854 - val_accuracy: 0.9292\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1443 - accuracy: 0.9588 - val_loss: 0.2889 - val_accuracy: 0.9291\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1392 - accuracy: 0.9602 - val_loss: 0.2710 - val_accuracy: 0.9327\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1373 - accuracy: 0.9610 - val_loss: 0.2821 - val_accuracy: 0.9309\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1470 - accuracy: 0.9584 - val_loss: 0.2964 - val_accuracy: 0.9276\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1879 - accuracy: 0.9453 - val_loss: 0.3171 - val_accuracy: 0.9188\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1454 - accuracy: 0.9579 - val_loss: 0.2853 - val_accuracy: 0.9291\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1523 - accuracy: 0.9562 - val_loss: 0.3019 - val_accuracy: 0.9234\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1432 - accuracy: 0.9591 - val_loss: 0.2858 - val_accuracy: 0.9295\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1403 - accuracy: 0.9597 - val_loss: 0.2861 - val_accuracy: 0.9306\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1332 - accuracy: 0.9624 - val_loss: 0.2781 - val_accuracy: 0.9328\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1384 - accuracy: 0.9605 - val_loss: 0.5442 - val_accuracy: 0.8348\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1446 - accuracy: 0.9574 - val_loss: 0.3076 - val_accuracy: 0.9260\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1375 - accuracy: 0.9603 - val_loss: 0.2787 - val_accuracy: 0.9325\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1344 - accuracy: 0.9617 - val_loss: 0.2962 - val_accuracy: 0.9297\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1361 - accuracy: 0.9612 - val_loss: 0.2989 - val_accuracy: 0.9305\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1384 - accuracy: 0.9603 - val_loss: 0.2879 - val_accuracy: 0.9303\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1331 - accuracy: 0.9622 - val_loss: 0.2795 - val_accuracy: 0.9333\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1327 - accuracy: 0.9620 - val_loss: 0.3021 - val_accuracy: 0.9291\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1322 - accuracy: 0.9620 - val_loss: 0.3049 - val_accuracy: 0.9313\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1486 - accuracy: 0.9592 - val_loss: 0.4501 - val_accuracy: 0.8904\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1694 - accuracy: 0.9503 - val_loss: 0.3068 - val_accuracy: 0.9266\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1322 - accuracy: 0.9621 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1243 - accuracy: 0.9647 - val_loss: 0.2779 - val_accuracy: 0.9341\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1268 - accuracy: 0.9641 - val_loss: 0.2852 - val_accuracy: 0.9327\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1287 - accuracy: 0.9635 - val_loss: 0.2879 - val_accuracy: 0.9314\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1272 - accuracy: 0.9641 - val_loss: 0.2968 - val_accuracy: 0.9299\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1275 - accuracy: 0.9639 - val_loss: 0.2848 - val_accuracy: 0.9346\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1271 - accuracy: 0.9639 - val_loss: 0.3266 - val_accuracy: 0.9158\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1254 - accuracy: 0.9642 - val_loss: 0.2825 - val_accuracy: 0.9339\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1273 - accuracy: 0.9639 - val_loss: 0.3040 - val_accuracy: 0.9297\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1331 - accuracy: 0.9614 - val_loss: 0.2999 - val_accuracy: 0.9301\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1283 - accuracy: 0.9633 - val_loss: 0.3020 - val_accuracy: 0.9299\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1274 - accuracy: 0.9634 - val_loss: 0.3047 - val_accuracy: 0.9269\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1287 - accuracy: 0.9632 - val_loss: 0.3001 - val_accuracy: 0.9294\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1311 - accuracy: 0.9626 - val_loss: 0.3041 - val_accuracy: 0.9304\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1272 - accuracy: 0.9638 - val_loss: 0.2969 - val_accuracy: 0.9317\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9538 - val_loss: 0.3260 - val_accuracy: 0.9221\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 0.1317 - accuracy: 0.9617 - val_loss: 0.2817 - val_accuracy: 0.9343\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1206 - accuracy: 0.9658 - val_loss: 0.2734 - val_accuracy: 0.9365\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1186 - accuracy: 0.9665 - val_loss: 0.2658 - val_accuracy: 0.9375\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1160 - accuracy: 0.9672 - val_loss: 0.2775 - val_accuracy: 0.9366\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1198 - accuracy: 0.9659 - val_loss: 0.2800 - val_accuracy: 0.9370\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 0.1201 - accuracy: 0.9661 - val_loss: 0.2833 - val_accuracy: 0.9350\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1233 - accuracy: 0.9650 - val_loss: 0.3055 - val_accuracy: 0.9273\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1269 - accuracy: 0.9636 - val_loss: 0.2939 - val_accuracy: 0.9323\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1240 - accuracy: 0.9646 - val_loss: 0.2903 - val_accuracy: 0.9329\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1242 - accuracy: 0.9645 - val_loss: 0.2898 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 0.1239 - accuracy: 0.9646 - val_loss: 0.2885 - val_accuracy: 0.9317\n",
      "Epoch 173/300\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 0.1221 - accuracy: 0.9652 - val_loss: 0.3138 - val_accuracy: 0.9286\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1272 - accuracy: 0.9634 - val_loss: 0.2983 - val_accuracy: 0.9328\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1204 - accuracy: 0.9654 - val_loss: 0.2780 - val_accuracy: 0.9354\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1231 - accuracy: 0.9647 - val_loss: 0.2922 - val_accuracy: 0.9336\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1190 - accuracy: 0.9659 - val_loss: 0.2886 - val_accuracy: 0.9337\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1217 - accuracy: 0.9653 - val_loss: 0.3219 - val_accuracy: 0.9207\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1190 - accuracy: 0.9658 - val_loss: 0.2913 - val_accuracy: 0.9311\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1165 - accuracy: 0.9667 - val_loss: 0.2833 - val_accuracy: 0.9360\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1152 - accuracy: 0.9670 - val_loss: 0.3041 - val_accuracy: 0.9299\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1194 - accuracy: 0.9658 - val_loss: 0.2868 - val_accuracy: 0.9339\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1166 - accuracy: 0.9669 - val_loss: 0.2896 - val_accuracy: 0.9348\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1167 - accuracy: 0.9666 - val_loss: 0.3252 - val_accuracy: 0.9234\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1200 - accuracy: 0.9659 - val_loss: 0.7359 - val_accuracy: 0.8055\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1196 - accuracy: 0.9658 - val_loss: 0.2835 - val_accuracy: 0.9354\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1195 - accuracy: 0.9655 - val_loss: 0.2896 - val_accuracy: 0.9333\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1185 - accuracy: 0.9661 - val_loss: 0.2841 - val_accuracy: 0.9332\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1169 - accuracy: 0.9665 - val_loss: 0.2898 - val_accuracy: 0.9352\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1149 - accuracy: 0.9672 - val_loss: 0.2869 - val_accuracy: 0.9344\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1134 - accuracy: 0.9677 - val_loss: 0.2877 - val_accuracy: 0.9354\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1115 - accuracy: 0.9685 - val_loss: 0.2939 - val_accuracy: 0.9339\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1129 - accuracy: 0.9677 - val_loss: 0.2924 - val_accuracy: 0.9351\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1148 - accuracy: 0.9675 - val_loss: 0.2905 - val_accuracy: 0.9357\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1173 - accuracy: 0.9665 - val_loss: 0.3071 - val_accuracy: 0.9312\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1151 - accuracy: 0.9674 - val_loss: 0.2921 - val_accuracy: 0.9344\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1139 - accuracy: 0.9676 - val_loss: 0.2960 - val_accuracy: 0.9333\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1144 - accuracy: 0.9675 - val_loss: 0.2983 - val_accuracy: 0.9339\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1148 - accuracy: 0.9670 - val_loss: 0.2934 - val_accuracy: 0.9353\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1140 - accuracy: 0.9671 - val_loss: 0.2905 - val_accuracy: 0.9352\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1210 - accuracy: 0.9650 - val_loss: 0.3027 - val_accuracy: 0.9306\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1174 - accuracy: 0.9664 - val_loss: 0.2834 - val_accuracy: 0.9365\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1114 - accuracy: 0.9683 - val_loss: 0.2855 - val_accuracy: 0.9361\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1100 - accuracy: 0.9686 - val_loss: 0.2950 - val_accuracy: 0.9347\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1137 - accuracy: 0.9675 - val_loss: 0.2920 - val_accuracy: 0.9351\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1114 - accuracy: 0.9682 - val_loss: 0.2965 - val_accuracy: 0.9345\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1122 - accuracy: 0.9680 - val_loss: 0.2973 - val_accuracy: 0.9344\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1144 - accuracy: 0.9675 - val_loss: 0.3073 - val_accuracy: 0.9332\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1132 - accuracy: 0.9675 - val_loss: 0.2834 - val_accuracy: 0.9368\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1065 - accuracy: 0.9697 - val_loss: 0.2980 - val_accuracy: 0.9316\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1062 - accuracy: 0.9698 - val_loss: 0.3062 - val_accuracy: 0.9324\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1104 - accuracy: 0.9685 - val_loss: 0.3016 - val_accuracy: 0.9343\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1101 - accuracy: 0.9683 - val_loss: 0.3071 - val_accuracy: 0.9336\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1119 - accuracy: 0.9679 - val_loss: 0.2922 - val_accuracy: 0.9360\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1139 - accuracy: 0.9673 - val_loss: 0.3081 - val_accuracy: 0.9335\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1123 - accuracy: 0.9678 - val_loss: 0.3045 - val_accuracy: 0.9332\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1107 - accuracy: 0.9684 - val_loss: 0.3083 - val_accuracy: 0.9307\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1098 - accuracy: 0.9685 - val_loss: 0.3043 - val_accuracy: 0.9349\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1071 - accuracy: 0.9693 - val_loss: 0.2923 - val_accuracy: 0.9351\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1076 - accuracy: 0.9693 - val_loss: 0.2907 - val_accuracy: 0.9347\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1081 - accuracy: 0.9690 - val_loss: 0.2932 - val_accuracy: 0.9342\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1102 - accuracy: 0.9684 - val_loss: 0.3008 - val_accuracy: 0.9328\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1061 - accuracy: 0.9694 - val_loss: 0.3072 - val_accuracy: 0.9309\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1049 - accuracy: 0.9700 - val_loss: 0.2993 - val_accuracy: 0.9347\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1080 - accuracy: 0.9691 - val_loss: 0.3287 - val_accuracy: 0.9230\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.2958 - val_accuracy: 0.9353\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1050 - accuracy: 0.9699 - val_loss: 0.2927 - val_accuracy: 0.9365\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1089 - accuracy: 0.9688 - val_loss: 0.3728 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1079 - accuracy: 0.9690 - val_loss: 0.3061 - val_accuracy: 0.9359\n",
      "Epoch 230/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1059 - accuracy: 0.9693 - val_loss: 0.3022 - val_accuracy: 0.9355\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1091 - accuracy: 0.9685 - val_loss: 0.2892 - val_accuracy: 0.9368\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1065 - accuracy: 0.9695 - val_loss: 0.3031 - val_accuracy: 0.9344\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1037 - accuracy: 0.9702 - val_loss: 0.3040 - val_accuracy: 0.9361\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1066 - accuracy: 0.9694 - val_loss: 0.3224 - val_accuracy: 0.9265\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1038 - accuracy: 0.9703 - val_loss: 0.2925 - val_accuracy: 0.9364\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1032 - accuracy: 0.9704 - val_loss: 0.2875 - val_accuracy: 0.9379\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.0997 - accuracy: 0.9716 - val_loss: 0.2895 - val_accuracy: 0.9387\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1058 - accuracy: 0.9698 - val_loss: 0.2980 - val_accuracy: 0.9367\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1093 - accuracy: 0.9684 - val_loss: 0.3120 - val_accuracy: 0.9343\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1068 - accuracy: 0.9695 - val_loss: 0.2981 - val_accuracy: 0.9366\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1069 - accuracy: 0.9692 - val_loss: 0.3023 - val_accuracy: 0.9326\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1070 - accuracy: 0.9693 - val_loss: 0.3057 - val_accuracy: 0.9358\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1041 - accuracy: 0.9701 - val_loss: 0.3073 - val_accuracy: 0.9341\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1011 - accuracy: 0.9710 - val_loss: 0.2943 - val_accuracy: 0.9360\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1002 - accuracy: 0.9713 - val_loss: 0.2955 - val_accuracy: 0.9366\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1100 - accuracy: 0.9695 - val_loss: 1.0439 - val_accuracy: 0.7567\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1858 - accuracy: 0.9470 - val_loss: 0.6767 - val_accuracy: 0.8152\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1097 - accuracy: 0.9684 - val_loss: 0.2823 - val_accuracy: 0.9365\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 0.1004 - accuracy: 0.9715 - val_loss: 0.2970 - val_accuracy: 0.9373\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0980 - accuracy: 0.9724 - val_loss: 0.2889 - val_accuracy: 0.9378\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0971 - accuracy: 0.9724 - val_loss: 0.2853 - val_accuracy: 0.9378\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0945 - accuracy: 0.9731 - val_loss: 0.2930 - val_accuracy: 0.9364\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0959 - accuracy: 0.9727 - val_loss: 0.2853 - val_accuracy: 0.9395\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0975 - accuracy: 0.9722 - val_loss: 0.3160 - val_accuracy: 0.9282\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0971 - accuracy: 0.9721 - val_loss: 0.2948 - val_accuracy: 0.9360\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1023 - accuracy: 0.9708 - val_loss: 0.3225 - val_accuracy: 0.9308\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0997 - accuracy: 0.9712 - val_loss: 0.2909 - val_accuracy: 0.9369\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1020 - accuracy: 0.9705 - val_loss: 0.2913 - val_accuracy: 0.9364\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0997 - accuracy: 0.9713 - val_loss: 0.3027 - val_accuracy: 0.9368\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.2973 - val_accuracy: 0.9355\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 0.1000 - accuracy: 0.9714 - val_loss: 0.3022 - val_accuracy: 0.9357\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0974 - accuracy: 0.9720 - val_loss: 0.2975 - val_accuracy: 0.9369\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1013 - accuracy: 0.9705 - val_loss: 0.3137 - val_accuracy: 0.9331\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.1003 - accuracy: 0.9708 - val_loss: 0.2981 - val_accuracy: 0.9355\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0973 - accuracy: 0.9719 - val_loss: 0.3024 - val_accuracy: 0.9360\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0971 - accuracy: 0.9719 - val_loss: 0.3054 - val_accuracy: 0.9377\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0953 - accuracy: 0.9724 - val_loss: 0.2878 - val_accuracy: 0.9391\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0972 - accuracy: 0.9721 - val_loss: 0.2985 - val_accuracy: 0.9374\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0994 - accuracy: 0.9713 - val_loss: 0.3003 - val_accuracy: 0.9375\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1546 - accuracy: 0.9574 - val_loss: 1.1681 - val_accuracy: 0.7441\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.1310 - accuracy: 0.9620 - val_loss: 0.3092 - val_accuracy: 0.9302\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 0.1040 - accuracy: 0.9699 - val_loss: 0.3007 - val_accuracy: 0.9327\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0966 - accuracy: 0.9723 - val_loss: 0.2972 - val_accuracy: 0.9380\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0938 - accuracy: 0.9734 - val_loss: 0.2849 - val_accuracy: 0.9393\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0934 - accuracy: 0.9736 - val_loss: 0.2968 - val_accuracy: 0.9361\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0946 - accuracy: 0.9729 - val_loss: 0.2964 - val_accuracy: 0.9385\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0967 - accuracy: 0.9724 - val_loss: 0.3032 - val_accuracy: 0.9383\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0945 - accuracy: 0.9730 - val_loss: 0.2962 - val_accuracy: 0.9378\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0948 - accuracy: 0.9728 - val_loss: 0.3006 - val_accuracy: 0.9352\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0980 - accuracy: 0.9718 - val_loss: 0.3107 - val_accuracy: 0.9372\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.3081 - val_accuracy: 0.9349\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0952 - accuracy: 0.9728 - val_loss: 0.2929 - val_accuracy: 0.9379\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0948 - accuracy: 0.9729 - val_loss: 0.2947 - val_accuracy: 0.9382\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0942 - accuracy: 0.9729 - val_loss: 0.3047 - val_accuracy: 0.9374\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0949 - accuracy: 0.9724 - val_loss: 0.2920 - val_accuracy: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0952 - accuracy: 0.9726 - val_loss: 0.3211 - val_accuracy: 0.9343\n",
      "Epoch 287/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0992 - accuracy: 0.9714 - val_loss: 0.2973 - val_accuracy: 0.9379\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0969 - accuracy: 0.9719 - val_loss: 0.3045 - val_accuracy: 0.9355\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0967 - accuracy: 0.9719 - val_loss: 0.3136 - val_accuracy: 0.9340\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0989 - accuracy: 0.9712 - val_loss: 0.2993 - val_accuracy: 0.9377\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.3290 - val_accuracy: 0.9330\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0949 - accuracy: 0.9729 - val_loss: 0.2986 - val_accuracy: 0.9371\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0934 - accuracy: 0.9730 - val_loss: 0.3032 - val_accuracy: 0.9377\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0968 - accuracy: 0.9718 - val_loss: 0.3022 - val_accuracy: 0.9369\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 0.3064 - val_accuracy: 0.9370\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0933 - accuracy: 0.9732 - val_loss: 0.3123 - val_accuracy: 0.9341\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0945 - accuracy: 0.9731 - val_loss: 0.3014 - val_accuracy: 0.9374\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 0.0938 - accuracy: 0.9729 - val_loss: 0.3105 - val_accuracy: 0.9359\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 0.0920 - accuracy: 0.9734 - val_loss: 0.2989 - val_accuracy: 0.9382\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 0.0936 - accuracy: 0.9730 - val_loss: 0.2941 - val_accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 8s 3ms/step - loss: 0.2941 - accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9712902e-01, 9.0814729e-07, 5.4093813e-05, ..., 3.1018078e-07,\n",
       "        1.8644353e-06, 5.1291418e-06],\n",
       "       [8.5135831e-12, 1.0767393e-11, 1.7071107e-11, ..., 6.9297179e-10,\n",
       "        2.1535147e-09, 3.5390329e-08],\n",
       "       [8.9415443e-01, 4.0513161e-03, 6.2962365e-04, ..., 1.1977407e-07,\n",
       "        8.1753555e-08, 2.8368721e-08],\n",
       "       ...,\n",
       "       [5.1982457e-08, 6.1490196e-10, 6.0992393e-09, ..., 3.8374184e-14,\n",
       "        5.6911041e-13, 7.2799633e-13],\n",
       "       [9.7800714e-01, 2.0131213e-04, 1.0536153e-02, ..., 7.6808220e-07,\n",
       "        6.8981228e-07, 2.2936670e-06],\n",
       "       [3.8685513e-13, 7.6024759e-10, 8.4630202e-08, ..., 5.6759976e-08,\n",
       "        4.1493369e-09, 2.6538194e-12]], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d4c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
