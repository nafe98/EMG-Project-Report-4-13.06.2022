{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313943</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380714</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38663</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373947</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325473</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "313943  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0122  0.0952   \n",
       "380714  0.0024  0.0024  0.0049  0.0024  0.0024  0.0024  0.0269  0.0464   \n",
       "38663   0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.2100  0.1074   \n",
       "373947  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342  0.0122   \n",
       "325473  0.0024  0.0024  0.0073  0.0024  0.0024  0.0024  0.0024  0.0049   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "313943  0.0024  0.0488           0             0         0           0  \n",
       "380714  0.1172  0.0049           9             0        14           0  \n",
       "38663   0.0024  0.0488           0             0         0           0  \n",
       "373947  0.0830  0.0024           1             0        14           0  \n",
       "325473  0.0098  0.0391           4             0         9           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential    \n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(48, input_dim=input_dim, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 48)                528       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48)               192       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                4704      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 192)               18624     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 192)              768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                4632      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 192)               4800      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 192)              768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 96)                18528     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 48)                4656      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 48)               192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 24)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,336\n",
      "Trainable params: 58,992\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "75/75 [==============================] - 3s 11ms/step - loss: 1.5748 - accuracy: 0.6115 - val_loss: 2.4633 - val_accuracy: 0.5284\n",
      "Epoch 2/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 1.0414 - accuracy: 0.7312 - val_loss: 2.1384 - val_accuracy: 0.5284\n",
      "Epoch 3/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.8649 - accuracy: 0.7716 - val_loss: 2.0684 - val_accuracy: 0.5286\n",
      "Epoch 4/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.7715 - accuracy: 0.7923 - val_loss: 1.9596 - val_accuracy: 0.5345\n",
      "Epoch 5/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.7104 - accuracy: 0.8061 - val_loss: 1.7025 - val_accuracy: 0.5706\n",
      "Epoch 6/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.6659 - accuracy: 0.8165 - val_loss: 1.3903 - val_accuracy: 0.6274\n",
      "Epoch 7/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.6323 - accuracy: 0.8242 - val_loss: 1.0695 - val_accuracy: 0.7065\n",
      "Epoch 8/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.6082 - accuracy: 0.8296 - val_loss: 0.8432 - val_accuracy: 0.7638\n",
      "Epoch 9/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5863 - accuracy: 0.8348 - val_loss: 0.6986 - val_accuracy: 0.8069\n",
      "Epoch 10/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.8390 - val_loss: 0.6228 - val_accuracy: 0.8250\n",
      "Epoch 11/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5531 - accuracy: 0.8430 - val_loss: 0.5899 - val_accuracy: 0.8353\n",
      "Epoch 12/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5387 - accuracy: 0.8468 - val_loss: 0.5815 - val_accuracy: 0.8380\n",
      "Epoch 13/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5310 - accuracy: 0.8489 - val_loss: 0.5584 - val_accuracy: 0.8412\n",
      "Epoch 14/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5132 - accuracy: 0.8532 - val_loss: 0.5536 - val_accuracy: 0.8466\n",
      "Epoch 15/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.5035 - accuracy: 0.8559 - val_loss: 0.5340 - val_accuracy: 0.8492\n",
      "Epoch 16/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4944 - accuracy: 0.8581 - val_loss: 0.5400 - val_accuracy: 0.8463\n",
      "Epoch 17/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4877 - accuracy: 0.8593 - val_loss: 0.5300 - val_accuracy: 0.8505\n",
      "Epoch 18/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4784 - accuracy: 0.8625 - val_loss: 0.5281 - val_accuracy: 0.8524\n",
      "Epoch 19/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4723 - accuracy: 0.8639 - val_loss: 0.5130 - val_accuracy: 0.8546\n",
      "Epoch 20/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4648 - accuracy: 0.8653 - val_loss: 0.5148 - val_accuracy: 0.8538\n",
      "Epoch 21/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4613 - accuracy: 0.8669 - val_loss: 0.5110 - val_accuracy: 0.8570\n",
      "Epoch 22/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4518 - accuracy: 0.8689 - val_loss: 0.5030 - val_accuracy: 0.8567\n",
      "Epoch 23/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4464 - accuracy: 0.8710 - val_loss: 0.4918 - val_accuracy: 0.8604\n",
      "Epoch 24/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4378 - accuracy: 0.8733 - val_loss: 0.4806 - val_accuracy: 0.8632\n",
      "Epoch 25/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.8733 - val_loss: 0.4803 - val_accuracy: 0.8631\n",
      "Epoch 26/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4337 - accuracy: 0.8741 - val_loss: 0.4796 - val_accuracy: 0.8629\n",
      "Epoch 27/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4264 - accuracy: 0.8763 - val_loss: 0.4792 - val_accuracy: 0.8656\n",
      "Epoch 28/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.8772 - val_loss: 0.4902 - val_accuracy: 0.8612\n",
      "Epoch 29/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4142 - accuracy: 0.8796 - val_loss: 0.4614 - val_accuracy: 0.8688\n",
      "Epoch 30/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4134 - accuracy: 0.8799 - val_loss: 0.4636 - val_accuracy: 0.8680\n",
      "Epoch 31/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4089 - accuracy: 0.8810 - val_loss: 0.4643 - val_accuracy: 0.8676\n",
      "Epoch 32/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4013 - accuracy: 0.8833 - val_loss: 0.4508 - val_accuracy: 0.8715\n",
      "Epoch 33/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.4012 - accuracy: 0.8830 - val_loss: 0.4561 - val_accuracy: 0.8702\n",
      "Epoch 34/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3973 - accuracy: 0.8838 - val_loss: 0.4568 - val_accuracy: 0.8693\n",
      "Epoch 35/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3915 - accuracy: 0.8855 - val_loss: 0.4533 - val_accuracy: 0.8714\n",
      "Epoch 36/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3927 - accuracy: 0.8858 - val_loss: 0.4613 - val_accuracy: 0.8712\n",
      "Epoch 37/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3859 - accuracy: 0.8876 - val_loss: 0.4442 - val_accuracy: 0.8740\n",
      "Epoch 38/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3844 - accuracy: 0.8872 - val_loss: 0.4494 - val_accuracy: 0.8717\n",
      "Epoch 39/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3831 - accuracy: 0.8886 - val_loss: 0.4876 - val_accuracy: 0.8674\n",
      "Epoch 40/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3776 - accuracy: 0.8897 - val_loss: 0.4445 - val_accuracy: 0.8734\n",
      "Epoch 41/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3749 - accuracy: 0.8905 - val_loss: 0.4388 - val_accuracy: 0.8742\n",
      "Epoch 42/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3729 - accuracy: 0.8911 - val_loss: 0.4394 - val_accuracy: 0.8741\n",
      "Epoch 43/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3702 - accuracy: 0.8921 - val_loss: 0.4453 - val_accuracy: 0.8725\n",
      "Epoch 44/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3701 - accuracy: 0.8912 - val_loss: 0.4392 - val_accuracy: 0.8758\n",
      "Epoch 45/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3684 - accuracy: 0.8920 - val_loss: 0.4327 - val_accuracy: 0.8761\n",
      "Epoch 46/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3639 - accuracy: 0.8938 - val_loss: 0.4309 - val_accuracy: 0.8764\n",
      "Epoch 47/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3636 - accuracy: 0.8937 - val_loss: 0.4442 - val_accuracy: 0.8728\n",
      "Epoch 48/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3603 - accuracy: 0.8944 - val_loss: 0.4343 - val_accuracy: 0.8763\n",
      "Epoch 49/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8947 - val_loss: 0.4189 - val_accuracy: 0.8796\n",
      "Epoch 50/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3532 - accuracy: 0.8968 - val_loss: 0.4308 - val_accuracy: 0.8769\n",
      "Epoch 51/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3561 - accuracy: 0.8956 - val_loss: 0.4215 - val_accuracy: 0.8796\n",
      "Epoch 52/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3491 - accuracy: 0.8975 - val_loss: 0.4255 - val_accuracy: 0.8817\n",
      "Epoch 53/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3501 - accuracy: 0.8976 - val_loss: 0.4125 - val_accuracy: 0.8826\n",
      "Epoch 54/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3434 - accuracy: 0.8996 - val_loss: 0.4165 - val_accuracy: 0.8812\n",
      "Epoch 55/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3438 - accuracy: 0.8997 - val_loss: 0.4190 - val_accuracy: 0.8813\n",
      "Epoch 56/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3462 - accuracy: 0.8989 - val_loss: 0.4083 - val_accuracy: 0.8837\n",
      "Epoch 57/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3424 - accuracy: 0.8999 - val_loss: 0.4123 - val_accuracy: 0.8830\n",
      "Epoch 58/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3412 - accuracy: 0.9000 - val_loss: 0.4247 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.9013 - val_loss: 0.4140 - val_accuracy: 0.8826\n",
      "Epoch 60/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3364 - accuracy: 0.9018 - val_loss: 0.4120 - val_accuracy: 0.8840\n",
      "Epoch 61/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.9012 - val_loss: 0.4067 - val_accuracy: 0.8849\n",
      "Epoch 62/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3321 - accuracy: 0.9028 - val_loss: 0.4066 - val_accuracy: 0.8845\n",
      "Epoch 63/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3344 - accuracy: 0.9020 - val_loss: 0.4044 - val_accuracy: 0.8849\n",
      "Epoch 64/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3324 - accuracy: 0.9025 - val_loss: 0.4074 - val_accuracy: 0.8835\n",
      "Epoch 65/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3319 - accuracy: 0.9032 - val_loss: 0.4062 - val_accuracy: 0.8859\n",
      "Epoch 66/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3267 - accuracy: 0.9047 - val_loss: 0.4022 - val_accuracy: 0.8856\n",
      "Epoch 67/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3284 - accuracy: 0.9040 - val_loss: 0.4075 - val_accuracy: 0.8839\n",
      "Epoch 68/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3253 - accuracy: 0.9047 - val_loss: 0.4031 - val_accuracy: 0.8852\n",
      "Epoch 69/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3288 - accuracy: 0.9037 - val_loss: 0.3952 - val_accuracy: 0.8862\n",
      "Epoch 70/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3218 - accuracy: 0.9060 - val_loss: 0.4033 - val_accuracy: 0.8854\n",
      "Epoch 71/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3209 - accuracy: 0.9068 - val_loss: 0.5032 - val_accuracy: 0.8574\n",
      "Epoch 72/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.9075 - val_loss: 0.3903 - val_accuracy: 0.8892\n",
      "Epoch 73/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3172 - accuracy: 0.9073 - val_loss: 0.3868 - val_accuracy: 0.8890\n",
      "Epoch 74/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3207 - accuracy: 0.9062 - val_loss: 0.4007 - val_accuracy: 0.8869\n",
      "Epoch 75/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.9064 - val_loss: 0.3876 - val_accuracy: 0.8915\n",
      "Epoch 76/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.9076 - val_loss: 0.3923 - val_accuracy: 0.8882\n",
      "Epoch 77/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.9078 - val_loss: 0.3983 - val_accuracy: 0.8884\n",
      "Epoch 78/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.4046 - val_accuracy: 0.8883\n",
      "Epoch 79/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3134 - accuracy: 0.9082 - val_loss: 0.3845 - val_accuracy: 0.8919\n",
      "Epoch 80/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.9093 - val_loss: 0.3798 - val_accuracy: 0.8924\n",
      "Epoch 81/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3100 - accuracy: 0.9095 - val_loss: 0.3844 - val_accuracy: 0.8919\n",
      "Epoch 82/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.9093 - val_loss: 0.3908 - val_accuracy: 0.8892\n",
      "Epoch 83/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3080 - accuracy: 0.9102 - val_loss: 0.3867 - val_accuracy: 0.8909\n",
      "Epoch 84/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3095 - accuracy: 0.9092 - val_loss: 0.3877 - val_accuracy: 0.8922\n",
      "Epoch 85/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3038 - accuracy: 0.9114 - val_loss: 0.3846 - val_accuracy: 0.8916\n",
      "Epoch 86/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.9112 - val_loss: 0.3911 - val_accuracy: 0.8894\n",
      "Epoch 87/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3086 - accuracy: 0.9103 - val_loss: 0.3760 - val_accuracy: 0.8942\n",
      "Epoch 88/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3032 - accuracy: 0.9115 - val_loss: 0.4019 - val_accuracy: 0.8908\n",
      "Epoch 89/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3007 - accuracy: 0.9126 - val_loss: 0.3804 - val_accuracy: 0.8916\n",
      "Epoch 90/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3034 - accuracy: 0.9113 - val_loss: 0.3897 - val_accuracy: 0.8897\n",
      "Epoch 91/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.9123 - val_loss: 0.3803 - val_accuracy: 0.8926\n",
      "Epoch 92/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.3002 - accuracy: 0.9123 - val_loss: 0.3860 - val_accuracy: 0.8924\n",
      "Epoch 93/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2999 - accuracy: 0.9128 - val_loss: 0.3857 - val_accuracy: 0.8917\n",
      "Epoch 94/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2992 - accuracy: 0.9126 - val_loss: 0.3834 - val_accuracy: 0.8930\n",
      "Epoch 95/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.9133 - val_loss: 0.4337 - val_accuracy: 0.8817\n",
      "Epoch 96/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2951 - accuracy: 0.9139 - val_loss: 0.3648 - val_accuracy: 0.8974\n",
      "Epoch 97/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2966 - accuracy: 0.9135 - val_loss: 0.3818 - val_accuracy: 0.8924\n",
      "Epoch 98/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2951 - accuracy: 0.9140 - val_loss: 0.3718 - val_accuracy: 0.8945\n",
      "Epoch 99/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2919 - accuracy: 0.9147 - val_loss: 0.3655 - val_accuracy: 0.8968\n",
      "Epoch 100/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2934 - accuracy: 0.9146 - val_loss: 0.3839 - val_accuracy: 0.8929\n",
      "Epoch 101/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2916 - accuracy: 0.9148 - val_loss: 0.3763 - val_accuracy: 0.8943\n",
      "Epoch 102/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2943 - accuracy: 0.9143 - val_loss: 0.3720 - val_accuracy: 0.8953\n",
      "Epoch 103/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2899 - accuracy: 0.9155 - val_loss: 0.3714 - val_accuracy: 0.8961\n",
      "Epoch 104/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2868 - accuracy: 0.9167 - val_loss: 0.3834 - val_accuracy: 0.8932\n",
      "Epoch 105/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2884 - accuracy: 0.9157 - val_loss: 0.3703 - val_accuracy: 0.8965\n",
      "Epoch 106/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2885 - accuracy: 0.9160 - val_loss: 0.3781 - val_accuracy: 0.8930\n",
      "Epoch 107/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2883 - accuracy: 0.9159 - val_loss: 0.3720 - val_accuracy: 0.8952\n",
      "Epoch 108/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2879 - accuracy: 0.9163 - val_loss: 0.3732 - val_accuracy: 0.8952\n",
      "Epoch 109/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2860 - accuracy: 0.9171 - val_loss: 0.3778 - val_accuracy: 0.8946\n",
      "Epoch 110/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2886 - accuracy: 0.9161 - val_loss: 0.3819 - val_accuracy: 0.8921\n",
      "Epoch 111/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2859 - accuracy: 0.9163 - val_loss: 0.3751 - val_accuracy: 0.8952\n",
      "Epoch 112/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2856 - accuracy: 0.9170 - val_loss: 0.3784 - val_accuracy: 0.8949\n",
      "Epoch 113/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2806 - accuracy: 0.9181 - val_loss: 0.3709 - val_accuracy: 0.8953\n",
      "Epoch 114/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2831 - accuracy: 0.9180 - val_loss: 0.3780 - val_accuracy: 0.8920\n",
      "Epoch 115/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2852 - accuracy: 0.9164 - val_loss: 0.3698 - val_accuracy: 0.8950\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2816 - accuracy: 0.9182 - val_loss: 0.3767 - val_accuracy: 0.8946\n",
      "Epoch 117/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2780 - accuracy: 0.9191 - val_loss: 0.3678 - val_accuracy: 0.8959\n",
      "Epoch 118/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2808 - accuracy: 0.9183 - val_loss: 0.3665 - val_accuracy: 0.8978\n",
      "Epoch 119/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2777 - accuracy: 0.9191 - val_loss: 0.3697 - val_accuracy: 0.8971\n",
      "Epoch 120/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2767 - accuracy: 0.9196 - val_loss: 0.3606 - val_accuracy: 0.8983\n",
      "Epoch 121/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2736 - accuracy: 0.9204 - val_loss: 0.3942 - val_accuracy: 0.8932\n",
      "Epoch 122/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2798 - accuracy: 0.9188 - val_loss: 0.3675 - val_accuracy: 0.8975\n",
      "Epoch 123/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2754 - accuracy: 0.9198 - val_loss: 0.3747 - val_accuracy: 0.8974\n",
      "Epoch 124/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2740 - accuracy: 0.9204 - val_loss: 0.3694 - val_accuracy: 0.8971\n",
      "Epoch 125/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2749 - accuracy: 0.9198 - val_loss: 0.3694 - val_accuracy: 0.8972\n",
      "Epoch 126/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2780 - accuracy: 0.9188 - val_loss: 0.3643 - val_accuracy: 0.8976\n",
      "Epoch 127/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2726 - accuracy: 0.9207 - val_loss: 0.3617 - val_accuracy: 0.8978\n",
      "Epoch 128/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2751 - accuracy: 0.9197 - val_loss: 0.3710 - val_accuracy: 0.8970\n",
      "Epoch 129/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2737 - accuracy: 0.9202 - val_loss: 0.3695 - val_accuracy: 0.8976\n",
      "Epoch 130/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2717 - accuracy: 0.9211 - val_loss: 0.3641 - val_accuracy: 0.8992\n",
      "Epoch 131/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2747 - accuracy: 0.9202 - val_loss: 0.3646 - val_accuracy: 0.8983\n",
      "Epoch 132/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2719 - accuracy: 0.9211 - val_loss: 0.3637 - val_accuracy: 0.8993\n",
      "Epoch 133/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2724 - accuracy: 0.9208 - val_loss: 0.3659 - val_accuracy: 0.8991\n",
      "Epoch 134/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2710 - accuracy: 0.9211 - val_loss: 0.3730 - val_accuracy: 0.8963\n",
      "Epoch 135/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2668 - accuracy: 0.9225 - val_loss: 0.3595 - val_accuracy: 0.8998\n",
      "Epoch 136/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2671 - accuracy: 0.9225 - val_loss: 0.3663 - val_accuracy: 0.8985\n",
      "Epoch 137/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2703 - accuracy: 0.9217 - val_loss: 0.3760 - val_accuracy: 0.8950\n",
      "Epoch 138/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2686 - accuracy: 0.9218 - val_loss: 0.3682 - val_accuracy: 0.8978\n",
      "Epoch 139/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2695 - accuracy: 0.9216 - val_loss: 0.3686 - val_accuracy: 0.8967\n",
      "Epoch 140/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2676 - accuracy: 0.9221 - val_loss: 0.3548 - val_accuracy: 0.9004\n",
      "Epoch 141/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2644 - accuracy: 0.9231 - val_loss: 0.3623 - val_accuracy: 0.8980\n",
      "Epoch 142/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2672 - accuracy: 0.9226 - val_loss: 0.3603 - val_accuracy: 0.8992\n",
      "Epoch 143/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2651 - accuracy: 0.9231 - val_loss: 0.3685 - val_accuracy: 0.8987\n",
      "Epoch 144/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2606 - accuracy: 0.9240 - val_loss: 0.3564 - val_accuracy: 0.9004\n",
      "Epoch 145/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2606 - accuracy: 0.9244 - val_loss: 0.3698 - val_accuracy: 0.8966\n",
      "Epoch 146/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2656 - accuracy: 0.9230 - val_loss: 0.3659 - val_accuracy: 0.8983\n",
      "Epoch 147/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2629 - accuracy: 0.9235 - val_loss: 0.3622 - val_accuracy: 0.8981\n",
      "Epoch 148/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2618 - accuracy: 0.9239 - val_loss: 0.3646 - val_accuracy: 0.8982\n",
      "Epoch 149/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2660 - accuracy: 0.9227 - val_loss: 0.3563 - val_accuracy: 0.9006\n",
      "Epoch 150/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2629 - accuracy: 0.9235 - val_loss: 0.3602 - val_accuracy: 0.8988\n",
      "Epoch 151/200\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.2622 - accuracy: 0.9239 - val_loss: 0.3592 - val_accuracy: 0.9004\n",
      "Epoch 152/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2602 - accuracy: 0.9244 - val_loss: 0.3558 - val_accuracy: 0.9019\n",
      "Epoch 153/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2600 - accuracy: 0.9245 - val_loss: 0.3556 - val_accuracy: 0.9008\n",
      "Epoch 154/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2636 - accuracy: 0.9233 - val_loss: 0.3641 - val_accuracy: 0.8991\n",
      "Epoch 155/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2625 - accuracy: 0.9235 - val_loss: 0.3673 - val_accuracy: 0.8992\n",
      "Epoch 156/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2612 - accuracy: 0.9235 - val_loss: 0.3587 - val_accuracy: 0.9005\n",
      "Epoch 157/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2562 - accuracy: 0.9255 - val_loss: 0.3528 - val_accuracy: 0.9022\n",
      "Epoch 158/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2570 - accuracy: 0.9258 - val_loss: 0.3583 - val_accuracy: 0.9007\n",
      "Epoch 159/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.3706 - val_accuracy: 0.8976\n",
      "Epoch 160/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2632 - accuracy: 0.9232 - val_loss: 0.3481 - val_accuracy: 0.9030\n",
      "Epoch 161/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2580 - accuracy: 0.9253 - val_loss: 0.3575 - val_accuracy: 0.9016\n",
      "Epoch 162/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2563 - accuracy: 0.9256 - val_loss: 0.3558 - val_accuracy: 0.9005\n",
      "Epoch 163/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2594 - accuracy: 0.9241 - val_loss: 0.3561 - val_accuracy: 0.9012\n",
      "Epoch 164/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2552 - accuracy: 0.9262 - val_loss: 0.3544 - val_accuracy: 0.9016\n",
      "Epoch 165/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2568 - accuracy: 0.9255 - val_loss: 0.3652 - val_accuracy: 0.8989\n",
      "Epoch 166/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2569 - accuracy: 0.9252 - val_loss: 0.3588 - val_accuracy: 0.9007\n",
      "Epoch 167/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2542 - accuracy: 0.9266 - val_loss: 0.3504 - val_accuracy: 0.9027\n",
      "Epoch 168/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2512 - accuracy: 0.9275 - val_loss: 0.3666 - val_accuracy: 0.8992\n",
      "Epoch 169/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2539 - accuracy: 0.9264 - val_loss: 0.3437 - val_accuracy: 0.9054\n",
      "Epoch 170/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2543 - accuracy: 0.9258 - val_loss: 0.3662 - val_accuracy: 0.9019\n",
      "Epoch 171/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2531 - accuracy: 0.9267 - val_loss: 0.3596 - val_accuracy: 0.9028\n",
      "Epoch 172/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2543 - accuracy: 0.9259 - val_loss: 0.3497 - val_accuracy: 0.9022\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2546 - accuracy: 0.9260 - val_loss: 0.3600 - val_accuracy: 0.9024\n",
      "Epoch 174/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2543 - accuracy: 0.9263 - val_loss: 0.3526 - val_accuracy: 0.9010\n",
      "Epoch 175/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2520 - accuracy: 0.9267 - val_loss: 0.3512 - val_accuracy: 0.9033\n",
      "Epoch 176/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2507 - accuracy: 0.9275 - val_loss: 0.3472 - val_accuracy: 0.9031\n",
      "Epoch 177/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2501 - accuracy: 0.9275 - val_loss: 0.3773 - val_accuracy: 0.8987\n",
      "Epoch 178/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2504 - accuracy: 0.9280 - val_loss: 0.3470 - val_accuracy: 0.9036\n",
      "Epoch 179/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2488 - accuracy: 0.9280 - val_loss: 0.3510 - val_accuracy: 0.9024\n",
      "Epoch 180/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2534 - accuracy: 0.9270 - val_loss: 0.3689 - val_accuracy: 0.8989\n",
      "Epoch 181/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2503 - accuracy: 0.9275 - val_loss: 0.3642 - val_accuracy: 0.8990\n",
      "Epoch 182/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2513 - accuracy: 0.9270 - val_loss: 0.3579 - val_accuracy: 0.9015\n",
      "Epoch 183/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2489 - accuracy: 0.9280 - val_loss: 0.3466 - val_accuracy: 0.9037\n",
      "Epoch 184/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2464 - accuracy: 0.9291 - val_loss: 0.3497 - val_accuracy: 0.9022\n",
      "Epoch 185/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2480 - accuracy: 0.9280 - val_loss: 0.3732 - val_accuracy: 0.8967\n",
      "Epoch 186/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2475 - accuracy: 0.9283 - val_loss: 0.3641 - val_accuracy: 0.9019\n",
      "Epoch 187/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2459 - accuracy: 0.9293 - val_loss: 0.3658 - val_accuracy: 0.8999\n",
      "Epoch 188/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2454 - accuracy: 0.9294 - val_loss: 0.3509 - val_accuracy: 0.9036\n",
      "Epoch 189/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2485 - accuracy: 0.9280 - val_loss: 0.3577 - val_accuracy: 0.9025\n",
      "Epoch 190/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2486 - accuracy: 0.9277 - val_loss: 0.3615 - val_accuracy: 0.9015\n",
      "Epoch 191/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2499 - accuracy: 0.9275 - val_loss: 0.3612 - val_accuracy: 0.9002\n",
      "Epoch 192/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2477 - accuracy: 0.9283 - val_loss: 0.3657 - val_accuracy: 0.9012\n",
      "Epoch 193/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2457 - accuracy: 0.9286 - val_loss: 0.3583 - val_accuracy: 0.9037\n",
      "Epoch 194/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2468 - accuracy: 0.9284 - val_loss: 0.3499 - val_accuracy: 0.9036\n",
      "Epoch 195/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2452 - accuracy: 0.9293 - val_loss: 0.3518 - val_accuracy: 0.9030\n",
      "Epoch 196/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2441 - accuracy: 0.9295 - val_loss: 0.3613 - val_accuracy: 0.9024\n",
      "Epoch 197/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2457 - accuracy: 0.9293 - val_loss: 0.3564 - val_accuracy: 0.9033\n",
      "Epoch 198/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2434 - accuracy: 0.9297 - val_loss: 0.3552 - val_accuracy: 0.9032\n",
      "Epoch 199/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2440 - accuracy: 0.9297 - val_loss: 0.3560 - val_accuracy: 0.9032\n",
      "Epoch 200/200\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.2440 - accuracy: 0.9294 - val_loss: 0.3471 - val_accuracy: 0.9060\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=200, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 5s 2ms/step - loss: 0.3471 - accuracy: 0.9060\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9722302e-01, 5.2048022e-06, 7.6227222e-04, ..., 8.1538758e-08,\n",
       "        5.8626416e-08, 5.5952199e-07],\n",
       "       [8.9352396e-15, 1.1071333e-09, 4.2660583e-18, ..., 1.2395338e-08,\n",
       "        1.4978834e-08, 2.2969914e-05],\n",
       "       [9.3918198e-01, 4.5768232e-03, 4.8911413e-03, ..., 3.8002022e-06,\n",
       "        4.8292040e-05, 2.2427760e-06],\n",
       "       ...,\n",
       "       [6.2086731e-03, 3.0960196e-05, 1.2569953e-07, ..., 8.9303037e-10,\n",
       "        2.2562835e-08, 2.2459441e-12],\n",
       "       [9.8862213e-01, 1.3487826e-03, 5.0786249e-03, ..., 1.0041124e-05,\n",
       "        3.3236560e-05, 1.8059818e-06],\n",
       "       [7.6659540e-05, 2.3876812e-06, 2.4686719e-06, ..., 1.5373917e-10,\n",
       "        2.6251030e-07, 5.6712600e-11]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1af7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
