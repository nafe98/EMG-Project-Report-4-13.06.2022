{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363000</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126905</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118497</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308858</th>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107934</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "363000  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0415  0.0928   \n",
       "126905  0.0024  0.0024  0.0513  0.0269  0.0024  0.0024  0.0684  0.0977   \n",
       "118497  0.0049  0.2026  0.0464  0.0024  0.0024  0.0024  0.0635  0.0659   \n",
       "308858  0.0928  0.0610  0.1465  0.1074  0.0073  0.0073  0.2271  0.2124   \n",
       "107934  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "363000  0.1440  0.0244           0             0         0           0  \n",
       "126905  0.0024  0.0342           1             1         4           4  \n",
       "118497  0.1929  0.1587           1             1         3           3  \n",
       "308858  0.0586  0.0586           6             6         7           7  \n",
       "107934  0.0024  0.0024           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential    \n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(48, input_dim=input_dim, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(192, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(96, activation='softmax'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 48)                528       \n",
      "                                                                 \n",
      " batch_normalization_124 (Ba  (None, 48)               192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 96)                4704      \n",
      "                                                                 \n",
      " batch_normalization_125 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_126 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 192)               18624     \n",
      "                                                                 \n",
      " batch_normalization_127 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 192)               37056     \n",
      "                                                                 \n",
      " batch_normalization_128 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 24)                4632      \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 192)               4800      \n",
      "                                                                 \n",
      " batch_normalization_129 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 192)               37056     \n",
      "                                                                 \n",
      " batch_normalization_130 (Ba  (None, 192)              768       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 96)                18528     \n",
      "                                                                 \n",
      " batch_normalization_131 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 96)                9312      \n",
      "                                                                 \n",
      " batch_normalization_132 (Ba  (None, 96)               384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 48)                4656      \n",
      "                                                                 \n",
      " batch_normalization_133 (Ba  (None, 48)               192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 24)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,376\n",
      "Trainable params: 152,880\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 4s 20ms/step - loss: 1.5595 - accuracy: 0.6136 - val_loss: 2.9039 - val_accuracy: 0.5284\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 1.0396 - accuracy: 0.7319 - val_loss: 2.7097 - val_accuracy: 0.5284\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.8414 - accuracy: 0.7753 - val_loss: 2.5880 - val_accuracy: 0.5284\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.7364 - accuracy: 0.8000 - val_loss: 2.5082 - val_accuracy: 0.5284\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.6757 - accuracy: 0.8135 - val_loss: 2.4386 - val_accuracy: 0.5284\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.6307 - accuracy: 0.8242 - val_loss: 2.3654 - val_accuracy: 0.5284\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.5888 - accuracy: 0.8341 - val_loss: 2.3648 - val_accuracy: 0.5284\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.5614 - accuracy: 0.8412 - val_loss: 2.3113 - val_accuracy: 0.5409\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.5419 - accuracy: 0.8459 - val_loss: 1.9462 - val_accuracy: 0.5966\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.5182 - accuracy: 0.8512 - val_loss: 1.4966 - val_accuracy: 0.7056\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.5054 - accuracy: 0.8548 - val_loss: 1.2263 - val_accuracy: 0.6432\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.4862 - accuracy: 0.8596 - val_loss: 0.5936 - val_accuracy: 0.8402\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.4772 - accuracy: 0.8620 - val_loss: 0.5712 - val_accuracy: 0.8503\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.4644 - accuracy: 0.8652 - val_loss: 0.5132 - val_accuracy: 0.8534\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.4491 - accuracy: 0.8696 - val_loss: 0.4920 - val_accuracy: 0.8592\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.4385 - accuracy: 0.8728 - val_loss: 0.4883 - val_accuracy: 0.8616\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.4287 - accuracy: 0.8755 - val_loss: 0.4883 - val_accuracy: 0.8618\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.4204 - accuracy: 0.8777 - val_loss: 0.4890 - val_accuracy: 0.8657\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.4116 - accuracy: 0.8804 - val_loss: 0.4749 - val_accuracy: 0.8685\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.4056 - accuracy: 0.8816 - val_loss: 0.4829 - val_accuracy: 0.8653\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.3963 - accuracy: 0.8849 - val_loss: 0.4583 - val_accuracy: 0.8726\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.3880 - accuracy: 0.8863 - val_loss: 0.4425 - val_accuracy: 0.8736\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3804 - accuracy: 0.8892 - val_loss: 0.4357 - val_accuracy: 0.8738\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3775 - accuracy: 0.8900 - val_loss: 0.4471 - val_accuracy: 0.8744\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3746 - accuracy: 0.8908 - val_loss: 0.4414 - val_accuracy: 0.8756\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3618 - accuracy: 0.8944 - val_loss: 0.4316 - val_accuracy: 0.8757\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3569 - accuracy: 0.8954 - val_loss: 0.4394 - val_accuracy: 0.8754\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3532 - accuracy: 0.8967 - val_loss: 0.4135 - val_accuracy: 0.8814\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3478 - accuracy: 0.8979 - val_loss: 0.4227 - val_accuracy: 0.8803\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3482 - accuracy: 0.8982 - val_loss: 0.4172 - val_accuracy: 0.8831\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3404 - accuracy: 0.8998 - val_loss: 0.4138 - val_accuracy: 0.8842\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3338 - accuracy: 0.9027 - val_loss: 0.4120 - val_accuracy: 0.8835\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3328 - accuracy: 0.9026 - val_loss: 0.3984 - val_accuracy: 0.8870\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3275 - accuracy: 0.9039 - val_loss: 0.4077 - val_accuracy: 0.8843\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3306 - accuracy: 0.9032 - val_loss: 0.4099 - val_accuracy: 0.8846\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3170 - accuracy: 0.9075 - val_loss: 0.4052 - val_accuracy: 0.8850\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3176 - accuracy: 0.9071 - val_loss: 0.3890 - val_accuracy: 0.8918\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.3135 - accuracy: 0.9081 - val_loss: 0.4269 - val_accuracy: 0.8827\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3163 - accuracy: 0.9073 - val_loss: 0.3937 - val_accuracy: 0.8891\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.3078 - accuracy: 0.9100 - val_loss: 0.3922 - val_accuracy: 0.8883\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.3042 - accuracy: 0.9113 - val_loss: 0.3803 - val_accuracy: 0.8927\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.3000 - accuracy: 0.9120 - val_loss: 0.3841 - val_accuracy: 0.8927\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2985 - accuracy: 0.9124 - val_loss: 0.3830 - val_accuracy: 0.8933\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2961 - accuracy: 0.9131 - val_loss: 0.3938 - val_accuracy: 0.8920\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2912 - accuracy: 0.9153 - val_loss: 0.3765 - val_accuracy: 0.8958\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2893 - accuracy: 0.9154 - val_loss: 0.3748 - val_accuracy: 0.8953\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2886 - accuracy: 0.9160 - val_loss: 0.3919 - val_accuracy: 0.8935\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2876 - accuracy: 0.9160 - val_loss: 0.3797 - val_accuracy: 0.8948\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2852 - accuracy: 0.9167 - val_loss: 0.3679 - val_accuracy: 0.8963\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2823 - accuracy: 0.9175 - val_loss: 0.3829 - val_accuracy: 0.8956\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2759 - accuracy: 0.9198 - val_loss: 0.3823 - val_accuracy: 0.8988\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2752 - accuracy: 0.9197 - val_loss: 0.3759 - val_accuracy: 0.8968\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2728 - accuracy: 0.9205 - val_loss: 0.3732 - val_accuracy: 0.8974\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2729 - accuracy: 0.9206 - val_loss: 0.3661 - val_accuracy: 0.8975\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2704 - accuracy: 0.9212 - val_loss: 0.3636 - val_accuracy: 0.8992\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2697 - accuracy: 0.9214 - val_loss: 0.3592 - val_accuracy: 0.8994\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2651 - accuracy: 0.9229 - val_loss: 0.3703 - val_accuracy: 0.8993\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2650 - accuracy: 0.9232 - val_loss: 0.3888 - val_accuracy: 0.8989\n",
      "Epoch 59/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2638 - accuracy: 0.9232 - val_loss: 0.3634 - val_accuracy: 0.9009\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2586 - accuracy: 0.9247 - val_loss: 0.3594 - val_accuracy: 0.9010\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2646 - accuracy: 0.9228 - val_loss: 0.3743 - val_accuracy: 0.8962\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2581 - accuracy: 0.9249 - val_loss: 0.3666 - val_accuracy: 0.8997\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2518 - accuracy: 0.9272 - val_loss: 0.3647 - val_accuracy: 0.8995\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2570 - accuracy: 0.9249 - val_loss: 0.3555 - val_accuracy: 0.9002\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2531 - accuracy: 0.9263 - val_loss: 0.3596 - val_accuracy: 0.9022\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2515 - accuracy: 0.9268 - val_loss: 0.3520 - val_accuracy: 0.9039\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2501 - accuracy: 0.9272 - val_loss: 0.3500 - val_accuracy: 0.9048\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2435 - accuracy: 0.9296 - val_loss: 0.3387 - val_accuracy: 0.9051\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2465 - accuracy: 0.9284 - val_loss: 0.3678 - val_accuracy: 0.8982\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2454 - accuracy: 0.9289 - val_loss: 0.3503 - val_accuracy: 0.9062\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2428 - accuracy: 0.9299 - val_loss: 0.3593 - val_accuracy: 0.9026\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2461 - accuracy: 0.9286 - val_loss: 0.3686 - val_accuracy: 0.9018\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2483 - accuracy: 0.9276 - val_loss: 0.3765 - val_accuracy: 0.9006\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2439 - accuracy: 0.9294 - val_loss: 0.4209 - val_accuracy: 0.8771\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2391 - accuracy: 0.9307 - val_loss: 0.3578 - val_accuracy: 0.9047\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2386 - accuracy: 0.9310 - val_loss: 0.3446 - val_accuracy: 0.9067\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2357 - accuracy: 0.9316 - val_loss: 0.3376 - val_accuracy: 0.9080\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2337 - accuracy: 0.9324 - val_loss: 0.3402 - val_accuracy: 0.9059\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2316 - accuracy: 0.9329 - val_loss: 0.3445 - val_accuracy: 0.9047\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2376 - accuracy: 0.9313 - val_loss: 0.3468 - val_accuracy: 0.9061\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2326 - accuracy: 0.9329 - val_loss: 0.3353 - val_accuracy: 0.9092\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2297 - accuracy: 0.9336 - val_loss: 0.3387 - val_accuracy: 0.9076\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2295 - accuracy: 0.9338 - val_loss: 0.3564 - val_accuracy: 0.9068\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2334 - accuracy: 0.9321 - val_loss: 0.3459 - val_accuracy: 0.9051\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2285 - accuracy: 0.9339 - val_loss: 0.3483 - val_accuracy: 0.9063\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2270 - accuracy: 0.9343 - val_loss: 0.3323 - val_accuracy: 0.9089\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2244 - accuracy: 0.9354 - val_loss: 0.3376 - val_accuracy: 0.9096\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2221 - accuracy: 0.9359 - val_loss: 0.3344 - val_accuracy: 0.9097\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2229 - accuracy: 0.9357 - val_loss: 0.3523 - val_accuracy: 0.9086\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2243 - accuracy: 0.9353 - val_loss: 0.3437 - val_accuracy: 0.9087\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2206 - accuracy: 0.9366 - val_loss: 0.3300 - val_accuracy: 0.9110\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2192 - accuracy: 0.9366 - val_loss: 0.3398 - val_accuracy: 0.9083\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2168 - accuracy: 0.9375 - val_loss: 0.3372 - val_accuracy: 0.9093\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2220 - accuracy: 0.9361 - val_loss: 0.3330 - val_accuracy: 0.9123\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2177 - accuracy: 0.9376 - val_loss: 0.3456 - val_accuracy: 0.9110\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2176 - accuracy: 0.9373 - val_loss: 0.3397 - val_accuracy: 0.9106\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2177 - accuracy: 0.9373 - val_loss: 0.3375 - val_accuracy: 0.9110\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2139 - accuracy: 0.9387 - val_loss: 0.3229 - val_accuracy: 0.9134\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2119 - accuracy: 0.9390 - val_loss: 0.3467 - val_accuracy: 0.9121\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2158 - accuracy: 0.9381 - val_loss: 0.3441 - val_accuracy: 0.9085\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2125 - accuracy: 0.9390 - val_loss: 0.3490 - val_accuracy: 0.9103\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2125 - accuracy: 0.9389 - val_loss: 0.3320 - val_accuracy: 0.9114\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2157 - accuracy: 0.9377 - val_loss: 0.3283 - val_accuracy: 0.9127\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2163 - accuracy: 0.9377 - val_loss: 0.3483 - val_accuracy: 0.9119\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2086 - accuracy: 0.9399 - val_loss: 0.3316 - val_accuracy: 0.9131\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2073 - accuracy: 0.9405 - val_loss: 0.3208 - val_accuracy: 0.9143\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2071 - accuracy: 0.9405 - val_loss: 0.3441 - val_accuracy: 0.9096\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2101 - accuracy: 0.9393 - val_loss: 0.3372 - val_accuracy: 0.9126\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2083 - accuracy: 0.9403 - val_loss: 0.3290 - val_accuracy: 0.9130\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.2064 - accuracy: 0.9406 - val_loss: 0.3294 - val_accuracy: 0.9146\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2069 - accuracy: 0.9403 - val_loss: 0.3352 - val_accuracy: 0.9108\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2050 - accuracy: 0.9409 - val_loss: 0.3311 - val_accuracy: 0.9123\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2067 - accuracy: 0.9409 - val_loss: 0.3501 - val_accuracy: 0.9132\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2031 - accuracy: 0.9415 - val_loss: 0.3370 - val_accuracy: 0.9144\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2047 - accuracy: 0.9410 - val_loss: 0.3420 - val_accuracy: 0.9121\n",
      "Epoch 116/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1986 - accuracy: 0.9432 - val_loss: 0.3982 - val_accuracy: 0.8898\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2017 - accuracy: 0.9422 - val_loss: 0.3247 - val_accuracy: 0.9157\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2007 - accuracy: 0.9424 - val_loss: 0.3203 - val_accuracy: 0.9153\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2014 - accuracy: 0.9427 - val_loss: 0.3262 - val_accuracy: 0.9150\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2026 - accuracy: 0.9422 - val_loss: 0.3366 - val_accuracy: 0.9152\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.2031 - accuracy: 0.9414 - val_loss: 0.3381 - val_accuracy: 0.9105\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.2009 - accuracy: 0.9424 - val_loss: 0.3262 - val_accuracy: 0.9153\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1974 - accuracy: 0.9434 - val_loss: 0.3227 - val_accuracy: 0.9150\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1964 - accuracy: 0.9440 - val_loss: 0.3272 - val_accuracy: 0.9163\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1957 - accuracy: 0.9439 - val_loss: 0.3302 - val_accuracy: 0.9142\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1970 - accuracy: 0.9435 - val_loss: 0.3406 - val_accuracy: 0.9142\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1984 - accuracy: 0.9428 - val_loss: 0.3166 - val_accuracy: 0.9169\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1969 - accuracy: 0.9435 - val_loss: 0.3212 - val_accuracy: 0.9165\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1973 - accuracy: 0.9434 - val_loss: 0.3467 - val_accuracy: 0.9103\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1938 - accuracy: 0.9444 - val_loss: 0.3144 - val_accuracy: 0.9181\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1923 - accuracy: 0.9451 - val_loss: 0.3291 - val_accuracy: 0.9169\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1947 - accuracy: 0.9444 - val_loss: 0.3513 - val_accuracy: 0.9079\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1937 - accuracy: 0.9446 - val_loss: 0.3207 - val_accuracy: 0.9191\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1937 - accuracy: 0.9445 - val_loss: 0.3630 - val_accuracy: 0.9058\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1942 - accuracy: 0.9446 - val_loss: 0.3339 - val_accuracy: 0.9145\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1900 - accuracy: 0.9455 - val_loss: 0.3199 - val_accuracy: 0.9177\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1881 - accuracy: 0.9463 - val_loss: 0.3306 - val_accuracy: 0.9150\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1899 - accuracy: 0.9457 - val_loss: 0.3336 - val_accuracy: 0.9163\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1880 - accuracy: 0.9460 - val_loss: 0.3153 - val_accuracy: 0.9190\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1875 - accuracy: 0.9464 - val_loss: 0.3401 - val_accuracy: 0.9135\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1889 - accuracy: 0.9458 - val_loss: 0.3257 - val_accuracy: 0.9159\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1975 - accuracy: 0.9430 - val_loss: 0.3476 - val_accuracy: 0.9135\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1926 - accuracy: 0.9449 - val_loss: 0.3460 - val_accuracy: 0.9130\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1866 - accuracy: 0.9469 - val_loss: 0.3161 - val_accuracy: 0.9185\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1850 - accuracy: 0.9471 - val_loss: 0.3230 - val_accuracy: 0.9175\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.1856 - accuracy: 0.9472 - val_loss: 0.3271 - val_accuracy: 0.9190\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1841 - accuracy: 0.9476 - val_loss: 0.3284 - val_accuracy: 0.9194\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1856 - accuracy: 0.9473 - val_loss: 0.3286 - val_accuracy: 0.9180\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1852 - accuracy: 0.9471 - val_loss: 0.3308 - val_accuracy: 0.9150\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1884 - accuracy: 0.9461 - val_loss: 0.3231 - val_accuracy: 0.9171\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1833 - accuracy: 0.9479 - val_loss: 0.3172 - val_accuracy: 0.9192\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1850 - accuracy: 0.9473 - val_loss: 0.3276 - val_accuracy: 0.9181\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1812 - accuracy: 0.9483 - val_loss: 0.3186 - val_accuracy: 0.9187\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1818 - accuracy: 0.9481 - val_loss: 0.3354 - val_accuracy: 0.9145\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9467 - val_loss: 0.3201 - val_accuracy: 0.9187\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1849 - accuracy: 0.9476 - val_loss: 0.3242 - val_accuracy: 0.9176\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1831 - accuracy: 0.9477 - val_loss: 0.3344 - val_accuracy: 0.9169\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1808 - accuracy: 0.9485 - val_loss: 0.3203 - val_accuracy: 0.9192\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1813 - accuracy: 0.9484 - val_loss: 0.3333 - val_accuracy: 0.9180\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1813 - accuracy: 0.9486 - val_loss: 0.3206 - val_accuracy: 0.9201\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1809 - accuracy: 0.9489 - val_loss: 0.3180 - val_accuracy: 0.9182\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1821 - accuracy: 0.9479 - val_loss: 0.3230 - val_accuracy: 0.9183\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1788 - accuracy: 0.9492 - val_loss: 0.3223 - val_accuracy: 0.9195\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1762 - accuracy: 0.9499 - val_loss: 0.3109 - val_accuracy: 0.9220\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1789 - accuracy: 0.9495 - val_loss: 0.3239 - val_accuracy: 0.9182\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1762 - accuracy: 0.9499 - val_loss: 0.3273 - val_accuracy: 0.9182\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1772 - accuracy: 0.9494 - val_loss: 0.3164 - val_accuracy: 0.9207\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1749 - accuracy: 0.9502 - val_loss: 0.3200 - val_accuracy: 0.9190\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1809 - accuracy: 0.9486 - val_loss: 0.3207 - val_accuracy: 0.9184\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1777 - accuracy: 0.9492 - val_loss: 0.3607 - val_accuracy: 0.9088\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1752 - accuracy: 0.9502 - val_loss: 0.3279 - val_accuracy: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1755 - accuracy: 0.9502 - val_loss: 0.3339 - val_accuracy: 0.9200\n",
      "Epoch 173/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1770 - accuracy: 0.9497 - val_loss: 0.3361 - val_accuracy: 0.9180\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1741 - accuracy: 0.9507 - val_loss: 0.3200 - val_accuracy: 0.9197\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1745 - accuracy: 0.9503 - val_loss: 0.3314 - val_accuracy: 0.9158\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1761 - accuracy: 0.9499 - val_loss: 0.3202 - val_accuracy: 0.9206\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1767 - accuracy: 0.9496 - val_loss: 0.3293 - val_accuracy: 0.9180\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1733 - accuracy: 0.9506 - val_loss: 0.3094 - val_accuracy: 0.9216\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1736 - accuracy: 0.9508 - val_loss: 0.3157 - val_accuracy: 0.9200\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1716 - accuracy: 0.9512 - val_loss: 0.3216 - val_accuracy: 0.9185\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1726 - accuracy: 0.9509 - val_loss: 0.3481 - val_accuracy: 0.9186\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1700 - accuracy: 0.9519 - val_loss: 0.3246 - val_accuracy: 0.9195\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1723 - accuracy: 0.9511 - val_loss: 0.3191 - val_accuracy: 0.9214\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1772 - accuracy: 0.9496 - val_loss: 0.3344 - val_accuracy: 0.9172\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1718 - accuracy: 0.9513 - val_loss: 0.3542 - val_accuracy: 0.9106\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1742 - accuracy: 0.9505 - val_loss: 0.3250 - val_accuracy: 0.9188\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1759 - accuracy: 0.9502 - val_loss: 0.3266 - val_accuracy: 0.9176\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1727 - accuracy: 0.9507 - val_loss: 0.3189 - val_accuracy: 0.9197\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1685 - accuracy: 0.9521 - val_loss: 0.3201 - val_accuracy: 0.9208\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1716 - accuracy: 0.9511 - val_loss: 0.3145 - val_accuracy: 0.9213\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1721 - accuracy: 0.9510 - val_loss: 0.3140 - val_accuracy: 0.9232\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1661 - accuracy: 0.9530 - val_loss: 0.3277 - val_accuracy: 0.9197\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1675 - accuracy: 0.9528 - val_loss: 0.3190 - val_accuracy: 0.9204\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1669 - accuracy: 0.9527 - val_loss: 0.3177 - val_accuracy: 0.9240\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1673 - accuracy: 0.9528 - val_loss: 0.3195 - val_accuracy: 0.9211\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1670 - accuracy: 0.9531 - val_loss: 0.3119 - val_accuracy: 0.9239\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1687 - accuracy: 0.9525 - val_loss: 0.3254 - val_accuracy: 0.9200\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1679 - accuracy: 0.9528 - val_loss: 0.3189 - val_accuracy: 0.9230\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1676 - accuracy: 0.9525 - val_loss: 0.3433 - val_accuracy: 0.9190\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1688 - accuracy: 0.9522 - val_loss: 0.3272 - val_accuracy: 0.9210\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1687 - accuracy: 0.9521 - val_loss: 0.3218 - val_accuracy: 0.9198\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1619 - accuracy: 0.9540 - val_loss: 0.3198 - val_accuracy: 0.9233\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1634 - accuracy: 0.9538 - val_loss: 0.3155 - val_accuracy: 0.9231\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1664 - accuracy: 0.9529 - val_loss: 0.3259 - val_accuracy: 0.9218\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1703 - accuracy: 0.9517 - val_loss: 0.3237 - val_accuracy: 0.9202\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1647 - accuracy: 0.9537 - val_loss: 0.3946 - val_accuracy: 0.8954\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1649 - accuracy: 0.9535 - val_loss: 0.3168 - val_accuracy: 0.9228\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1655 - accuracy: 0.9533 - val_loss: 0.3283 - val_accuracy: 0.9213\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1674 - accuracy: 0.9526 - val_loss: 0.3276 - val_accuracy: 0.9193\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1620 - accuracy: 0.9546 - val_loss: 0.3282 - val_accuracy: 0.9219\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1654 - accuracy: 0.9532 - val_loss: 0.3161 - val_accuracy: 0.9225\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1619 - accuracy: 0.9542 - val_loss: 0.3292 - val_accuracy: 0.9190\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1635 - accuracy: 0.9536 - val_loss: 0.3235 - val_accuracy: 0.9208\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1660 - accuracy: 0.9528 - val_loss: 0.3560 - val_accuracy: 0.9179\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1647 - accuracy: 0.9531 - val_loss: 0.3319 - val_accuracy: 0.9184\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1637 - accuracy: 0.9539 - val_loss: 0.3091 - val_accuracy: 0.9249\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1595 - accuracy: 0.9547 - val_loss: 0.3234 - val_accuracy: 0.9224\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1599 - accuracy: 0.9550 - val_loss: 0.3231 - val_accuracy: 0.9238\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1641 - accuracy: 0.9540 - val_loss: 0.3254 - val_accuracy: 0.9209\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1622 - accuracy: 0.9540 - val_loss: 0.3122 - val_accuracy: 0.9246\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1605 - accuracy: 0.9548 - val_loss: 0.3414 - val_accuracy: 0.9215\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1616 - accuracy: 0.9543 - val_loss: 0.3359 - val_accuracy: 0.9224\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1616 - accuracy: 0.9545 - val_loss: 0.3244 - val_accuracy: 0.9234\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1602 - accuracy: 0.9551 - val_loss: 0.3127 - val_accuracy: 0.9238\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1592 - accuracy: 0.9550 - val_loss: 0.3264 - val_accuracy: 0.9204\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1642 - accuracy: 0.9536 - val_loss: 0.3232 - val_accuracy: 0.9220\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1618 - accuracy: 0.9542 - val_loss: 0.3365 - val_accuracy: 0.9185\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1598 - accuracy: 0.9549 - val_loss: 0.3235 - val_accuracy: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1570 - accuracy: 0.9556 - val_loss: 0.3172 - val_accuracy: 0.9228\n",
      "Epoch 230/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1570 - accuracy: 0.9558 - val_loss: 0.3187 - val_accuracy: 0.9243\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1550 - accuracy: 0.9564 - val_loss: 0.3235 - val_accuracy: 0.9223\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1568 - accuracy: 0.9559 - val_loss: 0.3215 - val_accuracy: 0.9238\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1559 - accuracy: 0.9561 - val_loss: 0.3387 - val_accuracy: 0.9217\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1570 - accuracy: 0.9558 - val_loss: 0.3125 - val_accuracy: 0.9242\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1551 - accuracy: 0.9561 - val_loss: 0.3332 - val_accuracy: 0.9223\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1562 - accuracy: 0.9561 - val_loss: 0.3127 - val_accuracy: 0.9239\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1558 - accuracy: 0.9561 - val_loss: 0.3295 - val_accuracy: 0.9198\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1594 - accuracy: 0.9552 - val_loss: 0.3531 - val_accuracy: 0.9121\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1573 - accuracy: 0.9555 - val_loss: 0.3236 - val_accuracy: 0.9227\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.1575 - accuracy: 0.9554 - val_loss: 0.3326 - val_accuracy: 0.9221\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1572 - accuracy: 0.9553 - val_loss: 0.3188 - val_accuracy: 0.9244\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1564 - accuracy: 0.9559 - val_loss: 0.3255 - val_accuracy: 0.9242\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1580 - accuracy: 0.9557 - val_loss: 0.3263 - val_accuracy: 0.9211\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1571 - accuracy: 0.9558 - val_loss: 0.3248 - val_accuracy: 0.9246\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1561 - accuracy: 0.9559 - val_loss: 0.3383 - val_accuracy: 0.9220\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.1516 - accuracy: 0.9574 - val_loss: 0.3131 - val_accuracy: 0.9247\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1547 - accuracy: 0.9560 - val_loss: 0.3222 - val_accuracy: 0.9232\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1583 - accuracy: 0.9552 - val_loss: 0.3172 - val_accuracy: 0.9243\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1552 - accuracy: 0.9561 - val_loss: 0.3155 - val_accuracy: 0.9240\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1534 - accuracy: 0.9570 - val_loss: 0.3756 - val_accuracy: 0.9048\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1554 - accuracy: 0.9560 - val_loss: 0.3549 - val_accuracy: 0.9111\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1537 - accuracy: 0.9566 - val_loss: 0.3211 - val_accuracy: 0.9236\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1538 - accuracy: 0.9566 - val_loss: 0.3282 - val_accuracy: 0.9242\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1557 - accuracy: 0.9560 - val_loss: 0.3310 - val_accuracy: 0.9239\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1537 - accuracy: 0.9568 - val_loss: 0.3249 - val_accuracy: 0.9223\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1527 - accuracy: 0.9570 - val_loss: 0.3262 - val_accuracy: 0.9240\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1508 - accuracy: 0.9577 - val_loss: 0.3206 - val_accuracy: 0.9252\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1525 - accuracy: 0.9571 - val_loss: 0.3662 - val_accuracy: 0.9114\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1570 - accuracy: 0.9557 - val_loss: 0.3256 - val_accuracy: 0.9238\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1549 - accuracy: 0.9561 - val_loss: 0.3193 - val_accuracy: 0.9224\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1551 - accuracy: 0.9561 - val_loss: 0.3288 - val_accuracy: 0.9242\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1539 - accuracy: 0.9567 - val_loss: 0.3637 - val_accuracy: 0.9088\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1491 - accuracy: 0.9580 - val_loss: 0.3166 - val_accuracy: 0.9241\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1489 - accuracy: 0.9582 - val_loss: 0.3149 - val_accuracy: 0.9245\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1527 - accuracy: 0.9568 - val_loss: 0.3317 - val_accuracy: 0.9241\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.1488 - accuracy: 0.9583 - val_loss: 0.3267 - val_accuracy: 0.9235\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1516 - accuracy: 0.9577 - val_loss: 0.3138 - val_accuracy: 0.9262\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 0.3296 - val_accuracy: 0.9202\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1510 - accuracy: 0.9577 - val_loss: 0.3348 - val_accuracy: 0.9227\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1530 - accuracy: 0.9569 - val_loss: 0.3281 - val_accuracy: 0.9235\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1537 - accuracy: 0.9566 - val_loss: 0.3236 - val_accuracy: 0.9233\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1510 - accuracy: 0.9575 - val_loss: 0.3109 - val_accuracy: 0.9245\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1500 - accuracy: 0.9579 - val_loss: 0.3428 - val_accuracy: 0.9179\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1473 - accuracy: 0.9589 - val_loss: 0.3211 - val_accuracy: 0.9270\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1464 - accuracy: 0.9589 - val_loss: 0.3256 - val_accuracy: 0.9253\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1492 - accuracy: 0.9578 - val_loss: 0.3302 - val_accuracy: 0.9231\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1523 - accuracy: 0.9570 - val_loss: 0.3449 - val_accuracy: 0.9218\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1516 - accuracy: 0.9575 - val_loss: 0.3315 - val_accuracy: 0.9251\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1467 - accuracy: 0.9589 - val_loss: 0.3280 - val_accuracy: 0.9230\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1464 - accuracy: 0.9587 - val_loss: 0.3410 - val_accuracy: 0.9235\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1460 - accuracy: 0.9588 - val_loss: 0.3316 - val_accuracy: 0.9234\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1483 - accuracy: 0.9586 - val_loss: 0.3076 - val_accuracy: 0.9272\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1466 - accuracy: 0.9587 - val_loss: 0.3248 - val_accuracy: 0.9244\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1461 - accuracy: 0.9589 - val_loss: 0.3266 - val_accuracy: 0.9225\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1507 - accuracy: 0.9574 - val_loss: 0.3388 - val_accuracy: 0.9218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1493 - accuracy: 0.9579 - val_loss: 0.3303 - val_accuracy: 0.9235\n",
      "Epoch 287/300\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1476 - accuracy: 0.9585 - val_loss: 0.3265 - val_accuracy: 0.9247\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1473 - accuracy: 0.9583 - val_loss: 0.3370 - val_accuracy: 0.9216\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1495 - accuracy: 0.9582 - val_loss: 0.3343 - val_accuracy: 0.9224\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1479 - accuracy: 0.9584 - val_loss: 0.3317 - val_accuracy: 0.9258\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1447 - accuracy: 0.9594 - val_loss: 0.3311 - val_accuracy: 0.9250\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1436 - accuracy: 0.9597 - val_loss: 0.3219 - val_accuracy: 0.9258\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1489 - accuracy: 0.9581 - val_loss: 0.3252 - val_accuracy: 0.9226\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1479 - accuracy: 0.9580 - val_loss: 0.3247 - val_accuracy: 0.9262\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1433 - accuracy: 0.9599 - val_loss: 0.3155 - val_accuracy: 0.9263\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1430 - accuracy: 0.9601 - val_loss: 0.3233 - val_accuracy: 0.9247\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1480 - accuracy: 0.9582 - val_loss: 0.3285 - val_accuracy: 0.9240\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 0.1443 - accuracy: 0.9596 - val_loss: 0.3449 - val_accuracy: 0.9240\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1478 - accuracy: 0.9584 - val_loss: 0.3302 - val_accuracy: 0.9250\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.1427 - accuracy: 0.9600 - val_loss: 0.3355 - val_accuracy: 0.9260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 8s 3ms/step - loss: 0.3355 - accuracy: 0.9260\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98801589e-01, 1.49738862e-05, 3.48264875e-05, ...,\n",
       "        6.30669774e-08, 3.68270108e-08, 1.92971790e-08],\n",
       "       [1.81902646e-14, 1.34743995e-11, 3.87696636e-15, ...,\n",
       "        1.82911242e-14, 2.36850973e-11, 9.54664264e-11],\n",
       "       [9.63529468e-01, 5.35674533e-03, 1.15804677e-03, ...,\n",
       "        6.14926250e-07, 4.46558306e-06, 1.86560180e-06],\n",
       "       ...,\n",
       "       [1.68841190e-08, 1.02127595e-09, 1.45769681e-12, ...,\n",
       "        1.03293201e-13, 6.87753348e-13, 8.84596148e-14],\n",
       "       [9.92164969e-01, 5.49235498e-04, 2.41557416e-03, ...,\n",
       "        7.22335187e-07, 5.38337531e-07, 1.13147225e-08],\n",
       "       [3.69385613e-14, 9.59914856e-11, 1.91866389e-09, ...,\n",
       "        1.59642433e-09, 4.38899846e-14, 2.27471335e-13]], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3168ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
