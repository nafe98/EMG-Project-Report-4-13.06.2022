{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230825</th>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205408</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113331</th>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156006</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420019</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "230825  0.7983  0.0513  0.8862  0.8032  0.1025  0.1343  0.6738  0.5249   \n",
       "205408  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0220  0.0903   \n",
       "113331  0.1489  0.9351  0.1294  0.0073  0.0024  0.0293  1.7554  0.3931   \n",
       "156006  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342  0.0610   \n",
       "420019  0.0024  0.0049  0.0171  0.0024  0.0024  0.0024  0.0049  0.1270   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "230825  0.8887  0.0757           5             5        16          16  \n",
       "205408  0.0024  0.0439           5             0        13          13  \n",
       "113331  0.4272  1.2085           5             5         2           2  \n",
       "156006  0.0024  0.1221           6             0         7           7  \n",
       "420019  0.0757  0.0122           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(input_dim,))\n",
    "hidden1 = Dense(6000, activation='relu')(visible)\n",
    "hidden2 = Dense(3000, activation='relu')(hidden1)\n",
    "hidden3 = Dropout(0.2)(hidden2)\n",
    "hidden4 = Dense(1500, activation='relu')(hidden3)\n",
    "hidden5 = Dense(750, activation='relu')(hidden4)\n",
    "hidden6 = Dropout(0.2)(hidden5)\n",
    "hidden7 = Dense(48, activation='relu')(hidden6)\n",
    "output = Dense(num_classes, activation='softmax')(hidden7)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 6000)              66000     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 3000)              18003000  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1500)              4501500   \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 750)               1125750   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 750)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 48)                36048     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 24)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,733,474\n",
      "Trainable params: 23,733,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 1.3918 - accuracy: 0.6395 - val_loss: 0.9473 - val_accuracy: 0.7470\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 6s 86ms/step - loss: 0.8393 - accuracy: 0.7712 - val_loss: 0.7222 - val_accuracy: 0.8002\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.6778 - accuracy: 0.8097 - val_loss: 0.6209 - val_accuracy: 0.8250\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.5891 - accuracy: 0.8322 - val_loss: 0.5399 - val_accuracy: 0.8457\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.5468 - accuracy: 0.8434 - val_loss: 0.4963 - val_accuracy: 0.8568\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.4967 - accuracy: 0.8562 - val_loss: 0.4646 - val_accuracy: 0.8655\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 6s 87ms/step - loss: 0.4674 - accuracy: 0.8648 - val_loss: 0.4362 - val_accuracy: 0.8744\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.4398 - accuracy: 0.8726 - val_loss: 0.4114 - val_accuracy: 0.8814\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.4143 - accuracy: 0.8795 - val_loss: 0.3984 - val_accuracy: 0.8861\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.4020 - accuracy: 0.8834 - val_loss: 0.3947 - val_accuracy: 0.8865\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 7s 87ms/step - loss: 0.3820 - accuracy: 0.8890 - val_loss: 0.3738 - val_accuracy: 0.8938\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.3658 - accuracy: 0.8933 - val_loss: 0.3559 - val_accuracy: 0.8968\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.3554 - accuracy: 0.8963 - val_loss: 0.3467 - val_accuracy: 0.9004\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.3391 - accuracy: 0.9011 - val_loss: 0.3321 - val_accuracy: 0.9043\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.3336 - accuracy: 0.9035 - val_loss: 0.3231 - val_accuracy: 0.9053\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.3225 - accuracy: 0.9067 - val_loss: 0.3283 - val_accuracy: 0.9069\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.3102 - accuracy: 0.9097 - val_loss: 0.3106 - val_accuracy: 0.9104\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.3085 - accuracy: 0.9106 - val_loss: 0.3014 - val_accuracy: 0.9134\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2969 - accuracy: 0.9142 - val_loss: 0.3015 - val_accuracy: 0.9134\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2904 - accuracy: 0.9161 - val_loss: 0.2998 - val_accuracy: 0.9147\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2819 - accuracy: 0.9181 - val_loss: 0.2853 - val_accuracy: 0.9195\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2766 - accuracy: 0.9200 - val_loss: 0.2928 - val_accuracy: 0.9172\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2733 - accuracy: 0.9213 - val_loss: 0.2866 - val_accuracy: 0.9185\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2699 - accuracy: 0.9224 - val_loss: 0.2808 - val_accuracy: 0.9202\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2641 - accuracy: 0.9240 - val_loss: 0.2732 - val_accuracy: 0.9218\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2612 - accuracy: 0.9248 - val_loss: 0.2730 - val_accuracy: 0.9226\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2510 - accuracy: 0.9277 - val_loss: 0.2737 - val_accuracy: 0.9219\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2530 - accuracy: 0.9271 - val_loss: 0.2705 - val_accuracy: 0.9247\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2506 - accuracy: 0.9285 - val_loss: 0.2625 - val_accuracy: 0.9260\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2442 - accuracy: 0.9298 - val_loss: 0.2559 - val_accuracy: 0.9286\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2367 - accuracy: 0.9321 - val_loss: 0.2538 - val_accuracy: 0.9287\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2346 - accuracy: 0.9328 - val_loss: 0.2597 - val_accuracy: 0.9276\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2363 - accuracy: 0.9323 - val_loss: 0.2514 - val_accuracy: 0.9292\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2311 - accuracy: 0.9337 - val_loss: 0.2546 - val_accuracy: 0.9286\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2289 - accuracy: 0.9348 - val_loss: 0.2478 - val_accuracy: 0.9305\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.2243 - accuracy: 0.9359 - val_loss: 0.2468 - val_accuracy: 0.9314\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.2329 - accuracy: 0.9346 - val_loss: 0.3037 - val_accuracy: 0.9176\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2355 - accuracy: 0.9329 - val_loss: 0.2433 - val_accuracy: 0.9320\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2181 - accuracy: 0.9377 - val_loss: 0.2468 - val_accuracy: 0.9323\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2147 - accuracy: 0.9388 - val_loss: 0.2432 - val_accuracy: 0.9321\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.2110 - accuracy: 0.9396 - val_loss: 0.2337 - val_accuracy: 0.9343\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2325 - accuracy: 0.9348 - val_loss: 0.2397 - val_accuracy: 0.9332\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2080 - accuracy: 0.9406 - val_loss: 0.2356 - val_accuracy: 0.9354\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2048 - accuracy: 0.9417 - val_loss: 0.2366 - val_accuracy: 0.9352\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2045 - accuracy: 0.9420 - val_loss: 0.2365 - val_accuracy: 0.9347\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2038 - accuracy: 0.9418 - val_loss: 0.2346 - val_accuracy: 0.9350\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1999 - accuracy: 0.9429 - val_loss: 0.2284 - val_accuracy: 0.9374\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1972 - accuracy: 0.9434 - val_loss: 0.2370 - val_accuracy: 0.9350\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2024 - accuracy: 0.9428 - val_loss: 0.2335 - val_accuracy: 0.9350\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.2018 - accuracy: 0.9427 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1940 - accuracy: 0.9447 - val_loss: 0.2315 - val_accuracy: 0.9367\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1961 - accuracy: 0.9443 - val_loss: 0.2256 - val_accuracy: 0.9388\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1895 - accuracy: 0.9459 - val_loss: 0.2300 - val_accuracy: 0.9363\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2616 - accuracy: 0.9296 - val_loss: 0.2673 - val_accuracy: 0.9272\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.2200 - accuracy: 0.9378 - val_loss: 0.2302 - val_accuracy: 0.9357\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1977 - accuracy: 0.9442 - val_loss: 0.2352 - val_accuracy: 0.9357\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1916 - accuracy: 0.9459 - val_loss: 0.2286 - val_accuracy: 0.9377\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1869 - accuracy: 0.9472 - val_loss: 0.2240 - val_accuracy: 0.9385\n",
      "Epoch 59/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1850 - accuracy: 0.9479 - val_loss: 0.2253 - val_accuracy: 0.9387\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1836 - accuracy: 0.9482 - val_loss: 0.2205 - val_accuracy: 0.9399\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1814 - accuracy: 0.9490 - val_loss: 0.2299 - val_accuracy: 0.9388\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1817 - accuracy: 0.9488 - val_loss: 0.2264 - val_accuracy: 0.9388\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1814 - accuracy: 0.9488 - val_loss: 0.2181 - val_accuracy: 0.9409\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1796 - accuracy: 0.9494 - val_loss: 0.2214 - val_accuracy: 0.9399\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1783 - accuracy: 0.9495 - val_loss: 0.2199 - val_accuracy: 0.9407\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1769 - accuracy: 0.9500 - val_loss: 0.2254 - val_accuracy: 0.9398\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1791 - accuracy: 0.9493 - val_loss: 0.2184 - val_accuracy: 0.9411\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1722 - accuracy: 0.9511 - val_loss: 0.2203 - val_accuracy: 0.9415\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1732 - accuracy: 0.9512 - val_loss: 0.2201 - val_accuracy: 0.9415\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1756 - accuracy: 0.9505 - val_loss: 0.2156 - val_accuracy: 0.9422\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1723 - accuracy: 0.9514 - val_loss: 0.2203 - val_accuracy: 0.9412\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1758 - accuracy: 0.9502 - val_loss: 0.2187 - val_accuracy: 0.9415\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1707 - accuracy: 0.9519 - val_loss: 0.2202 - val_accuracy: 0.9418\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1702 - accuracy: 0.9520 - val_loss: 0.2210 - val_accuracy: 0.9408\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.2179 - val_accuracy: 0.9432\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1654 - accuracy: 0.9537 - val_loss: 0.2216 - val_accuracy: 0.9417\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1711 - accuracy: 0.9519 - val_loss: 0.2179 - val_accuracy: 0.9437\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1652 - accuracy: 0.9535 - val_loss: 0.2165 - val_accuracy: 0.9430\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 7s 93ms/step - loss: 0.1636 - accuracy: 0.9537 - val_loss: 0.2212 - val_accuracy: 0.9430\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1666 - accuracy: 0.9531 - val_loss: 0.2146 - val_accuracy: 0.9436\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1632 - accuracy: 0.9543 - val_loss: 0.2203 - val_accuracy: 0.9425\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1637 - accuracy: 0.9540 - val_loss: 0.2203 - val_accuracy: 0.9431\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1659 - accuracy: 0.9533 - val_loss: 0.2159 - val_accuracy: 0.9438\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1612 - accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.9428\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1595 - accuracy: 0.9551 - val_loss: 0.2224 - val_accuracy: 0.9429\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1587 - accuracy: 0.9552 - val_loss: 0.2201 - val_accuracy: 0.9428\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1589 - accuracy: 0.9552 - val_loss: 0.2171 - val_accuracy: 0.9426\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1559 - accuracy: 0.9563 - val_loss: 0.2157 - val_accuracy: 0.9445\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1551 - accuracy: 0.9563 - val_loss: 0.2201 - val_accuracy: 0.9440\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1551 - accuracy: 0.9560 - val_loss: 0.2105 - val_accuracy: 0.9452\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1546 - accuracy: 0.9567 - val_loss: 0.2141 - val_accuracy: 0.9446\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1561 - accuracy: 0.9561 - val_loss: 0.2153 - val_accuracy: 0.9461\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1571 - accuracy: 0.9558 - val_loss: 0.2166 - val_accuracy: 0.9438\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1517 - accuracy: 0.9570 - val_loss: 0.2144 - val_accuracy: 0.9445\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1509 - accuracy: 0.9574 - val_loss: 0.2121 - val_accuracy: 0.9458\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1494 - accuracy: 0.9579 - val_loss: 0.2114 - val_accuracy: 0.9453\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 0.2122 - val_accuracy: 0.9457\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1503 - accuracy: 0.9575 - val_loss: 0.2181 - val_accuracy: 0.9445\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1504 - accuracy: 0.9577 - val_loss: 0.2180 - val_accuracy: 0.9458\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1497 - accuracy: 0.9580 - val_loss: 0.2090 - val_accuracy: 0.9459\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1492 - accuracy: 0.9580 - val_loss: 0.2098 - val_accuracy: 0.9458\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1680 - accuracy: 0.9530 - val_loss: 0.2102 - val_accuracy: 0.9454\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1502 - accuracy: 0.9574 - val_loss: 0.2140 - val_accuracy: 0.9454\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1483 - accuracy: 0.9585 - val_loss: 0.2181 - val_accuracy: 0.9448\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1472 - accuracy: 0.9586 - val_loss: 0.2082 - val_accuracy: 0.9462\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1497 - accuracy: 0.9577 - val_loss: 0.2138 - val_accuracy: 0.9445\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1451 - accuracy: 0.9591 - val_loss: 0.2159 - val_accuracy: 0.9456\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1451 - accuracy: 0.9590 - val_loss: 0.2136 - val_accuracy: 0.9457\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1445 - accuracy: 0.9594 - val_loss: 0.2114 - val_accuracy: 0.9471\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1454 - accuracy: 0.9588 - val_loss: 0.2133 - val_accuracy: 0.9465\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1466 - accuracy: 0.9586 - val_loss: 0.2145 - val_accuracy: 0.9462\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1439 - accuracy: 0.9593 - val_loss: 0.2204 - val_accuracy: 0.9458\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 7s 94ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.2178 - val_accuracy: 0.9460\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 7s 93ms/step - loss: 0.1434 - accuracy: 0.9595 - val_loss: 0.2119 - val_accuracy: 0.9472\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1431 - accuracy: 0.9593 - val_loss: 0.2205 - val_accuracy: 0.9455\n",
      "Epoch 116/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1433 - accuracy: 0.9593 - val_loss: 0.2150 - val_accuracy: 0.9468\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1422 - accuracy: 0.9597 - val_loss: 0.2095 - val_accuracy: 0.9471\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1381 - accuracy: 0.9612 - val_loss: 0.2152 - val_accuracy: 0.9470\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.2284 - accuracy: 0.9396 - val_loss: 0.2329 - val_accuracy: 0.9406\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1594 - accuracy: 0.9549 - val_loss: 0.2172 - val_accuracy: 0.9453\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1443 - accuracy: 0.9592 - val_loss: 0.2148 - val_accuracy: 0.9467\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1385 - accuracy: 0.9610 - val_loss: 0.2108 - val_accuracy: 0.9468\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1397 - accuracy: 0.9611 - val_loss: 0.2115 - val_accuracy: 0.9462\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1357 - accuracy: 0.9616 - val_loss: 0.2111 - val_accuracy: 0.9482\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1357 - accuracy: 0.9618 - val_loss: 0.2138 - val_accuracy: 0.9456\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1346 - accuracy: 0.9621 - val_loss: 0.2132 - val_accuracy: 0.9470\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1355 - accuracy: 0.9618 - val_loss: 0.2147 - val_accuracy: 0.9483\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1352 - accuracy: 0.9617 - val_loss: 0.2119 - val_accuracy: 0.9474\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1319 - accuracy: 0.9628 - val_loss: 0.2118 - val_accuracy: 0.9483\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1318 - accuracy: 0.9626 - val_loss: 0.2149 - val_accuracy: 0.9475\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1354 - accuracy: 0.9619 - val_loss: 0.2159 - val_accuracy: 0.9466\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1351 - accuracy: 0.9621 - val_loss: 0.2186 - val_accuracy: 0.9473\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1332 - accuracy: 0.9624 - val_loss: 0.2115 - val_accuracy: 0.9478\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1317 - accuracy: 0.9624 - val_loss: 0.2157 - val_accuracy: 0.9479\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1334 - accuracy: 0.9623 - val_loss: 0.2146 - val_accuracy: 0.9484\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1326 - accuracy: 0.9627 - val_loss: 0.2180 - val_accuracy: 0.9470\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1335 - accuracy: 0.9626 - val_loss: 0.2233 - val_accuracy: 0.9468\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1320 - accuracy: 0.9629 - val_loss: 0.2143 - val_accuracy: 0.9487\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1299 - accuracy: 0.9637 - val_loss: 0.2097 - val_accuracy: 0.9489\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1316 - accuracy: 0.9628 - val_loss: 0.2142 - val_accuracy: 0.9483\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1306 - accuracy: 0.9635 - val_loss: 0.2171 - val_accuracy: 0.9481\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1275 - accuracy: 0.9640 - val_loss: 0.2147 - val_accuracy: 0.9489\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1276 - accuracy: 0.9639 - val_loss: 0.2201 - val_accuracy: 0.9481\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1314 - accuracy: 0.9628 - val_loss: 0.2176 - val_accuracy: 0.9472\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1304 - accuracy: 0.9632 - val_loss: 0.2147 - val_accuracy: 0.9480\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1288 - accuracy: 0.9637 - val_loss: 0.2121 - val_accuracy: 0.9483\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1607 - accuracy: 0.9560 - val_loss: 0.2146 - val_accuracy: 0.9467\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1321 - accuracy: 0.9627 - val_loss: 0.2118 - val_accuracy: 0.9488\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1300 - accuracy: 0.9633 - val_loss: 0.2146 - val_accuracy: 0.9479\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1292 - accuracy: 0.9638 - val_loss: 0.2216 - val_accuracy: 0.9477\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1259 - accuracy: 0.9646 - val_loss: 0.2143 - val_accuracy: 0.9484\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1282 - accuracy: 0.9641 - val_loss: 0.2133 - val_accuracy: 0.9488\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1265 - accuracy: 0.9644 - val_loss: 0.2195 - val_accuracy: 0.9487\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1258 - accuracy: 0.9644 - val_loss: 0.2081 - val_accuracy: 0.9496\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1248 - accuracy: 0.9651 - val_loss: 0.2174 - val_accuracy: 0.9492\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1236 - accuracy: 0.9651 - val_loss: 0.2176 - val_accuracy: 0.9492\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1237 - accuracy: 0.9650 - val_loss: 0.2139 - val_accuracy: 0.9490\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.1241 - accuracy: 0.9650 - val_loss: 0.2184 - val_accuracy: 0.9486\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.1229 - accuracy: 0.9652 - val_loss: 0.2145 - val_accuracy: 0.9494\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.1234 - accuracy: 0.9651 - val_loss: 0.2179 - val_accuracy: 0.9493\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1241 - accuracy: 0.9651 - val_loss: 0.2145 - val_accuracy: 0.9496\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1245 - accuracy: 0.9647 - val_loss: 0.2153 - val_accuracy: 0.9497\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1262 - accuracy: 0.9643 - val_loss: 0.2126 - val_accuracy: 0.9497\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1201 - accuracy: 0.9659 - val_loss: 0.2148 - val_accuracy: 0.9498\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1243 - accuracy: 0.9650 - val_loss: 0.2174 - val_accuracy: 0.9495\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1230 - accuracy: 0.9651 - val_loss: 0.2171 - val_accuracy: 0.9485\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1242 - accuracy: 0.9647 - val_loss: 0.2153 - val_accuracy: 0.9499\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1223 - accuracy: 0.9652 - val_loss: 0.2187 - val_accuracy: 0.9485\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1231 - accuracy: 0.9651 - val_loss: 0.2174 - val_accuracy: 0.9500\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1218 - accuracy: 0.9657 - val_loss: 0.2212 - val_accuracy: 0.9491\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1198 - accuracy: 0.9663 - val_loss: 0.2169 - val_accuracy: 0.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1192 - accuracy: 0.9665 - val_loss: 0.2211 - val_accuracy: 0.9498\n",
      "Epoch 173/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1251 - accuracy: 0.9648 - val_loss: 0.2197 - val_accuracy: 0.9502\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 7s 96ms/step - loss: 0.1188 - accuracy: 0.9665 - val_loss: 0.2186 - val_accuracy: 0.9502\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1188 - accuracy: 0.9665 - val_loss: 0.2187 - val_accuracy: 0.9493\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1187 - accuracy: 0.9664 - val_loss: 0.2205 - val_accuracy: 0.9502\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1191 - accuracy: 0.9660 - val_loss: 0.2213 - val_accuracy: 0.9496\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1194 - accuracy: 0.9664 - val_loss: 0.2180 - val_accuracy: 0.9499\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1197 - accuracy: 0.9662 - val_loss: 0.2189 - val_accuracy: 0.9493\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1183 - accuracy: 0.9662 - val_loss: 0.2183 - val_accuracy: 0.9491\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1184 - accuracy: 0.9663 - val_loss: 0.2224 - val_accuracy: 0.9483\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1170 - accuracy: 0.9669 - val_loss: 0.2197 - val_accuracy: 0.9506\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1155 - accuracy: 0.9672 - val_loss: 0.2265 - val_accuracy: 0.9493\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1200 - accuracy: 0.9660 - val_loss: 0.2329 - val_accuracy: 0.9485\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.1192 - accuracy: 0.9662 - val_loss: 0.2242 - val_accuracy: 0.9489\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.1194 - accuracy: 0.9663 - val_loss: 0.2170 - val_accuracy: 0.9498\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1154 - accuracy: 0.9673 - val_loss: 0.2194 - val_accuracy: 0.9492\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1147 - accuracy: 0.9675 - val_loss: 0.2227 - val_accuracy: 0.9493\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 7s 94ms/step - loss: 0.1152 - accuracy: 0.9672 - val_loss: 0.2213 - val_accuracy: 0.9493\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1172 - accuracy: 0.9668 - val_loss: 0.2231 - val_accuracy: 0.9493\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.1149 - accuracy: 0.9674 - val_loss: 0.2234 - val_accuracy: 0.9497\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1156 - accuracy: 0.9675 - val_loss: 0.2201 - val_accuracy: 0.9497\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1157 - accuracy: 0.9671 - val_loss: 0.2251 - val_accuracy: 0.9500\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1169 - accuracy: 0.9670 - val_loss: 0.2250 - val_accuracy: 0.9489\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1155 - accuracy: 0.9671 - val_loss: 0.2266 - val_accuracy: 0.9499\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1133 - accuracy: 0.9677 - val_loss: 0.2196 - val_accuracy: 0.9500\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1132 - accuracy: 0.9677 - val_loss: 0.2246 - val_accuracy: 0.9493\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1161 - accuracy: 0.9671 - val_loss: 0.2239 - val_accuracy: 0.9490\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1612 - accuracy: 0.9574 - val_loss: 0.2394 - val_accuracy: 0.9404\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1345 - accuracy: 0.9619 - val_loss: 0.2193 - val_accuracy: 0.9496\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1171 - accuracy: 0.9666 - val_loss: 0.2184 - val_accuracy: 0.9500\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1148 - accuracy: 0.9674 - val_loss: 0.2251 - val_accuracy: 0.9492\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 7s 96ms/step - loss: 0.1136 - accuracy: 0.9678 - val_loss: 0.2215 - val_accuracy: 0.9499\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1105 - accuracy: 0.9684 - val_loss: 0.2269 - val_accuracy: 0.9500\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1125 - accuracy: 0.9681 - val_loss: 0.2159 - val_accuracy: 0.9511\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1120 - accuracy: 0.9682 - val_loss: 0.2270 - val_accuracy: 0.9486\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.2267 - val_accuracy: 0.9492\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1124 - accuracy: 0.9680 - val_loss: 0.2217 - val_accuracy: 0.9503\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1108 - accuracy: 0.9683 - val_loss: 0.2243 - val_accuracy: 0.9508\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1107 - accuracy: 0.9684 - val_loss: 0.2269 - val_accuracy: 0.9501\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1124 - accuracy: 0.9678 - val_loss: 0.2256 - val_accuracy: 0.9496\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1102 - accuracy: 0.9690 - val_loss: 0.2217 - val_accuracy: 0.9516\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1100 - accuracy: 0.9690 - val_loss: 0.2235 - val_accuracy: 0.9499\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1124 - accuracy: 0.9681 - val_loss: 0.2252 - val_accuracy: 0.9494\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.2269 - val_accuracy: 0.9505\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.2209 - val_accuracy: 0.9503\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1069 - accuracy: 0.9696 - val_loss: 0.2263 - val_accuracy: 0.9502\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1073 - accuracy: 0.9694 - val_loss: 0.2242 - val_accuracy: 0.9508\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1081 - accuracy: 0.9692 - val_loss: 0.2256 - val_accuracy: 0.9513\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1068 - accuracy: 0.9695 - val_loss: 0.2297 - val_accuracy: 0.9504\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1112 - accuracy: 0.9684 - val_loss: 0.2230 - val_accuracy: 0.9503\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1096 - accuracy: 0.9687 - val_loss: 0.2263 - val_accuracy: 0.9500\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1102 - accuracy: 0.9684 - val_loss: 0.2269 - val_accuracy: 0.9504\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1361 - accuracy: 0.9626 - val_loss: 0.2345 - val_accuracy: 0.9454\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1178 - accuracy: 0.9660 - val_loss: 0.2281 - val_accuracy: 0.9497\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1087 - accuracy: 0.9692 - val_loss: 0.2252 - val_accuracy: 0.9501\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1089 - accuracy: 0.9690 - val_loss: 0.2300 - val_accuracy: 0.9499\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1089 - accuracy: 0.9689 - val_loss: 0.2301 - val_accuracy: 0.9502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1061 - accuracy: 0.9697 - val_loss: 0.2313 - val_accuracy: 0.9510\n",
      "Epoch 230/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1078 - accuracy: 0.9695 - val_loss: 0.2309 - val_accuracy: 0.9497\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1085 - accuracy: 0.9691 - val_loss: 0.2252 - val_accuracy: 0.9508\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1063 - accuracy: 0.9699 - val_loss: 0.2355 - val_accuracy: 0.9506\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1069 - accuracy: 0.9696 - val_loss: 0.2301 - val_accuracy: 0.9511\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1062 - accuracy: 0.9697 - val_loss: 0.2332 - val_accuracy: 0.9507\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1054 - accuracy: 0.9700 - val_loss: 0.2310 - val_accuracy: 0.9496\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1089 - accuracy: 0.9692 - val_loss: 0.2270 - val_accuracy: 0.9508\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1032 - accuracy: 0.9704 - val_loss: 0.2278 - val_accuracy: 0.9513\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1052 - accuracy: 0.9700 - val_loss: 0.2265 - val_accuracy: 0.9511\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1029 - accuracy: 0.9707 - val_loss: 0.2275 - val_accuracy: 0.9510\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1037 - accuracy: 0.9705 - val_loss: 0.2321 - val_accuracy: 0.9507\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1056 - accuracy: 0.9699 - val_loss: 0.2331 - val_accuracy: 0.9502\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1041 - accuracy: 0.9702 - val_loss: 0.2332 - val_accuracy: 0.9500\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1047 - accuracy: 0.9699 - val_loss: 0.2331 - val_accuracy: 0.9503\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1060 - accuracy: 0.9696 - val_loss: 0.2341 - val_accuracy: 0.9503\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1077 - accuracy: 0.9692 - val_loss: 0.2300 - val_accuracy: 0.9515\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1036 - accuracy: 0.9705 - val_loss: 0.2317 - val_accuracy: 0.9496\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.2336 - val_accuracy: 0.9497\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1047 - accuracy: 0.9698 - val_loss: 0.2312 - val_accuracy: 0.9503\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1024 - accuracy: 0.9706 - val_loss: 0.2339 - val_accuracy: 0.9505\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1048 - accuracy: 0.9701 - val_loss: 0.2297 - val_accuracy: 0.9509\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1041 - accuracy: 0.9703 - val_loss: 0.2361 - val_accuracy: 0.9506\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1058 - accuracy: 0.9695 - val_loss: 0.2340 - val_accuracy: 0.9508\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1053 - accuracy: 0.9698 - val_loss: 0.2327 - val_accuracy: 0.9510\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1069 - accuracy: 0.9696 - val_loss: 0.2351 - val_accuracy: 0.9505\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1059 - accuracy: 0.9699 - val_loss: 0.2308 - val_accuracy: 0.9501\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1037 - accuracy: 0.9703 - val_loss: 0.2323 - val_accuracy: 0.9516\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1041 - accuracy: 0.9703 - val_loss: 0.2314 - val_accuracy: 0.9513\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1032 - accuracy: 0.9704 - val_loss: 0.2308 - val_accuracy: 0.9515\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1013 - accuracy: 0.9710 - val_loss: 0.2320 - val_accuracy: 0.9508\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1020 - accuracy: 0.9709 - val_loss: 0.2303 - val_accuracy: 0.9513\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1009 - accuracy: 0.9709 - val_loss: 0.2334 - val_accuracy: 0.9509\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0996 - accuracy: 0.9714 - val_loss: 0.2301 - val_accuracy: 0.9511\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1038 - accuracy: 0.9703 - val_loss: 0.2378 - val_accuracy: 0.9505\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1004 - accuracy: 0.9714 - val_loss: 0.2353 - val_accuracy: 0.9517\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1009 - accuracy: 0.9712 - val_loss: 0.2317 - val_accuracy: 0.9516\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0993 - accuracy: 0.9715 - val_loss: 0.2336 - val_accuracy: 0.9515\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1005 - accuracy: 0.9710 - val_loss: 0.2348 - val_accuracy: 0.9517\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1003 - accuracy: 0.9713 - val_loss: 0.2345 - val_accuracy: 0.9512\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1054 - accuracy: 0.9704 - val_loss: 0.2462 - val_accuracy: 0.9500\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.2412 - val_accuracy: 0.9510\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.1034 - accuracy: 0.9705 - val_loss: 0.2351 - val_accuracy: 0.9495\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1023 - accuracy: 0.9707 - val_loss: 0.2347 - val_accuracy: 0.9498\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 7s 96ms/step - loss: 0.1027 - accuracy: 0.9705 - val_loss: 0.2332 - val_accuracy: 0.9512\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1022 - accuracy: 0.9708 - val_loss: 0.2382 - val_accuracy: 0.9505\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.0988 - accuracy: 0.9717 - val_loss: 0.2410 - val_accuracy: 0.9507\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0994 - accuracy: 0.9717 - val_loss: 0.2312 - val_accuracy: 0.9508\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.1000 - accuracy: 0.9712 - val_loss: 0.2322 - val_accuracy: 0.9520\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 0.2313 - val_accuracy: 0.9516\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0989 - accuracy: 0.9714 - val_loss: 0.2311 - val_accuracy: 0.9516\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.0984 - accuracy: 0.9717 - val_loss: 0.2378 - val_accuracy: 0.9510\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0997 - accuracy: 0.9715 - val_loss: 0.2360 - val_accuracy: 0.9502\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1000 - accuracy: 0.9715 - val_loss: 0.2375 - val_accuracy: 0.9513\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1016 - accuracy: 0.9709 - val_loss: 0.2383 - val_accuracy: 0.9516\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.2384 - val_accuracy: 0.9505\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.1008 - accuracy: 0.9711 - val_loss: 0.2392 - val_accuracy: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0993 - accuracy: 0.9715 - val_loss: 0.2333 - val_accuracy: 0.9513\n",
      "Epoch 287/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.1040 - accuracy: 0.9703 - val_loss: 0.2348 - val_accuracy: 0.9524\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0986 - accuracy: 0.9717 - val_loss: 0.2374 - val_accuracy: 0.9510\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 7s 91ms/step - loss: 0.0973 - accuracy: 0.9721 - val_loss: 0.2383 - val_accuracy: 0.9521\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0968 - accuracy: 0.9721 - val_loss: 0.2368 - val_accuracy: 0.9523\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0980 - accuracy: 0.9718 - val_loss: 0.2398 - val_accuracy: 0.9508\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0991 - accuracy: 0.9717 - val_loss: 0.2376 - val_accuracy: 0.9507\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0987 - accuracy: 0.9715 - val_loss: 0.2409 - val_accuracy: 0.9511\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 7s 93ms/step - loss: 0.0971 - accuracy: 0.9722 - val_loss: 0.2383 - val_accuracy: 0.9517\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0983 - accuracy: 0.9716 - val_loss: 0.2409 - val_accuracy: 0.9512\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0982 - accuracy: 0.9719 - val_loss: 0.2384 - val_accuracy: 0.9510\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0983 - accuracy: 0.9720 - val_loss: 0.2459 - val_accuracy: 0.9512\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 7s 92ms/step - loss: 0.0976 - accuracy: 0.9718 - val_loss: 0.2435 - val_accuracy: 0.9509\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 0.2357 - val_accuracy: 0.9515\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 7s 90ms/step - loss: 0.0969 - accuracy: 0.9723 - val_loss: 0.2395 - val_accuracy: 0.9518\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 5s 2ms/step - loss: 0.2395 - accuracy: 0.9518\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9888319e-01, 7.7599687e-09, 8.2438200e-06, ..., 3.1452699e-10,\n",
       "        1.1976146e-09, 1.8431401e-09],\n",
       "       [1.2249309e-38, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [9.8174864e-01, 2.5025990e-03, 5.6019810e-05, ..., 9.7371689e-08,\n",
       "        8.7936197e-10, 3.1272403e-08],\n",
       "       ...,\n",
       "       [9.3430941e-08, 4.4309522e-19, 1.4830009e-18, ..., 1.1566554e-18,\n",
       "        6.4325312e-18, 6.8091419e-22],\n",
       "       [9.7403699e-01, 1.2363612e-03, 1.5736772e-02, ..., 7.1943606e-07,\n",
       "        2.7612450e-07, 2.9972088e-07],\n",
       "       [5.6649567e-11, 8.7700572e-15, 9.2748458e-09, ..., 5.1959774e-19,\n",
       "        6.3780950e-15, 1.6337544e-24]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
