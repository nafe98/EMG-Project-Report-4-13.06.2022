{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230825</th>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205408</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113331</th>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156006</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420019</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "230825  0.7983  0.0513  0.8862  0.8032  0.1025  0.1343  0.6738  0.5249   \n",
       "205408  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0220  0.0903   \n",
       "113331  0.1489  0.9351  0.1294  0.0073  0.0024  0.0293  1.7554  0.3931   \n",
       "156006  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342  0.0610   \n",
       "420019  0.0024  0.0049  0.0171  0.0024  0.0024  0.0024  0.0049  0.1270   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "230825  0.8887  0.0757           5             5        16          16  \n",
       "205408  0.0024  0.0439           5             0        13          13  \n",
       "113331  0.4272  1.2085           5             5         2           2  \n",
       "156006  0.0024  0.1221           6             0         7           7  \n",
       "420019  0.0757  0.0122           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(input_dim,))\n",
    "hidden1 = Dense(768, activation='relu')(visible)\n",
    "hidden2 = Dense(384, activation='relu')(hidden1)\n",
    "hidden3 = Dense(384, activation='relu')(hidden2)\n",
    "hidden4 = Dense(192, activation='relu')(hidden3)\n",
    "hidden5 = Dense(192, activation='relu')(hidden4)\n",
    "output = Dense(num_classes, activation='softmax')(hidden5)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 768)               8448      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 384)               295296    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 384)               147840    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 192)               73920     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 192)               37056     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 24)                4632      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,192\n",
      "Trainable params: 567,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 1.4875 - accuracy: 0.6355 - val_loss: 1.0872 - val_accuracy: 0.7101\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.9679 - accuracy: 0.7382 - val_loss: 0.8923 - val_accuracy: 0.7577\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.8259 - accuracy: 0.7751 - val_loss: 0.7799 - val_accuracy: 0.7828\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.7471 - accuracy: 0.7950 - val_loss: 0.7186 - val_accuracy: 0.8004\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.8113 - val_loss: 0.6622 - val_accuracy: 0.8129\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.8215 - val_loss: 0.6226 - val_accuracy: 0.8229\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.8293 - val_loss: 0.6111 - val_accuracy: 0.8273\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.8282 - val_loss: 0.5980 - val_accuracy: 0.8284\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.8417 - val_loss: 0.5640 - val_accuracy: 0.8385\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.8466 - val_loss: 0.5451 - val_accuracy: 0.8427\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.8499 - val_loss: 0.5396 - val_accuracy: 0.8452\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.8530 - val_loss: 0.5199 - val_accuracy: 0.8496\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.8572 - val_loss: 0.5264 - val_accuracy: 0.8489\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.8602 - val_loss: 0.5092 - val_accuracy: 0.8534\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.8644 - val_loss: 0.4988 - val_accuracy: 0.8579\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.8666 - val_loss: 0.4857 - val_accuracy: 0.8621\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.8677 - val_loss: 0.4759 - val_accuracy: 0.8626\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8696 - val_loss: 0.4801 - val_accuracy: 0.8607\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.8734 - val_loss: 0.4624 - val_accuracy: 0.8670\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8749 - val_loss: 0.4583 - val_accuracy: 0.8683\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8773 - val_loss: 0.4536 - val_accuracy: 0.8685\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8795 - val_loss: 0.4374 - val_accuracy: 0.8731\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8821 - val_loss: 0.4321 - val_accuracy: 0.8751\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8845 - val_loss: 0.4524 - val_accuracy: 0.8724\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8838 - val_loss: 0.4269 - val_accuracy: 0.8769\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8882 - val_loss: 0.4169 - val_accuracy: 0.8791\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8886 - val_loss: 0.4168 - val_accuracy: 0.8786\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8905 - val_loss: 0.4130 - val_accuracy: 0.8797\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8911 - val_loss: 0.4083 - val_accuracy: 0.8802\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8918 - val_loss: 0.3982 - val_accuracy: 0.8841\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8936 - val_loss: 0.3992 - val_accuracy: 0.8827\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8955 - val_loss: 0.3956 - val_accuracy: 0.8846\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8973 - val_loss: 0.3823 - val_accuracy: 0.8886\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8980 - val_loss: 0.4043 - val_accuracy: 0.8815\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8980 - val_loss: 0.3843 - val_accuracy: 0.8876\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8997 - val_loss: 0.3863 - val_accuracy: 0.8872\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.9005 - val_loss: 0.3888 - val_accuracy: 0.8878\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.9020 - val_loss: 0.3736 - val_accuracy: 0.8908\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.9038 - val_loss: 0.3760 - val_accuracy: 0.8911\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.9054 - val_loss: 0.3763 - val_accuracy: 0.8905\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.9035 - val_loss: 0.3756 - val_accuracy: 0.8904\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.9046 - val_loss: 0.3854 - val_accuracy: 0.8886\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.9069 - val_loss: 0.3692 - val_accuracy: 0.8931\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.9081 - val_loss: 0.3539 - val_accuracy: 0.8967\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3090 - accuracy: 0.9110 - val_loss: 0.3587 - val_accuracy: 0.8961\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.9100 - val_loss: 0.3723 - val_accuracy: 0.8947\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.9108 - val_loss: 0.3497 - val_accuracy: 0.8985\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.9113 - val_loss: 0.3615 - val_accuracy: 0.8978\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.9118 - val_loss: 0.3452 - val_accuracy: 0.8993\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.3020 - accuracy: 0.9127 - val_loss: 0.3482 - val_accuracy: 0.8985\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.9141 - val_loss: 0.3393 - val_accuracy: 0.9012\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.9148 - val_loss: 0.3382 - val_accuracy: 0.9023\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9151 - val_loss: 0.3479 - val_accuracy: 0.9012\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.9167 - val_loss: 0.3414 - val_accuracy: 0.9015\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.9177 - val_loss: 0.3431 - val_accuracy: 0.9003\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2841 - accuracy: 0.9181 - val_loss: 0.3408 - val_accuracy: 0.9021\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9187 - val_loss: 0.3313 - val_accuracy: 0.9047\n",
      "Epoch 58/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.9187 - val_loss: 0.3271 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.9212 - val_loss: 0.3242 - val_accuracy: 0.9069\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.9218 - val_loss: 0.3298 - val_accuracy: 0.9051\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.9213 - val_loss: 0.3369 - val_accuracy: 0.9047\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.9220 - val_loss: 0.3261 - val_accuracy: 0.9066\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9226 - val_loss: 0.3270 - val_accuracy: 0.9045\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.9228 - val_loss: 0.3225 - val_accuracy: 0.9077\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9225 - val_loss: 0.3229 - val_accuracy: 0.9078\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.9226 - val_loss: 0.3235 - val_accuracy: 0.9076\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.9239 - val_loss: 0.3177 - val_accuracy: 0.9084\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2593 - accuracy: 0.9261 - val_loss: 0.3169 - val_accuracy: 0.9085\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.9255 - val_loss: 0.3248 - val_accuracy: 0.9072\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9263 - val_loss: 0.3135 - val_accuracy: 0.9106\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2539 - accuracy: 0.9281 - val_loss: 0.3172 - val_accuracy: 0.9093\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9285 - val_loss: 0.3272 - val_accuracy: 0.9077\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9283 - val_loss: 0.3133 - val_accuracy: 0.9100\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.9277 - val_loss: 0.3291 - val_accuracy: 0.9069\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.9273 - val_loss: 0.3081 - val_accuracy: 0.9116\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9297 - val_loss: 0.3118 - val_accuracy: 0.9120\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2468 - accuracy: 0.9296 - val_loss: 0.3257 - val_accuracy: 0.9091\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.9292 - val_loss: 0.3150 - val_accuracy: 0.9087\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 0.9301 - val_loss: 0.3019 - val_accuracy: 0.9142\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.9290 - val_loss: 0.3079 - val_accuracy: 0.9124\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9317 - val_loss: 0.2980 - val_accuracy: 0.9154\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9337 - val_loss: 0.2926 - val_accuracy: 0.9174\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9339 - val_loss: 0.3057 - val_accuracy: 0.9167\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9313 - val_loss: 0.3105 - val_accuracy: 0.9117\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9336 - val_loss: 0.3136 - val_accuracy: 0.9114\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9317 - val_loss: 0.3008 - val_accuracy: 0.9158\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9333 - val_loss: 0.2980 - val_accuracy: 0.9152\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2357 - accuracy: 0.9329 - val_loss: 0.2997 - val_accuracy: 0.9151\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.9349 - val_loss: 0.2911 - val_accuracy: 0.9174\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9341 - val_loss: 0.3060 - val_accuracy: 0.9128\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9345 - val_loss: 0.3021 - val_accuracy: 0.9145\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2268 - accuracy: 0.9357 - val_loss: 0.2898 - val_accuracy: 0.9174\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9369 - val_loss: 0.2911 - val_accuracy: 0.9172\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9368 - val_loss: 0.3026 - val_accuracy: 0.9152\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2295 - accuracy: 0.9346 - val_loss: 0.3000 - val_accuracy: 0.9142\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2239 - accuracy: 0.9367 - val_loss: 0.2869 - val_accuracy: 0.9188\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9375 - val_loss: 0.3024 - val_accuracy: 0.9141\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2222 - accuracy: 0.9371 - val_loss: 0.2964 - val_accuracy: 0.9170\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2203 - accuracy: 0.9378 - val_loss: 0.2947 - val_accuracy: 0.9177\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2177 - accuracy: 0.9383 - val_loss: 0.2946 - val_accuracy: 0.9169\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9383 - val_loss: 0.3150 - val_accuracy: 0.9127\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2188 - accuracy: 0.9379 - val_loss: 0.2921 - val_accuracy: 0.9183\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9390 - val_loss: 0.2864 - val_accuracy: 0.9190\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9393 - val_loss: 0.2918 - val_accuracy: 0.9193\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9389 - val_loss: 0.2955 - val_accuracy: 0.9170\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 0.9385 - val_loss: 0.2845 - val_accuracy: 0.9200\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9400 - val_loss: 0.2898 - val_accuracy: 0.9189\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9404 - val_loss: 0.2898 - val_accuracy: 0.9200\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2148 - accuracy: 0.9394 - val_loss: 0.2852 - val_accuracy: 0.9203\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9408 - val_loss: 0.2802 - val_accuracy: 0.9223\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2076 - accuracy: 0.9415 - val_loss: 0.2821 - val_accuracy: 0.9212\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2090 - accuracy: 0.9412 - val_loss: 0.2821 - val_accuracy: 0.9216\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9416 - val_loss: 0.2837 - val_accuracy: 0.9218\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9425 - val_loss: 0.2827 - val_accuracy: 0.9207\n",
      "Epoch 115/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.9422 - val_loss: 0.2847 - val_accuracy: 0.9211\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9412 - val_loss: 0.2935 - val_accuracy: 0.9184\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9424 - val_loss: 0.2839 - val_accuracy: 0.9215\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9431 - val_loss: 0.2825 - val_accuracy: 0.9233\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9419 - val_loss: 0.2972 - val_accuracy: 0.9193\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2037 - accuracy: 0.9424 - val_loss: 0.2853 - val_accuracy: 0.9203\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9442 - val_loss: 0.2841 - val_accuracy: 0.9210\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2009 - accuracy: 0.9434 - val_loss: 0.2806 - val_accuracy: 0.9229\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2006 - accuracy: 0.9433 - val_loss: 0.2855 - val_accuracy: 0.9212\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1997 - accuracy: 0.9437 - val_loss: 0.2809 - val_accuracy: 0.9228\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9445 - val_loss: 0.2830 - val_accuracy: 0.9215\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9430 - val_loss: 0.2927 - val_accuracy: 0.9188\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9432 - val_loss: 0.2870 - val_accuracy: 0.9216\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1957 - accuracy: 0.9447 - val_loss: 0.2757 - val_accuracy: 0.9253\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9439 - val_loss: 0.2986 - val_accuracy: 0.9176\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.2006 - accuracy: 0.9432 - val_loss: 0.2778 - val_accuracy: 0.9238\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1943 - accuracy: 0.9454 - val_loss: 0.2725 - val_accuracy: 0.9248\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9472 - val_loss: 0.2762 - val_accuracy: 0.9235\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9468 - val_loss: 0.2841 - val_accuracy: 0.9231\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1948 - accuracy: 0.9454 - val_loss: 0.2812 - val_accuracy: 0.9234\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9436 - val_loss: 0.2827 - val_accuracy: 0.9232\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9469 - val_loss: 0.2875 - val_accuracy: 0.9223\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1909 - accuracy: 0.9465 - val_loss: 0.2868 - val_accuracy: 0.9225\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9457 - val_loss: 0.2776 - val_accuracy: 0.9242\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9478 - val_loss: 0.2693 - val_accuracy: 0.9263\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9474 - val_loss: 0.2745 - val_accuracy: 0.9249\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1826 - accuracy: 0.9491 - val_loss: 0.2709 - val_accuracy: 0.9247\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9471 - val_loss: 0.2875 - val_accuracy: 0.9233\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1930 - accuracy: 0.9456 - val_loss: 0.2833 - val_accuracy: 0.9232\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1914 - accuracy: 0.9461 - val_loss: 0.2785 - val_accuracy: 0.9242\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9471 - val_loss: 0.2768 - val_accuracy: 0.9247\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1838 - accuracy: 0.9485 - val_loss: 0.2758 - val_accuracy: 0.9258\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1851 - accuracy: 0.9480 - val_loss: 0.2933 - val_accuracy: 0.9203\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9449 - val_loss: 0.2855 - val_accuracy: 0.9239\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9484 - val_loss: 0.2789 - val_accuracy: 0.9244\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9499 - val_loss: 0.2750 - val_accuracy: 0.9257\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1856 - accuracy: 0.9483 - val_loss: 0.2696 - val_accuracy: 0.9274\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 0.9482 - val_loss: 0.2730 - val_accuracy: 0.9268\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.9492 - val_loss: 0.2923 - val_accuracy: 0.9222\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9459 - val_loss: 0.3017 - val_accuracy: 0.9204\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9463 - val_loss: 0.2899 - val_accuracy: 0.9222\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9473 - val_loss: 0.2743 - val_accuracy: 0.9249\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9498 - val_loss: 0.2705 - val_accuracy: 0.9273\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9509 - val_loss: 0.2690 - val_accuracy: 0.9270\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9518 - val_loss: 0.2730 - val_accuracy: 0.9272\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9506 - val_loss: 0.2660 - val_accuracy: 0.9289\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1757 - accuracy: 0.9513 - val_loss: 0.2732 - val_accuracy: 0.9275\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9503 - val_loss: 0.2771 - val_accuracy: 0.9256\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9488 - val_loss: 0.2870 - val_accuracy: 0.9224\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9493 - val_loss: 0.2762 - val_accuracy: 0.9268\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9495 - val_loss: 0.2755 - val_accuracy: 0.9257\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9499 - val_loss: 0.2773 - val_accuracy: 0.9265\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.9494 - val_loss: 0.2863 - val_accuracy: 0.9230\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9506 - val_loss: 0.2686 - val_accuracy: 0.9282\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9521 - val_loss: 0.2682 - val_accuracy: 0.9281\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9510 - val_loss: 0.2715 - val_accuracy: 0.9277\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9519 - val_loss: 0.2682 - val_accuracy: 0.9286\n",
      "Epoch 172/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9518 - val_loss: 0.2818 - val_accuracy: 0.9264\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.9497 - val_loss: 0.2786 - val_accuracy: 0.9265\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1787 - accuracy: 0.9503 - val_loss: 0.2788 - val_accuracy: 0.9259\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9515 - val_loss: 0.2675 - val_accuracy: 0.9295\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9532 - val_loss: 0.2750 - val_accuracy: 0.9265\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9519 - val_loss: 0.2703 - val_accuracy: 0.9287\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9525 - val_loss: 0.2763 - val_accuracy: 0.9279\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9511 - val_loss: 0.2845 - val_accuracy: 0.9258\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9522 - val_loss: 0.2757 - val_accuracy: 0.9300\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9520 - val_loss: 0.2748 - val_accuracy: 0.9277\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9524 - val_loss: 0.2738 - val_accuracy: 0.9275\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9522 - val_loss: 0.2739 - val_accuracy: 0.9277\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.9526 - val_loss: 0.2769 - val_accuracy: 0.9269\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9526 - val_loss: 0.2688 - val_accuracy: 0.9295\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.9523 - val_loss: 0.2749 - val_accuracy: 0.9279\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.9524 - val_loss: 0.2735 - val_accuracy: 0.9269\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.9539 - val_loss: 0.2686 - val_accuracy: 0.9293\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9531 - val_loss: 0.2816 - val_accuracy: 0.9281\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9530 - val_loss: 0.2689 - val_accuracy: 0.9281\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9549 - val_loss: 0.2621 - val_accuracy: 0.9312\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9546 - val_loss: 0.2797 - val_accuracy: 0.9278\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9516 - val_loss: 0.2793 - val_accuracy: 0.9287\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1664 - accuracy: 0.9539 - val_loss: 0.2869 - val_accuracy: 0.9257\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9520 - val_loss: 0.2900 - val_accuracy: 0.9253\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9519 - val_loss: 0.2876 - val_accuracy: 0.9257\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1689 - accuracy: 0.9529 - val_loss: 0.2660 - val_accuracy: 0.9312\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.9557 - val_loss: 0.2662 - val_accuracy: 0.9309\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9563 - val_loss: 0.2714 - val_accuracy: 0.9305\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.9568 - val_loss: 0.2660 - val_accuracy: 0.9308\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9558 - val_loss: 0.2705 - val_accuracy: 0.9298\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9568 - val_loss: 0.2655 - val_accuracy: 0.9312\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9567 - val_loss: 0.2670 - val_accuracy: 0.9308\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.9552 - val_loss: 0.2846 - val_accuracy: 0.9273\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1668 - accuracy: 0.9534 - val_loss: 0.2721 - val_accuracy: 0.9297\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1669 - accuracy: 0.9537 - val_loss: 0.2806 - val_accuracy: 0.9293\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9537 - val_loss: 0.2775 - val_accuracy: 0.9281\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1668 - accuracy: 0.9536 - val_loss: 0.2857 - val_accuracy: 0.9272\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9549 - val_loss: 0.2762 - val_accuracy: 0.9279\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9543 - val_loss: 0.2805 - val_accuracy: 0.9282\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9539 - val_loss: 0.2753 - val_accuracy: 0.9291\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9540 - val_loss: 0.2941 - val_accuracy: 0.9259\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9540 - val_loss: 0.2918 - val_accuracy: 0.9252\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9544 - val_loss: 0.2836 - val_accuracy: 0.9274\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1603 - accuracy: 0.9555 - val_loss: 0.2842 - val_accuracy: 0.9278\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1576 - accuracy: 0.9564 - val_loss: 0.2652 - val_accuracy: 0.9318\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.9565 - val_loss: 0.2707 - val_accuracy: 0.9288\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9561 - val_loss: 0.2828 - val_accuracy: 0.9283\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.9572 - val_loss: 0.2669 - val_accuracy: 0.9306\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 0.9579 - val_loss: 0.2683 - val_accuracy: 0.9323\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9572 - val_loss: 0.2778 - val_accuracy: 0.9299\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9582 - val_loss: 0.2792 - val_accuracy: 0.9308\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.9564 - val_loss: 0.2835 - val_accuracy: 0.9286\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1639 - accuracy: 0.9544 - val_loss: 0.2978 - val_accuracy: 0.9240\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.9534 - val_loss: 0.2807 - val_accuracy: 0.9290\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9563 - val_loss: 0.2816 - val_accuracy: 0.9283\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1547 - accuracy: 0.9574 - val_loss: 0.2693 - val_accuracy: 0.9318\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9570 - val_loss: 0.2787 - val_accuracy: 0.9305\n",
      "Epoch 229/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.9573 - val_loss: 0.2813 - val_accuracy: 0.9312\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1528 - accuracy: 0.9577 - val_loss: 0.2673 - val_accuracy: 0.9319\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.9571 - val_loss: 0.2805 - val_accuracy: 0.9298\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1601 - accuracy: 0.9557 - val_loss: 0.3088 - val_accuracy: 0.9239\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9523 - val_loss: 0.3129 - val_accuracy: 0.9235\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9541 - val_loss: 0.2884 - val_accuracy: 0.9286\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9568 - val_loss: 0.2712 - val_accuracy: 0.9318\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9594 - val_loss: 0.2652 - val_accuracy: 0.9333\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9603 - val_loss: 0.2653 - val_accuracy: 0.9340\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.9606 - val_loss: 0.2701 - val_accuracy: 0.9337\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9590 - val_loss: 0.2711 - val_accuracy: 0.9311\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9593 - val_loss: 0.2730 - val_accuracy: 0.9328\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9589 - val_loss: 0.2732 - val_accuracy: 0.9319\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9586 - val_loss: 0.2803 - val_accuracy: 0.9305\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1572 - accuracy: 0.9566 - val_loss: 0.2945 - val_accuracy: 0.9280\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1684 - accuracy: 0.9528 - val_loss: 0.2859 - val_accuracy: 0.9273\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1579 - accuracy: 0.9560 - val_loss: 0.2752 - val_accuracy: 0.9315\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1495 - accuracy: 0.9587 - val_loss: 0.2826 - val_accuracy: 0.9303\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9577 - val_loss: 0.2823 - val_accuracy: 0.9311\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9579 - val_loss: 0.2781 - val_accuracy: 0.9307\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9587 - val_loss: 0.2739 - val_accuracy: 0.9320\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9578 - val_loss: 0.2749 - val_accuracy: 0.9299\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1469 - accuracy: 0.9598 - val_loss: 0.2738 - val_accuracy: 0.9322\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.9598 - val_loss: 0.2705 - val_accuracy: 0.9328\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.9594 - val_loss: 0.2734 - val_accuracy: 0.9314\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9607 - val_loss: 0.2800 - val_accuracy: 0.9310\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9599 - val_loss: 0.2778 - val_accuracy: 0.9322\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9581 - val_loss: 0.2693 - val_accuracy: 0.9328\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9600 - val_loss: 0.2779 - val_accuracy: 0.9320\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9578 - val_loss: 0.2745 - val_accuracy: 0.9313\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1550 - accuracy: 0.9570 - val_loss: 0.2901 - val_accuracy: 0.9294\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1535 - accuracy: 0.9570 - val_loss: 0.2878 - val_accuracy: 0.9293\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9577 - val_loss: 0.2887 - val_accuracy: 0.9300\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.9585 - val_loss: 0.2794 - val_accuracy: 0.9317\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9588 - val_loss: 0.2899 - val_accuracy: 0.9291\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9602 - val_loss: 0.2744 - val_accuracy: 0.9331\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9609 - val_loss: 0.2770 - val_accuracy: 0.9327\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9608 - val_loss: 0.2766 - val_accuracy: 0.9332\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9599 - val_loss: 0.2963 - val_accuracy: 0.9312\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9595 - val_loss: 0.2752 - val_accuracy: 0.9320\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9598 - val_loss: 0.2855 - val_accuracy: 0.9302\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9609 - val_loss: 0.2728 - val_accuracy: 0.9335\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9601 - val_loss: 0.2885 - val_accuracy: 0.9304\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.9602 - val_loss: 0.2812 - val_accuracy: 0.9318\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.9603 - val_loss: 0.2901 - val_accuracy: 0.9306\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9557 - val_loss: 0.2964 - val_accuracy: 0.9284\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1506 - accuracy: 0.9583 - val_loss: 0.2883 - val_accuracy: 0.9295\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9588 - val_loss: 0.2936 - val_accuracy: 0.9302\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9585 - val_loss: 0.2763 - val_accuracy: 0.9319\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.9595 - val_loss: 0.2840 - val_accuracy: 0.9318\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9606 - val_loss: 0.2777 - val_accuracy: 0.9340\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9602 - val_loss: 0.2815 - val_accuracy: 0.9305\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9620 - val_loss: 0.2746 - val_accuracy: 0.9347\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9611 - val_loss: 0.2827 - val_accuracy: 0.9324\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9590 - val_loss: 0.2850 - val_accuracy: 0.9319\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9605 - val_loss: 0.2776 - val_accuracy: 0.9320\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9624 - val_loss: 0.2724 - val_accuracy: 0.9342\n",
      "Epoch 286/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9616 - val_loss: 0.2786 - val_accuracy: 0.9341\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9603 - val_loss: 0.2834 - val_accuracy: 0.9311\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9605 - val_loss: 0.2827 - val_accuracy: 0.9331\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9611 - val_loss: 0.2807 - val_accuracy: 0.9331\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9601 - val_loss: 0.2923 - val_accuracy: 0.9295\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.9594 - val_loss: 0.2827 - val_accuracy: 0.9312\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9612 - val_loss: 0.2864 - val_accuracy: 0.9312\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.9608 - val_loss: 0.2876 - val_accuracy: 0.9315\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9616 - val_loss: 0.2883 - val_accuracy: 0.9319\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9612 - val_loss: 0.2703 - val_accuracy: 0.9353\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9610 - val_loss: 0.2756 - val_accuracy: 0.9342\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9612 - val_loss: 0.2886 - val_accuracy: 0.9312\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9605 - val_loss: 0.2874 - val_accuracy: 0.9316\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.1413 - accuracy: 0.9611 - val_loss: 0.2835 - val_accuracy: 0.9316\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.9619 - val_loss: 0.2797 - val_accuracy: 0.9341\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 5s 2ms/step - loss: 0.2797 - accuracy: 0.9341\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9275303e-01, 1.3616631e-05, 1.3807783e-03, ..., 2.3818625e-08,\n",
       "        6.8518304e-08, 4.8386478e-10],\n",
       "       [1.1947462e-13, 1.3299005e-35, 3.3202073e-23, ..., 7.9151265e-14,\n",
       "        1.8295718e-19, 1.1064859e-14],\n",
       "       [8.3414096e-01, 1.7443927e-02, 9.4191935e-03, ..., 1.3900648e-09,\n",
       "        1.0652984e-06, 1.9014693e-05],\n",
       "       ...,\n",
       "       [2.4474133e-04, 1.9146828e-06, 6.2104590e-07, ..., 5.3137592e-11,\n",
       "        3.6975422e-08, 6.6825581e-09],\n",
       "       [9.0934199e-01, 2.9233594e-03, 6.8358101e-02, ..., 4.1974619e-08,\n",
       "        1.0052432e-04, 6.0242630e-11],\n",
       "       [1.0129639e-04, 1.0141373e-06, 6.3420017e-03, ..., 1.7558632e-12,\n",
       "        3.8963350e-11, 8.9714130e-12]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
