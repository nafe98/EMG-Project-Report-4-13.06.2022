{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230825</th>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205408</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113331</th>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156006</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420019</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "230825  0.7983  0.0513  0.8862  0.8032  0.1025  0.1343  0.6738  0.5249   \n",
       "205408  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0220  0.0903   \n",
       "113331  0.1489  0.9351  0.1294  0.0073  0.0024  0.0293  1.7554  0.3931   \n",
       "156006  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342  0.0610   \n",
       "420019  0.0024  0.0049  0.0171  0.0024  0.0024  0.0024  0.0049  0.1270   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "230825  0.8887  0.0757           5             5        16          16  \n",
       "205408  0.0024  0.0439           5             0        13          13  \n",
       "113331  0.4272  1.2085           5             5         2           2  \n",
       "156006  0.0024  0.1221           6             0         7           7  \n",
       "420019  0.0757  0.0122           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(input_dim,))\n",
    "hidden1 = Dense(1536, activation='relu')(visible)\n",
    "hidden2 = Dense(786, activation='relu')(hidden1)\n",
    "hidden3 = Dense(384, activation='relu')(hidden2)\n",
    "hidden4 = Dense(384, activation='relu')(hidden3)\n",
    "hidden5 = Dense(192, activation='relu')(hidden4)\n",
    "output = Dense(num_classes, activation='softmax')(hidden5)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1536)              16896     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 786)               1208082   \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 384)               302208    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 384)               147840    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 192)               73920     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 24)                4632      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,753,578\n",
      "Trainable params: 1,753,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 2s 15ms/step - loss: 1.3669 - accuracy: 0.6513 - val_loss: 0.9931 - val_accuracy: 0.7289\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.8811 - accuracy: 0.7605 - val_loss: 0.7941 - val_accuracy: 0.7801\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.7281 - accuracy: 0.7971 - val_loss: 0.6832 - val_accuracy: 0.8073\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.6502 - accuracy: 0.8173 - val_loss: 0.6240 - val_accuracy: 0.8219\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.5983 - accuracy: 0.8298 - val_loss: 0.5831 - val_accuracy: 0.8328\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.5651 - accuracy: 0.8385 - val_loss: 0.5697 - val_accuracy: 0.8388\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.5295 - accuracy: 0.8480 - val_loss: 0.5366 - val_accuracy: 0.8472\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.5072 - accuracy: 0.8544 - val_loss: 0.5241 - val_accuracy: 0.8470\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4866 - accuracy: 0.8595 - val_loss: 0.5033 - val_accuracy: 0.8552\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4728 - accuracy: 0.8625 - val_loss: 0.5001 - val_accuracy: 0.8560\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4567 - accuracy: 0.8680 - val_loss: 0.4676 - val_accuracy: 0.8637\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4398 - accuracy: 0.8723 - val_loss: 0.4565 - val_accuracy: 0.8672\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4368 - accuracy: 0.8738 - val_loss: 0.4532 - val_accuracy: 0.8690\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4123 - accuracy: 0.8801 - val_loss: 0.4474 - val_accuracy: 0.8684\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.4040 - accuracy: 0.8821 - val_loss: 0.4254 - val_accuracy: 0.8775\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3929 - accuracy: 0.8861 - val_loss: 0.4263 - val_accuracy: 0.8750\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3867 - accuracy: 0.8879 - val_loss: 0.4091 - val_accuracy: 0.8809\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3778 - accuracy: 0.8901 - val_loss: 0.4099 - val_accuracy: 0.8797\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3738 - accuracy: 0.8915 - val_loss: 0.3980 - val_accuracy: 0.8834\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3610 - accuracy: 0.8953 - val_loss: 0.3964 - val_accuracy: 0.8859\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3557 - accuracy: 0.8966 - val_loss: 0.3802 - val_accuracy: 0.8891\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3471 - accuracy: 0.8993 - val_loss: 0.3834 - val_accuracy: 0.8876\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3380 - accuracy: 0.9014 - val_loss: 0.3733 - val_accuracy: 0.8914\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3350 - accuracy: 0.9026 - val_loss: 0.3861 - val_accuracy: 0.8877\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3292 - accuracy: 0.9045 - val_loss: 0.3643 - val_accuracy: 0.8939\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.9064 - val_loss: 0.3701 - val_accuracy: 0.8933\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3181 - accuracy: 0.9079 - val_loss: 0.3550 - val_accuracy: 0.8965\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3173 - accuracy: 0.9076 - val_loss: 0.3592 - val_accuracy: 0.8952\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3052 - accuracy: 0.9119 - val_loss: 0.3485 - val_accuracy: 0.8988\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3035 - accuracy: 0.9115 - val_loss: 0.3387 - val_accuracy: 0.9015\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.3016 - accuracy: 0.9123 - val_loss: 0.3590 - val_accuracy: 0.8964\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2978 - accuracy: 0.9137 - val_loss: 0.3405 - val_accuracy: 0.9005\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2906 - accuracy: 0.9162 - val_loss: 0.3380 - val_accuracy: 0.9014\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2883 - accuracy: 0.9166 - val_loss: 0.3310 - val_accuracy: 0.9038\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2816 - accuracy: 0.9186 - val_loss: 0.3295 - val_accuracy: 0.9045\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2765 - accuracy: 0.9204 - val_loss: 0.3292 - val_accuracy: 0.9049\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2751 - accuracy: 0.9205 - val_loss: 0.3483 - val_accuracy: 0.8992\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2767 - accuracy: 0.9200 - val_loss: 0.3180 - val_accuracy: 0.9078\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2669 - accuracy: 0.9231 - val_loss: 0.3276 - val_accuracy: 0.9047\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2633 - accuracy: 0.9245 - val_loss: 0.3126 - val_accuracy: 0.9092\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2609 - accuracy: 0.9254 - val_loss: 0.3226 - val_accuracy: 0.9063\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2600 - accuracy: 0.9254 - val_loss: 0.3036 - val_accuracy: 0.9116\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2597 - accuracy: 0.9253 - val_loss: 0.3165 - val_accuracy: 0.9084\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2533 - accuracy: 0.9271 - val_loss: 0.3071 - val_accuracy: 0.9119\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2498 - accuracy: 0.9282 - val_loss: 0.3005 - val_accuracy: 0.9146\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2490 - accuracy: 0.9287 - val_loss: 0.3132 - val_accuracy: 0.9108\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2444 - accuracy: 0.9296 - val_loss: 0.2993 - val_accuracy: 0.9139\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.2434 - accuracy: 0.9302 - val_loss: 0.2976 - val_accuracy: 0.9147\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.2385 - accuracy: 0.9317 - val_loss: 0.3023 - val_accuracy: 0.9139\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2374 - accuracy: 0.9318 - val_loss: 0.3006 - val_accuracy: 0.9143\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2407 - accuracy: 0.9313 - val_loss: 0.3106 - val_accuracy: 0.9144\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2341 - accuracy: 0.9328 - val_loss: 0.3005 - val_accuracy: 0.9154\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2323 - accuracy: 0.9336 - val_loss: 0.2957 - val_accuracy: 0.9160\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2336 - accuracy: 0.9332 - val_loss: 0.2904 - val_accuracy: 0.9169\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2257 - accuracy: 0.9358 - val_loss: 0.2921 - val_accuracy: 0.9173\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9361 - val_loss: 0.3094 - val_accuracy: 0.9100\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2252 - accuracy: 0.9355 - val_loss: 0.2935 - val_accuracy: 0.9163\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2194 - accuracy: 0.9378 - val_loss: 0.2906 - val_accuracy: 0.9178\n",
      "Epoch 59/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2201 - accuracy: 0.9373 - val_loss: 0.2960 - val_accuracy: 0.9160\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2208 - accuracy: 0.9370 - val_loss: 0.2873 - val_accuracy: 0.9205\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2178 - accuracy: 0.9381 - val_loss: 0.2866 - val_accuracy: 0.9186\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2137 - accuracy: 0.9396 - val_loss: 0.2820 - val_accuracy: 0.9199\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2115 - accuracy: 0.9398 - val_loss: 0.2794 - val_accuracy: 0.9215\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2090 - accuracy: 0.9407 - val_loss: 0.2787 - val_accuracy: 0.9222\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2122 - accuracy: 0.9400 - val_loss: 0.2893 - val_accuracy: 0.9181\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2092 - accuracy: 0.9403 - val_loss: 0.2836 - val_accuracy: 0.9217\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.2087 - accuracy: 0.9409 - val_loss: 0.2825 - val_accuracy: 0.9215\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2062 - accuracy: 0.9416 - val_loss: 0.2798 - val_accuracy: 0.9226\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9426 - val_loss: 0.2811 - val_accuracy: 0.9202\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2046 - accuracy: 0.9424 - val_loss: 0.2839 - val_accuracy: 0.9204\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2038 - accuracy: 0.9421 - val_loss: 0.2744 - val_accuracy: 0.9238\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2029 - accuracy: 0.9422 - val_loss: 0.2704 - val_accuracy: 0.9239\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9426 - val_loss: 0.2804 - val_accuracy: 0.9216\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.2001 - accuracy: 0.9431 - val_loss: 0.2965 - val_accuracy: 0.9179\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1987 - accuracy: 0.9438 - val_loss: 0.2717 - val_accuracy: 0.9251\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.9438 - val_loss: 0.2733 - val_accuracy: 0.9233\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1912 - accuracy: 0.9460 - val_loss: 0.2702 - val_accuracy: 0.9251\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1919 - accuracy: 0.9460 - val_loss: 0.2812 - val_accuracy: 0.9241\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1970 - accuracy: 0.9444 - val_loss: 0.2740 - val_accuracy: 0.9248\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1975 - accuracy: 0.9441 - val_loss: 0.2675 - val_accuracy: 0.9263\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9457 - val_loss: 0.2721 - val_accuracy: 0.9256\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1874 - accuracy: 0.9473 - val_loss: 0.2656 - val_accuracy: 0.9259\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1905 - accuracy: 0.9461 - val_loss: 0.2836 - val_accuracy: 0.9207\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1918 - accuracy: 0.9460 - val_loss: 0.2707 - val_accuracy: 0.9247\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1912 - accuracy: 0.9459 - val_loss: 0.2656 - val_accuracy: 0.9277\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1826 - accuracy: 0.9490 - val_loss: 0.2616 - val_accuracy: 0.9279\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.9489 - val_loss: 0.2615 - val_accuracy: 0.9279\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1812 - accuracy: 0.9492 - val_loss: 0.2633 - val_accuracy: 0.9289\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1788 - accuracy: 0.9498 - val_loss: 0.2671 - val_accuracy: 0.9285\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1851 - accuracy: 0.9484 - val_loss: 0.2667 - val_accuracy: 0.9277\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1850 - accuracy: 0.9479 - val_loss: 0.2629 - val_accuracy: 0.9282\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1795 - accuracy: 0.9496 - val_loss: 0.2542 - val_accuracy: 0.9311\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1738 - accuracy: 0.9515 - val_loss: 0.2804 - val_accuracy: 0.9242\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1760 - accuracy: 0.9506 - val_loss: 0.2584 - val_accuracy: 0.9293\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.9513 - val_loss: 0.2644 - val_accuracy: 0.9277\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1784 - accuracy: 0.9500 - val_loss: 0.2672 - val_accuracy: 0.9276\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1765 - accuracy: 0.9506 - val_loss: 0.2701 - val_accuracy: 0.9270\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1783 - accuracy: 0.9499 - val_loss: 0.2656 - val_accuracy: 0.9269\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9500 - val_loss: 0.2720 - val_accuracy: 0.9262\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1736 - accuracy: 0.9514 - val_loss: 0.2671 - val_accuracy: 0.9278\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1746 - accuracy: 0.9510 - val_loss: 0.2654 - val_accuracy: 0.9288\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9523 - val_loss: 0.2603 - val_accuracy: 0.9304\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1679 - accuracy: 0.9533 - val_loss: 0.2581 - val_accuracy: 0.9314\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1710 - accuracy: 0.9520 - val_loss: 0.2686 - val_accuracy: 0.9276\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9521 - val_loss: 0.2565 - val_accuracy: 0.9309\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1753 - accuracy: 0.9505 - val_loss: 0.2690 - val_accuracy: 0.9277\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1764 - accuracy: 0.9506 - val_loss: 0.2789 - val_accuracy: 0.9277\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9531 - val_loss: 0.2579 - val_accuracy: 0.9315\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1624 - accuracy: 0.9547 - val_loss: 0.2743 - val_accuracy: 0.9303\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1637 - accuracy: 0.9544 - val_loss: 0.2692 - val_accuracy: 0.9280\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1661 - accuracy: 0.9537 - val_loss: 0.2721 - val_accuracy: 0.9292\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1685 - accuracy: 0.9528 - val_loss: 0.2676 - val_accuracy: 0.9293\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.9517 - val_loss: 0.2647 - val_accuracy: 0.9308\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1629 - accuracy: 0.9542 - val_loss: 0.2691 - val_accuracy: 0.9298\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1610 - accuracy: 0.9549 - val_loss: 0.2656 - val_accuracy: 0.9316\n",
      "Epoch 116/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9531 - val_loss: 0.2678 - val_accuracy: 0.9292\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1629 - accuracy: 0.9545 - val_loss: 0.2592 - val_accuracy: 0.9325\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1627 - accuracy: 0.9543 - val_loss: 0.2562 - val_accuracy: 0.9333\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1589 - accuracy: 0.9557 - val_loss: 0.2611 - val_accuracy: 0.9323\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9548 - val_loss: 0.2595 - val_accuracy: 0.9324\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1599 - accuracy: 0.9553 - val_loss: 0.2695 - val_accuracy: 0.9297\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1581 - accuracy: 0.9555 - val_loss: 0.2534 - val_accuracy: 0.9347\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1582 - accuracy: 0.9555 - val_loss: 0.2541 - val_accuracy: 0.9342\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1521 - accuracy: 0.9578 - val_loss: 0.2583 - val_accuracy: 0.9332\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1614 - accuracy: 0.9552 - val_loss: 0.2739 - val_accuracy: 0.9290\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1601 - accuracy: 0.9554 - val_loss: 0.2618 - val_accuracy: 0.9324\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1530 - accuracy: 0.9574 - val_loss: 0.2535 - val_accuracy: 0.9357\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1551 - accuracy: 0.9570 - val_loss: 0.2564 - val_accuracy: 0.9330\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1530 - accuracy: 0.9574 - val_loss: 0.2582 - val_accuracy: 0.9334\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9556 - val_loss: 0.2750 - val_accuracy: 0.9303\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1624 - accuracy: 0.9544 - val_loss: 0.2757 - val_accuracy: 0.9290\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1635 - accuracy: 0.9544 - val_loss: 0.2878 - val_accuracy: 0.9269\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1585 - accuracy: 0.9559 - val_loss: 0.2805 - val_accuracy: 0.9304\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1558 - accuracy: 0.9566 - val_loss: 0.2443 - val_accuracy: 0.9369\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1523 - accuracy: 0.9578 - val_loss: 0.2654 - val_accuracy: 0.9317\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9579 - val_loss: 0.2665 - val_accuracy: 0.9321\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9579 - val_loss: 0.2643 - val_accuracy: 0.9328\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9580 - val_loss: 0.2649 - val_accuracy: 0.9310\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1498 - accuracy: 0.9581 - val_loss: 0.2634 - val_accuracy: 0.9342\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1465 - accuracy: 0.9593 - val_loss: 0.2567 - val_accuracy: 0.9355\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1465 - accuracy: 0.9592 - val_loss: 0.2529 - val_accuracy: 0.9353\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1470 - accuracy: 0.9595 - val_loss: 0.2633 - val_accuracy: 0.9337\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1543 - accuracy: 0.9570 - val_loss: 0.2642 - val_accuracy: 0.9326\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1493 - accuracy: 0.9584 - val_loss: 0.2667 - val_accuracy: 0.9334\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1521 - accuracy: 0.9579 - val_loss: 0.2751 - val_accuracy: 0.9313\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9576 - val_loss: 0.2713 - val_accuracy: 0.9315\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1482 - accuracy: 0.9589 - val_loss: 0.2656 - val_accuracy: 0.9330\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1474 - accuracy: 0.9589 - val_loss: 0.2601 - val_accuracy: 0.9363\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9602 - val_loss: 0.2568 - val_accuracy: 0.9354\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1442 - accuracy: 0.9600 - val_loss: 0.2632 - val_accuracy: 0.9343\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1409 - accuracy: 0.9612 - val_loss: 0.2525 - val_accuracy: 0.9361\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9600 - val_loss: 0.2638 - val_accuracy: 0.9341\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1457 - accuracy: 0.9599 - val_loss: 0.2565 - val_accuracy: 0.9353\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1795 - accuracy: 0.9509 - val_loss: 0.2696 - val_accuracy: 0.9327\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1529 - accuracy: 0.9574 - val_loss: 0.2575 - val_accuracy: 0.9346\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1428 - accuracy: 0.9604 - val_loss: 0.2612 - val_accuracy: 0.9343\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1444 - accuracy: 0.9601 - val_loss: 0.2524 - val_accuracy: 0.9374\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1393 - accuracy: 0.9617 - val_loss: 0.2552 - val_accuracy: 0.9367\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1374 - accuracy: 0.9619 - val_loss: 0.2572 - val_accuracy: 0.9366\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1379 - accuracy: 0.9620 - val_loss: 0.2601 - val_accuracy: 0.9356\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1386 - accuracy: 0.9614 - val_loss: 0.2515 - val_accuracy: 0.9367\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1394 - accuracy: 0.9613 - val_loss: 0.2586 - val_accuracy: 0.9363\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9616 - val_loss: 0.2608 - val_accuracy: 0.9361\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.9620 - val_loss: 0.2619 - val_accuracy: 0.9357\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1434 - accuracy: 0.9599 - val_loss: 0.2724 - val_accuracy: 0.9342\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1442 - accuracy: 0.9596 - val_loss: 0.2673 - val_accuracy: 0.9343\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1422 - accuracy: 0.9606 - val_loss: 0.2653 - val_accuracy: 0.9351\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1439 - accuracy: 0.9603 - val_loss: 0.2615 - val_accuracy: 0.9353\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.2697 - val_accuracy: 0.9339\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1384 - accuracy: 0.9616 - val_loss: 0.2613 - val_accuracy: 0.9377\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1401 - accuracy: 0.9614 - val_loss: 0.2630 - val_accuracy: 0.9350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1338 - accuracy: 0.9628 - val_loss: 0.2664 - val_accuracy: 0.9355\n",
      "Epoch 173/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1346 - accuracy: 0.9630 - val_loss: 0.2752 - val_accuracy: 0.9346\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9608 - val_loss: 0.2609 - val_accuracy: 0.9366\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9628 - val_loss: 0.2677 - val_accuracy: 0.9353\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1330 - accuracy: 0.9631 - val_loss: 0.2650 - val_accuracy: 0.9369\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1363 - accuracy: 0.9621 - val_loss: 0.2751 - val_accuracy: 0.9353\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9587 - val_loss: 0.2746 - val_accuracy: 0.9316\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1424 - accuracy: 0.9603 - val_loss: 0.2706 - val_accuracy: 0.9334\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1422 - accuracy: 0.9603 - val_loss: 0.2742 - val_accuracy: 0.9340\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1383 - accuracy: 0.9615 - val_loss: 0.2616 - val_accuracy: 0.9369\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1317 - accuracy: 0.9634 - val_loss: 0.2654 - val_accuracy: 0.9359\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1367 - accuracy: 0.9620 - val_loss: 0.2716 - val_accuracy: 0.9372\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1331 - accuracy: 0.9633 - val_loss: 0.2699 - val_accuracy: 0.9363\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1288 - accuracy: 0.9645 - val_loss: 0.2606 - val_accuracy: 0.9375\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1298 - accuracy: 0.9642 - val_loss: 0.2700 - val_accuracy: 0.9361\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.9625 - val_loss: 0.2626 - val_accuracy: 0.9380\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1355 - accuracy: 0.9625 - val_loss: 0.2763 - val_accuracy: 0.9342\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1369 - accuracy: 0.9621 - val_loss: 0.2588 - val_accuracy: 0.9385\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1287 - accuracy: 0.9643 - val_loss: 0.2610 - val_accuracy: 0.9366\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1298 - accuracy: 0.9641 - val_loss: 0.2691 - val_accuracy: 0.9383\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1296 - accuracy: 0.9643 - val_loss: 0.2598 - val_accuracy: 0.9384\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1285 - accuracy: 0.9646 - val_loss: 0.2640 - val_accuracy: 0.9386\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9622 - val_loss: 0.2668 - val_accuracy: 0.9365\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1325 - accuracy: 0.9631 - val_loss: 0.2773 - val_accuracy: 0.9352\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9624 - val_loss: 0.2711 - val_accuracy: 0.9360\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1340 - accuracy: 0.9629 - val_loss: 0.2719 - val_accuracy: 0.9354\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1335 - accuracy: 0.9632 - val_loss: 0.2811 - val_accuracy: 0.9349\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1380 - accuracy: 0.9617 - val_loss: 0.2666 - val_accuracy: 0.9371\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1268 - accuracy: 0.9649 - val_loss: 0.2634 - val_accuracy: 0.9374\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1268 - accuracy: 0.9651 - val_loss: 0.2639 - val_accuracy: 0.9382\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9643 - val_loss: 0.2738 - val_accuracy: 0.9356\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1272 - accuracy: 0.9646 - val_loss: 0.2644 - val_accuracy: 0.9385\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1278 - accuracy: 0.9644 - val_loss: 0.2647 - val_accuracy: 0.9382\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1345 - accuracy: 0.9630 - val_loss: 0.2764 - val_accuracy: 0.9374\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9637 - val_loss: 0.2653 - val_accuracy: 0.9375\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9656 - val_loss: 0.2564 - val_accuracy: 0.9404\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1227 - accuracy: 0.9664 - val_loss: 0.2769 - val_accuracy: 0.9366\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9649 - val_loss: 0.2628 - val_accuracy: 0.9384\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1229 - accuracy: 0.9662 - val_loss: 0.2621 - val_accuracy: 0.9379\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1254 - accuracy: 0.9654 - val_loss: 0.2652 - val_accuracy: 0.9383\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1283 - accuracy: 0.9645 - val_loss: 0.2723 - val_accuracy: 0.9363\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9652 - val_loss: 0.2700 - val_accuracy: 0.9386\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1285 - accuracy: 0.9641 - val_loss: 0.2787 - val_accuracy: 0.9361\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9633 - val_loss: 0.2930 - val_accuracy: 0.9341\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1335 - accuracy: 0.9631 - val_loss: 0.2928 - val_accuracy: 0.9352\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.9622 - val_loss: 0.2885 - val_accuracy: 0.9344\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1300 - accuracy: 0.9637 - val_loss: 0.2743 - val_accuracy: 0.9377\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1210 - accuracy: 0.9664 - val_loss: 0.2592 - val_accuracy: 0.9408\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1168 - accuracy: 0.9679 - val_loss: 0.2607 - val_accuracy: 0.9409\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1157 - accuracy: 0.9682 - val_loss: 0.2575 - val_accuracy: 0.9418\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1160 - accuracy: 0.9685 - val_loss: 0.2584 - val_accuracy: 0.9402\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1200 - accuracy: 0.9671 - val_loss: 0.2630 - val_accuracy: 0.9410\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1214 - accuracy: 0.9663 - val_loss: 0.2695 - val_accuracy: 0.9395\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1184 - accuracy: 0.9672 - val_loss: 0.2770 - val_accuracy: 0.9380\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1182 - accuracy: 0.9673 - val_loss: 0.2720 - val_accuracy: 0.9377\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1211 - accuracy: 0.9663 - val_loss: 0.2818 - val_accuracy: 0.9357\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1270 - accuracy: 0.9649 - val_loss: 0.2968 - val_accuracy: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1410 - accuracy: 0.9608 - val_loss: 0.2813 - val_accuracy: 0.9373\n",
      "Epoch 230/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1289 - accuracy: 0.9641 - val_loss: 0.2765 - val_accuracy: 0.9368\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1257 - accuracy: 0.9652 - val_loss: 0.2809 - val_accuracy: 0.9360\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1226 - accuracy: 0.9658 - val_loss: 0.2684 - val_accuracy: 0.9399\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1174 - accuracy: 0.9677 - val_loss: 0.2662 - val_accuracy: 0.9395\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1170 - accuracy: 0.9678 - val_loss: 0.2673 - val_accuracy: 0.9410\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9682 - val_loss: 0.2664 - val_accuracy: 0.9399\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1163 - accuracy: 0.9680 - val_loss: 0.2664 - val_accuracy: 0.9405\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9686 - val_loss: 0.2641 - val_accuracy: 0.9420\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9685 - val_loss: 0.2717 - val_accuracy: 0.9395\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1148 - accuracy: 0.9684 - val_loss: 0.2765 - val_accuracy: 0.9390\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1196 - accuracy: 0.9668 - val_loss: 0.2890 - val_accuracy: 0.9376\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1283 - accuracy: 0.9645 - val_loss: 0.2964 - val_accuracy: 0.9350\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1316 - accuracy: 0.9633 - val_loss: 0.2982 - val_accuracy: 0.9344\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9634 - val_loss: 0.2845 - val_accuracy: 0.9367\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1204 - accuracy: 0.9662 - val_loss: 0.2643 - val_accuracy: 0.9412\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1177 - accuracy: 0.9674 - val_loss: 0.2854 - val_accuracy: 0.9367\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1163 - accuracy: 0.9679 - val_loss: 0.2710 - val_accuracy: 0.9393\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9682 - val_loss: 0.2758 - val_accuracy: 0.9393\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1160 - accuracy: 0.9675 - val_loss: 0.2650 - val_accuracy: 0.9419\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1136 - accuracy: 0.9687 - val_loss: 0.2752 - val_accuracy: 0.9410\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1173 - accuracy: 0.9675 - val_loss: 0.2760 - val_accuracy: 0.9392\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9683 - val_loss: 0.2719 - val_accuracy: 0.9392\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1186 - accuracy: 0.9670 - val_loss: 0.2895 - val_accuracy: 0.9368\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1278 - accuracy: 0.9646 - val_loss: 0.3022 - val_accuracy: 0.9350\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1270 - accuracy: 0.9644 - val_loss: 0.2911 - val_accuracy: 0.9371\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1189 - accuracy: 0.9670 - val_loss: 0.2685 - val_accuracy: 0.9399\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1142 - accuracy: 0.9682 - val_loss: 0.2741 - val_accuracy: 0.9399\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.9687 - val_loss: 0.2691 - val_accuracy: 0.9412\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1126 - accuracy: 0.9688 - val_loss: 0.2746 - val_accuracy: 0.9409\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9679 - val_loss: 0.2820 - val_accuracy: 0.9394\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1167 - accuracy: 0.9678 - val_loss: 0.2753 - val_accuracy: 0.9394\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1163 - accuracy: 0.9679 - val_loss: 0.2941 - val_accuracy: 0.9377\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1221 - accuracy: 0.9659 - val_loss: 0.2772 - val_accuracy: 0.9388\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9680 - val_loss: 0.2693 - val_accuracy: 0.9396\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1121 - accuracy: 0.9688 - val_loss: 0.2812 - val_accuracy: 0.9402\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1112 - accuracy: 0.9692 - val_loss: 0.2783 - val_accuracy: 0.9405\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1119 - accuracy: 0.9689 - val_loss: 0.2841 - val_accuracy: 0.9396\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1131 - accuracy: 0.9687 - val_loss: 0.2794 - val_accuracy: 0.9393\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1128 - accuracy: 0.9686 - val_loss: 0.2768 - val_accuracy: 0.9412\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1135 - accuracy: 0.9685 - val_loss: 0.3000 - val_accuracy: 0.9382\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1183 - accuracy: 0.9673 - val_loss: 0.2840 - val_accuracy: 0.9395\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9681 - val_loss: 0.2805 - val_accuracy: 0.9396\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9685 - val_loss: 0.2849 - val_accuracy: 0.9399\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1147 - accuracy: 0.9679 - val_loss: 0.2974 - val_accuracy: 0.9364\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1209 - accuracy: 0.9665 - val_loss: 0.2986 - val_accuracy: 0.9376\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1228 - accuracy: 0.9656 - val_loss: 0.2984 - val_accuracy: 0.9344\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1193 - accuracy: 0.9665 - val_loss: 0.2845 - val_accuracy: 0.9392\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9682 - val_loss: 0.2814 - val_accuracy: 0.9389\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1699 - accuracy: 0.9562 - val_loss: 0.3054 - val_accuracy: 0.9323\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1273 - accuracy: 0.9648 - val_loss: 0.2787 - val_accuracy: 0.9404\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9694 - val_loss: 0.2688 - val_accuracy: 0.9414\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1048 - accuracy: 0.9711 - val_loss: 0.2791 - val_accuracy: 0.9391\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1059 - accuracy: 0.9709 - val_loss: 0.2757 - val_accuracy: 0.9419\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1052 - accuracy: 0.9710 - val_loss: 0.2623 - val_accuracy: 0.9440\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1052 - accuracy: 0.9709 - val_loss: 0.2778 - val_accuracy: 0.9424\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1047 - accuracy: 0.9712 - val_loss: 0.2713 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1069 - accuracy: 0.9706 - val_loss: 0.2821 - val_accuracy: 0.9401\n",
      "Epoch 287/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9700 - val_loss: 0.2829 - val_accuracy: 0.9413\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1058 - accuracy: 0.9710 - val_loss: 0.2811 - val_accuracy: 0.9398\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1082 - accuracy: 0.9699 - val_loss: 0.2772 - val_accuracy: 0.9409\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1066 - accuracy: 0.9707 - val_loss: 0.2873 - val_accuracy: 0.9413\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1120 - accuracy: 0.9687 - val_loss: 0.2856 - val_accuracy: 0.9404\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1160 - accuracy: 0.9681 - val_loss: 0.2980 - val_accuracy: 0.9375\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9678 - val_loss: 0.2911 - val_accuracy: 0.9384\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1126 - accuracy: 0.9685 - val_loss: 0.2961 - val_accuracy: 0.9386\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1108 - accuracy: 0.9691 - val_loss: 0.2908 - val_accuracy: 0.9388\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1085 - accuracy: 0.9697 - val_loss: 0.2894 - val_accuracy: 0.9392\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1075 - accuracy: 0.9703 - val_loss: 0.2837 - val_accuracy: 0.9391\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1084 - accuracy: 0.9699 - val_loss: 0.2867 - val_accuracy: 0.9413\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1103 - accuracy: 0.9692 - val_loss: 0.2958 - val_accuracy: 0.9381\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1107 - accuracy: 0.9692 - val_loss: 0.2907 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 5s 2ms/step - loss: 0.2907 - accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9584228e-01, 7.7861770e-08, 6.8411842e-05, ..., 2.8436830e-12,\n",
       "        1.9743222e-14, 1.1946634e-13],\n",
       "       [5.4251852e-29, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 1.6034463e-25],\n",
       "       [9.7387302e-01, 9.2133153e-03, 1.0764612e-03, ..., 6.7413050e-05,\n",
       "        8.5922919e-05, 3.5136425e-06],\n",
       "       ...,\n",
       "       [5.0198106e-04, 3.5143162e-15, 1.4232147e-15, ..., 1.0106419e-33,\n",
       "        6.7839659e-26, 7.6191155e-22],\n",
       "       [9.8253524e-01, 8.5771381e-04, 1.2527879e-02, ..., 9.6870725e-09,\n",
       "        4.2545083e-09, 3.9230924e-10],\n",
       "       [1.3149453e-17, 9.3192329e-19, 1.6458994e-08, ..., 0.0000000e+00,\n",
       "        6.1870644e-29, 2.7245320e-37]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
