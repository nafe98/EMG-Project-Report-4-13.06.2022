{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230825</th>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205408</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113331</th>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>1.2085</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156006</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420019</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Emg1    Emg2    Emg3    Emg4    Emg5    Emg6    Emg7    Emg8  \\\n",
       "230825  0.7983  0.0513  0.8862  0.8032  0.1025  0.1343  0.6738  0.5249   \n",
       "205408  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0220  0.0903   \n",
       "113331  0.1489  0.9351  0.1294  0.0073  0.0024  0.0293  1.7554  0.3931   \n",
       "156006  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342  0.0610   \n",
       "420019  0.0024  0.0049  0.0171  0.0024  0.0024  0.0024  0.0049  0.1270   \n",
       "\n",
       "          Emg9   Emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "230825  0.8887  0.0757           5             5        16          16  \n",
       "205408  0.0024  0.0439           5             0        13          13  \n",
       "113331  0.4272  1.2085           5             5         2           2  \n",
       "156006  0.0024  0.1221           6             0         7           7  \n",
       "420019  0.0757  0.0122           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset 1 Patient 1.xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471483 entries, 0 to 471482\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Emg1          471483 non-null  float64\n",
      " 1   Emg2          471483 non-null  float64\n",
      " 2   Emg3          471483 non-null  float64\n",
      " 3   Emg4          471483 non-null  float64\n",
      " 4   Emg5          471483 non-null  float64\n",
      " 5   Emg6          471483 non-null  float64\n",
      " 6   Emg7          471483 non-null  float64\n",
      " 7   Emg8          471483 non-null  float64\n",
      " 8   Emg9          471483 non-null  float64\n",
      " 9   Emg10         471483 non-null  float64\n",
      " 10  repetition    471483 non-null  int64  \n",
      " 11  rerepetition  471483 non-null  int64  \n",
      " 12  stimulus      471483 non-null  int64  \n",
      " 13  restimulus    471483 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emg1</th>\n",
       "      <th>Emg2</th>\n",
       "      <th>Emg3</th>\n",
       "      <th>Emg4</th>\n",
       "      <th>Emg5</th>\n",
       "      <th>Emg6</th>\n",
       "      <th>Emg7</th>\n",
       "      <th>Emg8</th>\n",
       "      <th>Emg9</th>\n",
       "      <th>Emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "      <td>471483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>0.123409</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.107259</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>3.136047</td>\n",
       "      <td>2.113255</td>\n",
       "      <td>5.562892</td>\n",
       "      <td>4.570513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286859</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.476014</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>3.480664</td>\n",
       "      <td>3.212682</td>\n",
       "      <td>6.575838</td>\n",
       "      <td>6.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.658200</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>1.484400</td>\n",
       "      <td>4.663100</td>\n",
       "      <td>4.665500</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>4.628900</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Emg1           Emg2           Emg3           Emg4  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.129657       0.122672       0.123409       0.044321   \n",
       "std         0.286859       0.322911       0.337717       0.167680   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.017100       0.002400       0.002400       0.002400   \n",
       "75%         0.114700       0.046400       0.058600       0.007300   \n",
       "max         4.665500       4.663100       4.658200       4.663100   \n",
       "\n",
       "                Emg5           Emg6           Emg7           Emg8  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.012722       0.014612       0.221796       0.233414   \n",
       "std         0.032359       0.042109       0.476014       0.353467   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.012200       0.063500   \n",
       "50%         0.002400       0.002400       0.051300       0.112300   \n",
       "75%         0.002400       0.002400       0.190400       0.244100   \n",
       "max         0.876500       1.484400       4.663100       4.665500   \n",
       "\n",
       "                Emg9          Emg10     repetition   rerepetition  \\\n",
       "count  471483.000000  471483.000000  471483.000000  471483.000000   \n",
       "mean        0.107259       0.072334       3.136047       2.113255   \n",
       "std         0.233386       0.156993       3.480664       3.212682   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.009800       0.000000       0.000000   \n",
       "50%         0.007300       0.039100       2.000000       0.000000   \n",
       "75%         0.136700       0.065900       6.000000       4.000000   \n",
       "max         4.660600       4.628900      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  471483.000000  471483.000000  \n",
       "mean        5.562892       4.570513  \n",
       "std         6.575838       6.427040  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%        10.000000       9.000000  \n",
       "max        23.000000      23.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     202625\n",
      "2      15538\n",
      "12     15532\n",
      "8      15531\n",
      "7      15518\n",
      "4      15516\n",
      "11     15514\n",
      "5      15492\n",
      "9      15492\n",
      "10     15477\n",
      "1      15476\n",
      "3      15469\n",
      "6      15469\n",
      "14     10361\n",
      "13     10360\n",
      "17     10346\n",
      "15     10334\n",
      "16     10320\n",
      "18      5210\n",
      "20      5202\n",
      "19      5189\n",
      "21      5185\n",
      "23      5166\n",
      "22      5161\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be64bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "y = keras.utils.np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273175</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.163107</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.275575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.304453</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.583680</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.589922</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.334591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312113</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.602667</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.378552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.596424</td>\n",
       "      <td>-0.498765</td>\n",
       "      <td>-0.393607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378530</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.545445</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378531</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.268859</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378532</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.558190</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378533</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.564693</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378534</th>\n",
       "      <td>-0.483823</td>\n",
       "      <td>-0.420358</td>\n",
       "      <td>-0.402043</td>\n",
       "      <td>-0.277718</td>\n",
       "      <td>-0.355235</td>\n",
       "      <td>-0.322813</td>\n",
       "      <td>-0.495774</td>\n",
       "      <td>-0.577437</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.467075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.273175 -0.420358 -0.402043 -0.277718 -0.355235 -0.163107 -0.495774   \n",
       "1      -0.304453 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "2      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "3      -0.312113 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "4      -0.335731 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "378530 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378531 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.268859 -0.495774   \n",
       "378532 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378533 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "378534 -0.483823 -0.420358 -0.402043 -0.277718 -0.355235 -0.322813 -0.495774   \n",
       "\n",
       "               7         8         9  \n",
       "0      -0.564693 -0.498765 -0.275575  \n",
       "1      -0.583680 -0.498765 -0.305083  \n",
       "2      -0.589922 -0.498765 -0.334591  \n",
       "3      -0.602667 -0.498765 -0.378552  \n",
       "4      -0.596424 -0.498765 -0.393607  \n",
       "...          ...       ...       ...  \n",
       "378530 -0.545445 -0.007433 -0.467075  \n",
       "378531 -0.558190  0.012680 -0.467075  \n",
       "378532 -0.558190  0.012680 -0.467075  \n",
       "378533 -0.564693  0.022532 -0.467075  \n",
       "378534 -0.577437  0.022532 -0.467075  \n",
       "\n",
       "[378535 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47781",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d426e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0ef208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n",
    "from keras.initializers import random_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d61bc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd77bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbdce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(input_dim,))\n",
    "hidden1 = Dense(3000, activation='relu')(visible)\n",
    "hidden2 = Dense(1500, activation='relu')(hidden1)\n",
    "hidden3 = Dropout(0.2)(hidden2)\n",
    "hidden4 = Dense(750, activation='relu')(hidden3)\n",
    "hidden5 = Dense(375, activation='relu')(hidden4)\n",
    "hidden6 = Dense(48, activation='relu')(hidden5)\n",
    "output = Dense(num_classes, activation='softmax')(hidden6)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dd33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 3000)              33000     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1500)              4501500   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 750)               1125750   \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 375)               281625    \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 48)                18048     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 24)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,961,099\n",
      "Trainable params: 5,961,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196ac97",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a2d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1d2b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, 'EMG_ANN', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358b592",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0ed4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "75/75 [==============================] - 3s 28ms/step - loss: 1.3858 - accuracy: 0.6522 - val_loss: 0.9775 - val_accuracy: 0.7351\n",
      "Epoch 2/300\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 0.8828 - accuracy: 0.7616 - val_loss: 0.7665 - val_accuracy: 0.7889\n",
      "Epoch 3/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.7160 - accuracy: 0.8010 - val_loss: 0.6568 - val_accuracy: 0.8156\n",
      "Epoch 4/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.6375 - accuracy: 0.8208 - val_loss: 0.6030 - val_accuracy: 0.8289\n",
      "Epoch 5/300\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 0.5846 - accuracy: 0.8338 - val_loss: 0.5549 - val_accuracy: 0.8421\n",
      "Epoch 6/300\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 0.5440 - accuracy: 0.8441 - val_loss: 0.5184 - val_accuracy: 0.8515\n",
      "Epoch 7/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.5192 - accuracy: 0.8517 - val_loss: 0.5059 - val_accuracy: 0.8551\n",
      "Epoch 8/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4846 - accuracy: 0.8600 - val_loss: 0.4799 - val_accuracy: 0.8632\n",
      "Epoch 9/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4639 - accuracy: 0.8661 - val_loss: 0.4529 - val_accuracy: 0.8696\n",
      "Epoch 10/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4460 - accuracy: 0.8708 - val_loss: 0.4408 - val_accuracy: 0.8719\n",
      "Epoch 11/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4273 - accuracy: 0.8759 - val_loss: 0.4254 - val_accuracy: 0.8770\n",
      "Epoch 12/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4154 - accuracy: 0.8794 - val_loss: 0.4154 - val_accuracy: 0.8794\n",
      "Epoch 13/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.4028 - accuracy: 0.8831 - val_loss: 0.4031 - val_accuracy: 0.8837\n",
      "Epoch 14/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3926 - accuracy: 0.8861 - val_loss: 0.4048 - val_accuracy: 0.8842\n",
      "Epoch 15/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3822 - accuracy: 0.8891 - val_loss: 0.3886 - val_accuracy: 0.8885\n",
      "Epoch 16/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3690 - accuracy: 0.8923 - val_loss: 0.3763 - val_accuracy: 0.8913\n",
      "Epoch 17/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3641 - accuracy: 0.8945 - val_loss: 0.3707 - val_accuracy: 0.8940\n",
      "Epoch 18/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3532 - accuracy: 0.8970 - val_loss: 0.3664 - val_accuracy: 0.8934\n",
      "Epoch 19/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3482 - accuracy: 0.8991 - val_loss: 0.3579 - val_accuracy: 0.8974\n",
      "Epoch 20/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3374 - accuracy: 0.9024 - val_loss: 0.3449 - val_accuracy: 0.9003\n",
      "Epoch 21/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3314 - accuracy: 0.9042 - val_loss: 0.3478 - val_accuracy: 0.9011\n",
      "Epoch 22/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3269 - accuracy: 0.9049 - val_loss: 0.3432 - val_accuracy: 0.9015\n",
      "Epoch 23/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3206 - accuracy: 0.9071 - val_loss: 0.3389 - val_accuracy: 0.9056\n",
      "Epoch 24/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3115 - accuracy: 0.9096 - val_loss: 0.3278 - val_accuracy: 0.9047\n",
      "Epoch 25/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.3067 - accuracy: 0.9113 - val_loss: 0.3203 - val_accuracy: 0.9074\n",
      "Epoch 26/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2987 - accuracy: 0.9133 - val_loss: 0.3255 - val_accuracy: 0.9078\n",
      "Epoch 27/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2973 - accuracy: 0.9140 - val_loss: 0.3237 - val_accuracy: 0.9084\n",
      "Epoch 28/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2908 - accuracy: 0.9156 - val_loss: 0.3070 - val_accuracy: 0.9131\n",
      "Epoch 29/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2882 - accuracy: 0.9169 - val_loss: 0.3183 - val_accuracy: 0.9099\n",
      "Epoch 30/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2833 - accuracy: 0.9187 - val_loss: 0.3030 - val_accuracy: 0.9133\n",
      "Epoch 31/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2781 - accuracy: 0.9196 - val_loss: 0.2998 - val_accuracy: 0.9141\n",
      "Epoch 32/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2793 - accuracy: 0.9191 - val_loss: 0.3036 - val_accuracy: 0.9135\n",
      "Epoch 33/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2718 - accuracy: 0.9215 - val_loss: 0.2898 - val_accuracy: 0.9177\n",
      "Epoch 34/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2657 - accuracy: 0.9234 - val_loss: 0.2886 - val_accuracy: 0.9172\n",
      "Epoch 35/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2653 - accuracy: 0.9236 - val_loss: 0.2887 - val_accuracy: 0.9171\n",
      "Epoch 36/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2638 - accuracy: 0.9236 - val_loss: 0.2890 - val_accuracy: 0.9179\n",
      "Epoch 37/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2604 - accuracy: 0.9253 - val_loss: 0.2882 - val_accuracy: 0.9187\n",
      "Epoch 38/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2557 - accuracy: 0.9260 - val_loss: 0.2841 - val_accuracy: 0.9202\n",
      "Epoch 39/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2551 - accuracy: 0.9265 - val_loss: 0.2729 - val_accuracy: 0.9221\n",
      "Epoch 40/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2517 - accuracy: 0.9276 - val_loss: 0.2723 - val_accuracy: 0.9230\n",
      "Epoch 41/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2502 - accuracy: 0.9285 - val_loss: 0.2770 - val_accuracy: 0.9214\n",
      "Epoch 42/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2434 - accuracy: 0.9297 - val_loss: 0.2696 - val_accuracy: 0.9246\n",
      "Epoch 43/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2466 - accuracy: 0.9292 - val_loss: 0.2656 - val_accuracy: 0.9242\n",
      "Epoch 44/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2452 - accuracy: 0.9299 - val_loss: 0.2713 - val_accuracy: 0.9230\n",
      "Epoch 45/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2400 - accuracy: 0.9311 - val_loss: 0.2674 - val_accuracy: 0.9237\n",
      "Epoch 46/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2361 - accuracy: 0.9319 - val_loss: 0.2688 - val_accuracy: 0.9236\n",
      "Epoch 47/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2343 - accuracy: 0.9332 - val_loss: 0.2707 - val_accuracy: 0.9233\n",
      "Epoch 48/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2318 - accuracy: 0.9340 - val_loss: 0.2643 - val_accuracy: 0.9252\n",
      "Epoch 49/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2306 - accuracy: 0.9341 - val_loss: 0.2553 - val_accuracy: 0.9275\n",
      "Epoch 50/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2311 - accuracy: 0.9338 - val_loss: 0.2623 - val_accuracy: 0.9268\n",
      "Epoch 51/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2272 - accuracy: 0.9349 - val_loss: 0.2669 - val_accuracy: 0.9246\n",
      "Epoch 52/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2237 - accuracy: 0.9362 - val_loss: 0.2619 - val_accuracy: 0.9264\n",
      "Epoch 53/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2251 - accuracy: 0.9357 - val_loss: 0.2522 - val_accuracy: 0.9296\n",
      "Epoch 54/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2248 - accuracy: 0.9364 - val_loss: 0.2571 - val_accuracy: 0.9280\n",
      "Epoch 55/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2178 - accuracy: 0.9379 - val_loss: 0.2551 - val_accuracy: 0.9289\n",
      "Epoch 56/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2173 - accuracy: 0.9379 - val_loss: 0.2546 - val_accuracy: 0.9279\n",
      "Epoch 57/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2169 - accuracy: 0.9383 - val_loss: 0.2597 - val_accuracy: 0.9280\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2181 - accuracy: 0.9378 - val_loss: 0.2415 - val_accuracy: 0.9324\n",
      "Epoch 59/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2105 - accuracy: 0.9402 - val_loss: 0.2473 - val_accuracy: 0.9306\n",
      "Epoch 60/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2169 - accuracy: 0.9382 - val_loss: 0.2559 - val_accuracy: 0.9289\n",
      "Epoch 61/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2127 - accuracy: 0.9394 - val_loss: 0.2461 - val_accuracy: 0.9308\n",
      "Epoch 62/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2104 - accuracy: 0.9401 - val_loss: 0.2470 - val_accuracy: 0.9316\n",
      "Epoch 63/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2094 - accuracy: 0.9401 - val_loss: 0.2470 - val_accuracy: 0.9310\n",
      "Epoch 64/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2071 - accuracy: 0.9411 - val_loss: 0.2427 - val_accuracy: 0.9326\n",
      "Epoch 65/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2047 - accuracy: 0.9417 - val_loss: 0.2493 - val_accuracy: 0.9301\n",
      "Epoch 66/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2079 - accuracy: 0.9411 - val_loss: 0.2461 - val_accuracy: 0.9309\n",
      "Epoch 67/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.2066 - accuracy: 0.9414 - val_loss: 0.2417 - val_accuracy: 0.9339\n",
      "Epoch 68/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1987 - accuracy: 0.9437 - val_loss: 0.2402 - val_accuracy: 0.9339\n",
      "Epoch 69/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1969 - accuracy: 0.9442 - val_loss: 0.2411 - val_accuracy: 0.9333\n",
      "Epoch 70/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1980 - accuracy: 0.9437 - val_loss: 0.2377 - val_accuracy: 0.9343\n",
      "Epoch 71/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.2013 - accuracy: 0.9430 - val_loss: 0.2439 - val_accuracy: 0.9331\n",
      "Epoch 72/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1994 - accuracy: 0.9434 - val_loss: 0.2353 - val_accuracy: 0.9349\n",
      "Epoch 73/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1961 - accuracy: 0.9443 - val_loss: 0.2362 - val_accuracy: 0.9344\n",
      "Epoch 74/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1972 - accuracy: 0.9444 - val_loss: 0.2339 - val_accuracy: 0.9360\n",
      "Epoch 75/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1949 - accuracy: 0.9446 - val_loss: 0.2329 - val_accuracy: 0.9361\n",
      "Epoch 76/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1906 - accuracy: 0.9465 - val_loss: 0.2363 - val_accuracy: 0.9353\n",
      "Epoch 77/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1943 - accuracy: 0.9449 - val_loss: 0.2429 - val_accuracy: 0.9326\n",
      "Epoch 78/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1946 - accuracy: 0.9446 - val_loss: 0.2468 - val_accuracy: 0.9318\n",
      "Epoch 79/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1899 - accuracy: 0.9464 - val_loss: 0.2347 - val_accuracy: 0.9354\n",
      "Epoch 80/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1872 - accuracy: 0.9468 - val_loss: 0.2356 - val_accuracy: 0.9351\n",
      "Epoch 81/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1868 - accuracy: 0.9475 - val_loss: 0.2308 - val_accuracy: 0.9365\n",
      "Epoch 82/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1829 - accuracy: 0.9481 - val_loss: 0.2300 - val_accuracy: 0.9369\n",
      "Epoch 83/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1890 - accuracy: 0.9466 - val_loss: 0.2359 - val_accuracy: 0.9349\n",
      "Epoch 84/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1857 - accuracy: 0.9473 - val_loss: 0.2357 - val_accuracy: 0.9361\n",
      "Epoch 85/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1849 - accuracy: 0.9478 - val_loss: 0.2301 - val_accuracy: 0.9370\n",
      "Epoch 86/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1895 - accuracy: 0.9464 - val_loss: 0.2338 - val_accuracy: 0.9366\n",
      "Epoch 87/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1901 - accuracy: 0.9462 - val_loss: 0.2335 - val_accuracy: 0.9369\n",
      "Epoch 88/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1822 - accuracy: 0.9485 - val_loss: 0.2243 - val_accuracy: 0.9389\n",
      "Epoch 89/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1781 - accuracy: 0.9496 - val_loss: 0.2335 - val_accuracy: 0.9369\n",
      "Epoch 90/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1791 - accuracy: 0.9494 - val_loss: 0.2394 - val_accuracy: 0.9361\n",
      "Epoch 91/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1797 - accuracy: 0.9493 - val_loss: 0.2334 - val_accuracy: 0.9367\n",
      "Epoch 92/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1784 - accuracy: 0.9495 - val_loss: 0.2269 - val_accuracy: 0.9393\n",
      "Epoch 93/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1777 - accuracy: 0.9500 - val_loss: 0.2416 - val_accuracy: 0.9356\n",
      "Epoch 94/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1810 - accuracy: 0.9491 - val_loss: 0.2278 - val_accuracy: 0.9388\n",
      "Epoch 95/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1779 - accuracy: 0.9496 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 96/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1763 - accuracy: 0.9501 - val_loss: 0.2252 - val_accuracy: 0.9384\n",
      "Epoch 97/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1756 - accuracy: 0.9507 - val_loss: 0.2457 - val_accuracy: 0.9341\n",
      "Epoch 98/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1793 - accuracy: 0.9494 - val_loss: 0.2301 - val_accuracy: 0.9376\n",
      "Epoch 99/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1752 - accuracy: 0.9507 - val_loss: 0.2267 - val_accuracy: 0.9388\n",
      "Epoch 100/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1716 - accuracy: 0.9517 - val_loss: 0.2272 - val_accuracy: 0.9388\n",
      "Epoch 101/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1733 - accuracy: 0.9508 - val_loss: 0.2316 - val_accuracy: 0.9384\n",
      "Epoch 102/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1711 - accuracy: 0.9518 - val_loss: 0.2264 - val_accuracy: 0.9397\n",
      "Epoch 103/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1721 - accuracy: 0.9515 - val_loss: 0.2247 - val_accuracy: 0.9400\n",
      "Epoch 104/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1730 - accuracy: 0.9515 - val_loss: 0.2310 - val_accuracy: 0.9382\n",
      "Epoch 105/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1750 - accuracy: 0.9506 - val_loss: 0.2258 - val_accuracy: 0.9396\n",
      "Epoch 106/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1681 - accuracy: 0.9528 - val_loss: 0.2269 - val_accuracy: 0.9401\n",
      "Epoch 107/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1669 - accuracy: 0.9526 - val_loss: 0.2229 - val_accuracy: 0.9403\n",
      "Epoch 108/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1673 - accuracy: 0.9530 - val_loss: 0.2281 - val_accuracy: 0.9392\n",
      "Epoch 109/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1678 - accuracy: 0.9529 - val_loss: 0.2298 - val_accuracy: 0.9382\n",
      "Epoch 110/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1673 - accuracy: 0.9529 - val_loss: 0.2288 - val_accuracy: 0.9381\n",
      "Epoch 111/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.2298 - val_accuracy: 0.9378\n",
      "Epoch 112/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1668 - accuracy: 0.9530 - val_loss: 0.2209 - val_accuracy: 0.9407\n",
      "Epoch 113/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1658 - accuracy: 0.9536 - val_loss: 0.2270 - val_accuracy: 0.9401\n",
      "Epoch 114/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1646 - accuracy: 0.9540 - val_loss: 0.2294 - val_accuracy: 0.9391\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1656 - accuracy: 0.9533 - val_loss: 0.2277 - val_accuracy: 0.9400\n",
      "Epoch 116/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1632 - accuracy: 0.9541 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 117/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1804 - accuracy: 0.9504 - val_loss: 0.2734 - val_accuracy: 0.9285\n",
      "Epoch 118/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1770 - accuracy: 0.9500 - val_loss: 0.2229 - val_accuracy: 0.9395\n",
      "Epoch 119/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1597 - accuracy: 0.9549 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 120/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1601 - accuracy: 0.9549 - val_loss: 0.2210 - val_accuracy: 0.9422\n",
      "Epoch 121/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1611 - accuracy: 0.9550 - val_loss: 0.2282 - val_accuracy: 0.9395\n",
      "Epoch 122/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1605 - accuracy: 0.9545 - val_loss: 0.2221 - val_accuracy: 0.9424\n",
      "Epoch 123/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1586 - accuracy: 0.9554 - val_loss: 0.2255 - val_accuracy: 0.9405\n",
      "Epoch 124/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1561 - accuracy: 0.9565 - val_loss: 0.2178 - val_accuracy: 0.9429\n",
      "Epoch 125/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1559 - accuracy: 0.9562 - val_loss: 0.2243 - val_accuracy: 0.9406\n",
      "Epoch 126/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1552 - accuracy: 0.9565 - val_loss: 0.2221 - val_accuracy: 0.9410\n",
      "Epoch 127/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1577 - accuracy: 0.9557 - val_loss: 0.2266 - val_accuracy: 0.9418\n",
      "Epoch 128/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1563 - accuracy: 0.9563 - val_loss: 0.2253 - val_accuracy: 0.9403\n",
      "Epoch 129/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1568 - accuracy: 0.9560 - val_loss: 0.2269 - val_accuracy: 0.9415\n",
      "Epoch 130/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1555 - accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.9417\n",
      "Epoch 131/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1552 - accuracy: 0.9565 - val_loss: 0.2253 - val_accuracy: 0.9421\n",
      "Epoch 132/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1586 - accuracy: 0.9555 - val_loss: 0.2240 - val_accuracy: 0.9423\n",
      "Epoch 133/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1555 - accuracy: 0.9565 - val_loss: 0.2191 - val_accuracy: 0.9430\n",
      "Epoch 134/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1528 - accuracy: 0.9572 - val_loss: 0.2271 - val_accuracy: 0.9422\n",
      "Epoch 135/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1518 - accuracy: 0.9574 - val_loss: 0.2183 - val_accuracy: 0.9430\n",
      "Epoch 136/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1526 - accuracy: 0.9572 - val_loss: 0.2171 - val_accuracy: 0.9435\n",
      "Epoch 137/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1518 - accuracy: 0.9574 - val_loss: 0.2259 - val_accuracy: 0.9420\n",
      "Epoch 138/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1530 - accuracy: 0.9569 - val_loss: 0.2244 - val_accuracy: 0.9419\n",
      "Epoch 139/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1543 - accuracy: 0.9567 - val_loss: 0.2210 - val_accuracy: 0.9418\n",
      "Epoch 140/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1549 - accuracy: 0.9567 - val_loss: 0.2221 - val_accuracy: 0.9418\n",
      "Epoch 141/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1528 - accuracy: 0.9569 - val_loss: 0.2228 - val_accuracy: 0.9415\n",
      "Epoch 142/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1496 - accuracy: 0.9579 - val_loss: 0.2155 - val_accuracy: 0.9435\n",
      "Epoch 143/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1499 - accuracy: 0.9582 - val_loss: 0.2177 - val_accuracy: 0.9435\n",
      "Epoch 144/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1484 - accuracy: 0.9582 - val_loss: 0.2258 - val_accuracy: 0.9423\n",
      "Epoch 145/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1517 - accuracy: 0.9574 - val_loss: 0.2213 - val_accuracy: 0.9424\n",
      "Epoch 146/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1495 - accuracy: 0.9580 - val_loss: 0.2208 - val_accuracy: 0.9428\n",
      "Epoch 147/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1697 - accuracy: 0.9529 - val_loss: 0.2225 - val_accuracy: 0.9423\n",
      "Epoch 148/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.2182 - val_accuracy: 0.9432\n",
      "Epoch 149/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1480 - accuracy: 0.9583 - val_loss: 0.2174 - val_accuracy: 0.9441\n",
      "Epoch 150/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1475 - accuracy: 0.9587 - val_loss: 0.2238 - val_accuracy: 0.9433\n",
      "Epoch 151/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1480 - accuracy: 0.9584 - val_loss: 0.2195 - val_accuracy: 0.9435\n",
      "Epoch 152/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1493 - accuracy: 0.9584 - val_loss: 0.2245 - val_accuracy: 0.9423\n",
      "Epoch 153/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1481 - accuracy: 0.9585 - val_loss: 0.2222 - val_accuracy: 0.9434\n",
      "Epoch 154/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1477 - accuracy: 0.9586 - val_loss: 0.2174 - val_accuracy: 0.9449\n",
      "Epoch 155/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1446 - accuracy: 0.9597 - val_loss: 0.2243 - val_accuracy: 0.9442\n",
      "Epoch 156/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1445 - accuracy: 0.9593 - val_loss: 0.2223 - val_accuracy: 0.9432\n",
      "Epoch 157/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1635 - accuracy: 0.9548 - val_loss: 0.2335 - val_accuracy: 0.9396\n",
      "Epoch 158/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1491 - accuracy: 0.9581 - val_loss: 0.2159 - val_accuracy: 0.9443\n",
      "Epoch 159/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.2260 - val_accuracy: 0.9429\n",
      "Epoch 160/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1423 - accuracy: 0.9602 - val_loss: 0.2156 - val_accuracy: 0.9448\n",
      "Epoch 161/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1393 - accuracy: 0.9607 - val_loss: 0.2213 - val_accuracy: 0.9439\n",
      "Epoch 162/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1412 - accuracy: 0.9604 - val_loss: 0.2219 - val_accuracy: 0.9434\n",
      "Epoch 163/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1428 - accuracy: 0.9603 - val_loss: 0.2162 - val_accuracy: 0.9448\n",
      "Epoch 164/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1408 - accuracy: 0.9606 - val_loss: 0.2171 - val_accuracy: 0.9435\n",
      "Epoch 165/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1414 - accuracy: 0.9605 - val_loss: 0.2194 - val_accuracy: 0.9444\n",
      "Epoch 166/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1420 - accuracy: 0.9602 - val_loss: 0.2227 - val_accuracy: 0.9439\n",
      "Epoch 167/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1409 - accuracy: 0.9609 - val_loss: 0.2194 - val_accuracy: 0.9443\n",
      "Epoch 168/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1424 - accuracy: 0.9600 - val_loss: 0.2232 - val_accuracy: 0.9432\n",
      "Epoch 169/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.2184 - val_accuracy: 0.9449\n",
      "Epoch 170/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1415 - accuracy: 0.9600 - val_loss: 0.2200 - val_accuracy: 0.9446\n",
      "Epoch 171/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1435 - accuracy: 0.9599 - val_loss: 0.2243 - val_accuracy: 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1400 - accuracy: 0.9608 - val_loss: 0.2175 - val_accuracy: 0.9449\n",
      "Epoch 173/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1365 - accuracy: 0.9616 - val_loss: 0.2186 - val_accuracy: 0.9450\n",
      "Epoch 174/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1414 - accuracy: 0.9601 - val_loss: 0.2205 - val_accuracy: 0.9442\n",
      "Epoch 175/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1369 - accuracy: 0.9614 - val_loss: 0.2208 - val_accuracy: 0.9441\n",
      "Epoch 176/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1367 - accuracy: 0.9617 - val_loss: 0.2240 - val_accuracy: 0.9442\n",
      "Epoch 177/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1377 - accuracy: 0.9613 - val_loss: 0.2229 - val_accuracy: 0.9447\n",
      "Epoch 178/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1397 - accuracy: 0.9607 - val_loss: 0.2185 - val_accuracy: 0.9440\n",
      "Epoch 179/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1383 - accuracy: 0.9611 - val_loss: 0.2213 - val_accuracy: 0.9449\n",
      "Epoch 180/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1360 - accuracy: 0.9618 - val_loss: 0.2179 - val_accuracy: 0.9451\n",
      "Epoch 181/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1329 - accuracy: 0.9628 - val_loss: 0.2161 - val_accuracy: 0.9449\n",
      "Epoch 182/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1361 - accuracy: 0.9619 - val_loss: 0.2186 - val_accuracy: 0.9455\n",
      "Epoch 183/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1372 - accuracy: 0.9613 - val_loss: 0.2203 - val_accuracy: 0.9446\n",
      "Epoch 184/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1354 - accuracy: 0.9622 - val_loss: 0.2159 - val_accuracy: 0.9460\n",
      "Epoch 185/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1339 - accuracy: 0.9622 - val_loss: 0.2219 - val_accuracy: 0.9447\n",
      "Epoch 186/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1364 - accuracy: 0.9618 - val_loss: 0.2222 - val_accuracy: 0.9445\n",
      "Epoch 187/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1506 - accuracy: 0.9583 - val_loss: 0.2218 - val_accuracy: 0.9446\n",
      "Epoch 188/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1354 - accuracy: 0.9617 - val_loss: 0.2202 - val_accuracy: 0.9448\n",
      "Epoch 189/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1347 - accuracy: 0.9623 - val_loss: 0.2199 - val_accuracy: 0.9457\n",
      "Epoch 190/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1343 - accuracy: 0.9624 - val_loss: 0.2204 - val_accuracy: 0.9451\n",
      "Epoch 191/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1348 - accuracy: 0.9619 - val_loss: 0.2212 - val_accuracy: 0.9442\n",
      "Epoch 192/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1313 - accuracy: 0.9632 - val_loss: 0.2324 - val_accuracy: 0.9426\n",
      "Epoch 193/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1360 - accuracy: 0.9617 - val_loss: 0.2194 - val_accuracy: 0.9447\n",
      "Epoch 194/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1336 - accuracy: 0.9626 - val_loss: 0.2202 - val_accuracy: 0.9452\n",
      "Epoch 195/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1319 - accuracy: 0.9631 - val_loss: 0.2150 - val_accuracy: 0.9467\n",
      "Epoch 196/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1317 - accuracy: 0.9632 - val_loss: 0.2224 - val_accuracy: 0.9442\n",
      "Epoch 197/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1313 - accuracy: 0.9629 - val_loss: 0.2225 - val_accuracy: 0.9452\n",
      "Epoch 198/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1395 - accuracy: 0.9609 - val_loss: 0.2226 - val_accuracy: 0.9456\n",
      "Epoch 199/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1315 - accuracy: 0.9630 - val_loss: 0.2195 - val_accuracy: 0.9463\n",
      "Epoch 200/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1326 - accuracy: 0.9627 - val_loss: 0.2184 - val_accuracy: 0.9464\n",
      "Epoch 201/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1313 - accuracy: 0.9631 - val_loss: 0.2260 - val_accuracy: 0.9449\n",
      "Epoch 202/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1315 - accuracy: 0.9630 - val_loss: 0.2293 - val_accuracy: 0.9449\n",
      "Epoch 203/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1341 - accuracy: 0.9623 - val_loss: 0.2185 - val_accuracy: 0.9457\n",
      "Epoch 204/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1321 - accuracy: 0.9630 - val_loss: 0.2189 - val_accuracy: 0.9454\n",
      "Epoch 205/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1306 - accuracy: 0.9634 - val_loss: 0.2198 - val_accuracy: 0.9454\n",
      "Epoch 206/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1303 - accuracy: 0.9633 - val_loss: 0.2222 - val_accuracy: 0.9464\n",
      "Epoch 207/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1300 - accuracy: 0.9634 - val_loss: 0.2191 - val_accuracy: 0.9460\n",
      "Epoch 208/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1297 - accuracy: 0.9636 - val_loss: 0.2227 - val_accuracy: 0.9462\n",
      "Epoch 209/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1292 - accuracy: 0.9634 - val_loss: 0.2251 - val_accuracy: 0.9456\n",
      "Epoch 210/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1296 - accuracy: 0.9638 - val_loss: 0.2239 - val_accuracy: 0.9460\n",
      "Epoch 211/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1294 - accuracy: 0.9635 - val_loss: 0.2168 - val_accuracy: 0.9465\n",
      "Epoch 212/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1273 - accuracy: 0.9644 - val_loss: 0.2172 - val_accuracy: 0.9470\n",
      "Epoch 213/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1270 - accuracy: 0.9644 - val_loss: 0.2237 - val_accuracy: 0.9469\n",
      "Epoch 214/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1367 - accuracy: 0.9618 - val_loss: 0.2226 - val_accuracy: 0.9460\n",
      "Epoch 215/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1263 - accuracy: 0.9646 - val_loss: 0.2278 - val_accuracy: 0.9462\n",
      "Epoch 216/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1254 - accuracy: 0.9649 - val_loss: 0.2211 - val_accuracy: 0.9471\n",
      "Epoch 217/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1277 - accuracy: 0.9641 - val_loss: 0.2217 - val_accuracy: 0.9470\n",
      "Epoch 218/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1300 - accuracy: 0.9635 - val_loss: 0.2297 - val_accuracy: 0.9454\n",
      "Epoch 219/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1265 - accuracy: 0.9641 - val_loss: 0.2198 - val_accuracy: 0.9461\n",
      "Epoch 220/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1273 - accuracy: 0.9642 - val_loss: 0.2180 - val_accuracy: 0.9465\n",
      "Epoch 221/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1248 - accuracy: 0.9650 - val_loss: 0.2223 - val_accuracy: 0.9471\n",
      "Epoch 222/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1265 - accuracy: 0.9644 - val_loss: 0.2299 - val_accuracy: 0.9454\n",
      "Epoch 223/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1277 - accuracy: 0.9639 - val_loss: 0.2233 - val_accuracy: 0.9460\n",
      "Epoch 224/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1269 - accuracy: 0.9641 - val_loss: 0.2278 - val_accuracy: 0.9451\n",
      "Epoch 225/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1293 - accuracy: 0.9635 - val_loss: 0.2288 - val_accuracy: 0.9457\n",
      "Epoch 226/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1354 - accuracy: 0.9619 - val_loss: 0.2162 - val_accuracy: 0.9475\n",
      "Epoch 227/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1241 - accuracy: 0.9650 - val_loss: 0.2188 - val_accuracy: 0.9463\n",
      "Epoch 228/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1242 - accuracy: 0.9651 - val_loss: 0.2194 - val_accuracy: 0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1241 - accuracy: 0.9653 - val_loss: 0.2272 - val_accuracy: 0.9462\n",
      "Epoch 230/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1244 - accuracy: 0.9649 - val_loss: 0.2193 - val_accuracy: 0.9477\n",
      "Epoch 231/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1226 - accuracy: 0.9657 - val_loss: 0.2215 - val_accuracy: 0.9472\n",
      "Epoch 232/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1256 - accuracy: 0.9650 - val_loss: 0.2187 - val_accuracy: 0.9466\n",
      "Epoch 233/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1225 - accuracy: 0.9658 - val_loss: 0.2209 - val_accuracy: 0.9469\n",
      "Epoch 234/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1224 - accuracy: 0.9655 - val_loss: 0.2200 - val_accuracy: 0.9478\n",
      "Epoch 235/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1210 - accuracy: 0.9661 - val_loss: 0.2154 - val_accuracy: 0.9480\n",
      "Epoch 236/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1222 - accuracy: 0.9657 - val_loss: 0.2209 - val_accuracy: 0.9470\n",
      "Epoch 237/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1216 - accuracy: 0.9659 - val_loss: 0.2225 - val_accuracy: 0.9465\n",
      "Epoch 238/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1247 - accuracy: 0.9648 - val_loss: 0.2248 - val_accuracy: 0.9464\n",
      "Epoch 239/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1230 - accuracy: 0.9655 - val_loss: 0.2300 - val_accuracy: 0.9439\n",
      "Epoch 240/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1247 - accuracy: 0.9650 - val_loss: 0.2231 - val_accuracy: 0.9467\n",
      "Epoch 241/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1219 - accuracy: 0.9657 - val_loss: 0.2203 - val_accuracy: 0.9470\n",
      "Epoch 242/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1227 - accuracy: 0.9656 - val_loss: 0.2268 - val_accuracy: 0.9459\n",
      "Epoch 243/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1228 - accuracy: 0.9652 - val_loss: 0.2180 - val_accuracy: 0.9479\n",
      "Epoch 244/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1203 - accuracy: 0.9661 - val_loss: 0.2211 - val_accuracy: 0.9465\n",
      "Epoch 245/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1206 - accuracy: 0.9659 - val_loss: 0.2303 - val_accuracy: 0.9459\n",
      "Epoch 246/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1215 - accuracy: 0.9660 - val_loss: 0.2252 - val_accuracy: 0.9464\n",
      "Epoch 247/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1222 - accuracy: 0.9654 - val_loss: 0.2210 - val_accuracy: 0.9478\n",
      "Epoch 248/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1227 - accuracy: 0.9658 - val_loss: 0.2233 - val_accuracy: 0.9474\n",
      "Epoch 249/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1208 - accuracy: 0.9657 - val_loss: 0.2219 - val_accuracy: 0.9472\n",
      "Epoch 250/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1198 - accuracy: 0.9663 - val_loss: 0.2220 - val_accuracy: 0.9473\n",
      "Epoch 251/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1204 - accuracy: 0.9662 - val_loss: 0.2190 - val_accuracy: 0.9474\n",
      "Epoch 252/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1181 - accuracy: 0.9672 - val_loss: 0.2221 - val_accuracy: 0.9470\n",
      "Epoch 253/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1181 - accuracy: 0.9668 - val_loss: 0.2257 - val_accuracy: 0.9473\n",
      "Epoch 254/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1191 - accuracy: 0.9666 - val_loss: 0.2256 - val_accuracy: 0.9469\n",
      "Epoch 255/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1211 - accuracy: 0.9661 - val_loss: 0.2291 - val_accuracy: 0.9452\n",
      "Epoch 256/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1198 - accuracy: 0.9663 - val_loss: 0.2299 - val_accuracy: 0.9455\n",
      "Epoch 257/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1820 - accuracy: 0.9523 - val_loss: 0.2305 - val_accuracy: 0.9442\n",
      "Epoch 258/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1264 - accuracy: 0.9641 - val_loss: 0.2178 - val_accuracy: 0.9467\n",
      "Epoch 259/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1203 - accuracy: 0.9658 - val_loss: 0.2227 - val_accuracy: 0.9474\n",
      "Epoch 260/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1170 - accuracy: 0.9669 - val_loss: 0.2223 - val_accuracy: 0.9479\n",
      "Epoch 261/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1195 - accuracy: 0.9661 - val_loss: 0.2227 - val_accuracy: 0.9473\n",
      "Epoch 262/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1185 - accuracy: 0.9665 - val_loss: 0.2483 - val_accuracy: 0.9426\n",
      "Epoch 263/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1253 - accuracy: 0.9647 - val_loss: 0.2177 - val_accuracy: 0.9473\n",
      "Epoch 264/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1184 - accuracy: 0.9668 - val_loss: 0.2219 - val_accuracy: 0.9473\n",
      "Epoch 265/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1159 - accuracy: 0.9670 - val_loss: 0.2246 - val_accuracy: 0.9479\n",
      "Epoch 266/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1159 - accuracy: 0.9671 - val_loss: 0.2213 - val_accuracy: 0.9486\n",
      "Epoch 267/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1170 - accuracy: 0.9669 - val_loss: 0.2252 - val_accuracy: 0.9477\n",
      "Epoch 268/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1154 - accuracy: 0.9674 - val_loss: 0.2268 - val_accuracy: 0.9470\n",
      "Epoch 269/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1171 - accuracy: 0.9670 - val_loss: 0.2267 - val_accuracy: 0.9474\n",
      "Epoch 270/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1147 - accuracy: 0.9675 - val_loss: 0.2233 - val_accuracy: 0.9471\n",
      "Epoch 271/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1144 - accuracy: 0.9678 - val_loss: 0.2278 - val_accuracy: 0.9468\n",
      "Epoch 272/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1148 - accuracy: 0.9674 - val_loss: 0.2283 - val_accuracy: 0.9480\n",
      "Epoch 273/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1183 - accuracy: 0.9665 - val_loss: 0.2202 - val_accuracy: 0.9481\n",
      "Epoch 274/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1175 - accuracy: 0.9670 - val_loss: 0.2269 - val_accuracy: 0.9472\n",
      "Epoch 275/300\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1173 - accuracy: 0.9672 - val_loss: 0.2304 - val_accuracy: 0.9462\n",
      "Epoch 276/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1163 - accuracy: 0.9673 - val_loss: 0.2246 - val_accuracy: 0.9483\n",
      "Epoch 277/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1169 - accuracy: 0.9672 - val_loss: 0.2280 - val_accuracy: 0.9465\n",
      "Epoch 278/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1145 - accuracy: 0.9677 - val_loss: 0.2293 - val_accuracy: 0.9479\n",
      "Epoch 279/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1147 - accuracy: 0.9675 - val_loss: 0.2223 - val_accuracy: 0.9483\n",
      "Epoch 280/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1179 - accuracy: 0.9668 - val_loss: 0.2394 - val_accuracy: 0.9432\n",
      "Epoch 281/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1214 - accuracy: 0.9658 - val_loss: 0.2278 - val_accuracy: 0.9464\n",
      "Epoch 282/300\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.1140 - accuracy: 0.9680 - val_loss: 0.2239 - val_accuracy: 0.9485\n",
      "Epoch 283/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1130 - accuracy: 0.9681 - val_loss: 0.2256 - val_accuracy: 0.9485\n",
      "Epoch 284/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1137 - accuracy: 0.9679 - val_loss: 0.2243 - val_accuracy: 0.9477\n",
      "Epoch 285/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1135 - accuracy: 0.9681 - val_loss: 0.2258 - val_accuracy: 0.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1128 - accuracy: 0.9682 - val_loss: 0.2258 - val_accuracy: 0.9477\n",
      "Epoch 287/300\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 0.1121 - accuracy: 0.9685 - val_loss: 0.2271 - val_accuracy: 0.9474\n",
      "Epoch 288/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1134 - accuracy: 0.9681 - val_loss: 0.2269 - val_accuracy: 0.9479\n",
      "Epoch 289/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1135 - accuracy: 0.9678 - val_loss: 0.2269 - val_accuracy: 0.9478\n",
      "Epoch 290/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1133 - accuracy: 0.9680 - val_loss: 0.2227 - val_accuracy: 0.9479\n",
      "Epoch 291/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1137 - accuracy: 0.9679 - val_loss: 0.2272 - val_accuracy: 0.9478\n",
      "Epoch 292/300\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1133 - accuracy: 0.9679 - val_loss: 0.2262 - val_accuracy: 0.9489\n",
      "Epoch 293/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1114 - accuracy: 0.9686 - val_loss: 0.2257 - val_accuracy: 0.9478\n",
      "Epoch 294/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1149 - accuracy: 0.9676 - val_loss: 0.2297 - val_accuracy: 0.9475\n",
      "Epoch 295/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1136 - accuracy: 0.9679 - val_loss: 0.2293 - val_accuracy: 0.9480\n",
      "Epoch 296/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1135 - accuracy: 0.9681 - val_loss: 0.2247 - val_accuracy: 0.9483\n",
      "Epoch 297/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1120 - accuracy: 0.9681 - val_loss: 0.2271 - val_accuracy: 0.9479\n",
      "Epoch 298/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1122 - accuracy: 0.9682 - val_loss: 0.2306 - val_accuracy: 0.9469\n",
      "Epoch 299/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1129 - accuracy: 0.9679 - val_loss: 0.2283 - val_accuracy: 0.9479\n",
      "Epoch 300/300\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 0.1109 - accuracy: 0.9686 - val_loss: 0.2257 - val_accuracy: 0.9484\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4056, epochs=300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed59b1",
   "metadata": {},
   "source": [
    "# 4.Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28731190",
   "metadata": {},
   "source": [
    "## 4.1. Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "971e6040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Curve\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0c193ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy Curve\n",
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806270f7",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f86c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366/2366 [==============================] - 5s 2ms/step - loss: 0.2257 - accuracy: 0.9484\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a02aa",
   "metadata": {},
   "source": [
    "##  4.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8465627",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68ff1c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97636080e-01, 2.73465250e-08, 1.07962376e-04, ...,\n",
       "        4.88408247e-08, 9.48978141e-08, 1.19607666e-08],\n",
       "       [2.05656894e-37, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.18623328e-01, 2.22342573e-02, 1.33453577e-03, ...,\n",
       "        2.08075630e-06, 5.26231547e-09, 1.53041594e-06],\n",
       "       ...,\n",
       "       [2.09843847e-07, 4.24011141e-14, 4.35414110e-16, ...,\n",
       "        5.50314235e-16, 1.93676076e-13, 1.89363347e-23],\n",
       "       [9.87774193e-01, 1.70205324e-03, 6.89684693e-03, ...,\n",
       "        1.63209961e-06, 5.58209740e-06, 2.45342221e-06],\n",
       "       [1.11240729e-13, 1.33564827e-16, 2.51333719e-12, ...,\n",
       "        1.07356944e-20, 1.54395225e-22, 1.43924278e-29]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
